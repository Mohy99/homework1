{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_excel('sz50.xlsx',sheetname= None, index_col='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('600000.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  115.99  117.06  115.14  115.43  16232125\n",
      "2017-01-04 15:00:00  116.28  116.42  115.21  115.99  29656234\n",
      "2017-01-05 15:00:00  116.07  116.64  115.64  116.07  26436646\n",
      "2017-01-06 15:00:00  115.21  116.07  114.86  116.07  17195598\n",
      "2017-01-09 15:00:00  115.35  115.99  114.86  115.64  14908745\n",
      "2017-01-10 15:00:00  115.28  115.64  114.93  115.21   7996636\n",
      "2017-01-11 15:00:00  115.07  115.64  115.00  115.64   9166532\n",
      "2017-01-12 15:00:00  114.78  115.35  114.71  115.21   8295650\n",
      "2017-01-13 15:00:00  115.85  115.99  114.64  114.64  19024943\n",
      "2017-01-16 15:00:00  117.92  118.20  114.64  115.57  53249124\n",
      "2017-01-17 15:00:00  116.85  117.77  116.56  117.21  12555292\n",
      "2017-01-18 15:00:00  117.42  117.85  116.49  116.92  11478663\n",
      "2017-01-19 15:00:00  117.77  118.49  116.99  116.99  12180687\n",
      "2017-01-20 15:00:00  118.06  118.63  117.49  118.06  14285968\n",
      "2017-01-23 15:00:00  117.99  118.84  117.56  118.63  14615740\n",
      "2017-01-24 15:00:00  118.91  118.91  118.06  118.06  14985241\n",
      "2017-01-25 15:00:00  118.91  119.20  118.27  118.84  11284869\n",
      "2017-01-26 15:00:00  119.41  119.91  118.27  118.84   8602907\n",
      "2017-02-03 15:00:00  118.42  119.98  118.34  119.77   8171489\n",
      "2017-02-06 15:00:00  118.63  119.48  118.63  119.27  13455250\n",
      "2017-02-07 15:00:00  118.77  119.20  118.42  118.56  14757284\n",
      "2017-02-08 15:00:00  118.63  118.84  117.77  118.42  11238767\n",
      "2017-02-09 15:00:00  119.06  119.41  118.13  118.77  11393034\n",
      "2017-02-10 15:00:00  119.48  119.91  118.91  119.34  13983062\n",
      "2017-02-13 15:00:00  119.98  120.34  119.48  120.20  19992372\n",
      "2017-02-14 15:00:00  119.34  120.20  119.20  120.12  12987135\n",
      "2017-02-15 15:00:00  119.98  120.55  119.27  119.77  25687112\n",
      "2017-02-16 15:00:00  119.48  120.41  119.34  120.20  16325732\n",
      "2017-02-17 15:00:00  118.56  119.77  118.13  119.48  13863642\n",
      "2017-02-20 15:00:00  120.55  120.91  118.34  118.34  29915560\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  122.81  122.81  121.78  122.44  13475400\n",
      "2017-10-11 15:00:00  122.44  122.91  122.16  122.34   9654900\n",
      "2017-10-12 15:00:00  122.34  122.72  121.59  122.34   8363600\n",
      "2017-10-13 15:00:00  121.31  122.62  121.22  122.16  11271700\n",
      "2017-10-16 15:00:00  122.25  122.44  121.31  121.59  11832600\n",
      "2017-10-17 15:00:00  121.78  122.44  121.41  122.16   7934100\n",
      "2017-10-18 15:00:00  122.53  122.72  121.22  121.87  22599700\n",
      "2017-10-19 15:00:00  123.09  123.37  121.69  122.25  28931900\n",
      "2017-10-20 15:00:00  121.97  122.81  121.97  122.53   8716900\n",
      "2017-10-23 15:00:00  120.37  122.16  120.28  122.06  15590300\n",
      "2017-10-24 15:00:00  120.56  121.41  120.19  120.37  12571800\n",
      "2017-10-25 15:00:00  120.94  121.31  120.19  120.56  10200400\n",
      "2017-10-26 15:00:00  120.19  120.75  119.81  120.75  12938000\n",
      "2017-10-27 15:00:00  120.47  121.31  120.19  120.37  15482700\n",
      "2017-10-30 15:00:00  119.06  120.19  118.03  120.19  37086800\n",
      "2017-10-31 15:00:00  118.22  118.69  117.94  118.22   9330200\n",
      "2017-11-01 15:00:00  117.56  119.25  117.47  118.12  16948000\n",
      "2017-11-02 15:00:00  117.47  117.75  116.53  117.37  23219200\n",
      "2017-11-03 15:00:00  117.94  118.12  116.53  117.47  15786000\n",
      "2017-11-06 15:00:00  116.91  117.56  116.72  117.56   9785200\n",
      "2017-11-07 15:00:00  117.56  118.12  116.34  116.91  19003800\n",
      "2017-11-08 15:00:00  117.94  118.87  117.19  117.47  18500100\n",
      "2017-11-09 15:00:00  117.66  118.41  117.47  117.84   8739900\n",
      "2017-11-10 15:00:00  118.41  118.41  116.81  117.56  24748600\n",
      "2017-11-13 15:00:00  120.00  120.47  118.41  118.59  41250100\n",
      "2017-11-14 15:00:00  118.12  119.72  117.94  119.62  17172100\n",
      "2017-11-15 15:00:00  118.12  118.41  117.66  117.84  14029600\n",
      "2017-11-16 15:00:00  116.16  117.75  116.06  117.75  18042800\n",
      "2017-11-17 15:00:00  119.81  120.00  116.25  116.25  53475100\n",
      "2017-11-20 15:00:00  120.47  120.56  118.22  118.97  29413900\n",
      "\n",
      "[215 rows x 5 columns]), ('600016.XSHG',                       close    high     low    open     volume\n",
      "datetime                                                      \n",
      "2017-01-03 15:00:00  135.93  136.67  135.03  135.48   58351289\n",
      "2017-01-04 15:00:00  135.93  136.08  134.88  135.78   73120372\n",
      "2017-01-05 15:00:00  135.63  136.08  135.33  135.93   56243309\n",
      "2017-01-06 15:00:00  134.58  135.63  134.44  135.48   55725253\n",
      "2017-01-09 15:00:00  134.73  134.88  133.99  134.29   49094801\n",
      "2017-01-10 15:00:00  134.73  135.03  134.44  134.44   38942271\n",
      "2017-01-11 15:00:00  134.14  135.03  133.99  134.73   38822892\n",
      "2017-01-12 15:00:00  134.29  134.73  133.99  134.29   22501184\n",
      "2017-01-13 15:00:00  135.48  135.78  133.99  134.14   59000703\n",
      "2017-01-16 15:00:00  136.97  138.31  133.84  135.33  196314955\n",
      "2017-01-17 15:00:00  136.52  137.12  136.23  136.67   31710744\n",
      "2017-01-18 15:00:00  137.12  137.27  136.23  136.82   23076975\n",
      "2017-01-19 15:00:00  136.97  138.17  136.37  136.52   24704834\n",
      "2017-01-20 15:00:00  137.27  137.87  136.52  136.97   27038313\n",
      "2017-01-23 15:00:00  137.57  138.17  137.12  137.87   23741568\n",
      "2017-01-24 15:00:00  138.31  138.61  137.42  137.57   27881495\n",
      "2017-01-25 15:00:00  137.57  138.17  137.27  137.87   16776054\n",
      "2017-01-26 15:00:00  137.87  138.61  137.72  137.72   19569744\n",
      "2017-02-03 15:00:00  136.97  138.46  136.82  138.46   24803969\n",
      "2017-02-06 15:00:00  136.82  137.72  136.52  137.42   42565220\n",
      "2017-02-07 15:00:00  136.37  137.12  135.78  136.67   42115167\n",
      "2017-02-08 15:00:00  136.23  136.37  135.18  135.93   39678117\n",
      "2017-02-09 15:00:00  136.08  136.52  135.63  136.08   45952900\n",
      "2017-02-10 15:00:00  136.08  136.37  135.48  136.23   97265021\n",
      "2017-02-13 15:00:00  136.52  136.97  135.78  136.08  102536449\n",
      "2017-02-14 15:00:00  135.63  136.52  135.48  136.37   64754799\n",
      "2017-02-15 15:00:00  136.52  136.97  135.48  135.93  144280519\n",
      "2017-02-16 15:00:00  135.93  136.82  135.78  136.37   95448996\n",
      "2017-02-17 15:00:00  134.88  136.37  134.73  136.08  107443137\n",
      "2017-02-20 15:00:00  136.37  136.52  134.73  134.88  157638214\n",
      "...                     ...     ...     ...     ...        ...\n",
      "2017-10-10 15:00:00  121.75  121.75  121.16  121.16   29819100\n",
      "2017-10-11 15:00:00  122.20  122.50  121.60  121.75   28391000\n",
      "2017-10-12 15:00:00  121.75  122.35  121.60  122.05   25652800\n",
      "2017-10-13 15:00:00  121.90  122.20  121.75  121.90   14016900\n",
      "2017-10-16 15:00:00  121.75  122.50  121.45  121.90   26761700\n",
      "2017-10-17 15:00:00  121.45  122.05  121.30  121.90   14803400\n",
      "2017-10-18 15:00:00  121.30  121.75  121.30  121.45   22187900\n",
      "2017-10-19 15:00:00  120.41  121.60  120.26  121.30   34053600\n",
      "2017-10-20 15:00:00  120.41  120.56  120.11  120.41   17028300\n",
      "2017-10-23 15:00:00  120.11  120.56  119.96  120.56   19176900\n",
      "2017-10-24 15:00:00  120.86  121.30  120.11  120.11   29919200\n",
      "2017-10-25 15:00:00  120.86  121.30  120.71  121.01   15880800\n",
      "2017-10-26 15:00:00  121.16  121.45  120.71  121.01   30167200\n",
      "2017-10-27 15:00:00  122.05  122.80  121.01  121.01   37093400\n",
      "2017-10-30 15:00:00  121.90  122.80  121.01  122.35   44294900\n",
      "2017-10-31 15:00:00  123.69  125.18  121.60  122.20   69033800\n",
      "2017-11-01 15:00:00  122.95  123.39  122.50  123.10   38497000\n",
      "2017-11-02 15:00:00  122.65  123.10  120.56  122.80   70693800\n",
      "2017-11-03 15:00:00  123.10  123.39  121.30  121.90   61739700\n",
      "2017-11-06 15:00:00  123.24  123.24  122.05  122.65   35767700\n",
      "2017-11-07 15:00:00  124.74  124.89  122.50  123.10   56719500\n",
      "2017-11-08 15:00:00  125.33  125.63  124.29  124.74   69077100\n",
      "2017-11-09 15:00:00  124.89  126.08  124.74  125.18   41141700\n",
      "2017-11-10 15:00:00  125.48  125.48  124.59  124.89   50606000\n",
      "2017-11-13 15:00:00  126.08  127.72  125.48  126.97  100677500\n",
      "2017-11-14 15:00:00  125.93  126.08  124.29  125.78   69650400\n",
      "2017-11-15 15:00:00  124.74  125.78  124.14  125.33   56386900\n",
      "2017-11-16 15:00:00  123.54  124.44  123.39  124.29   29555900\n",
      "2017-11-17 15:00:00  127.42  127.57  123.10  123.10  118100600\n",
      "2017-11-20 15:00:00  128.17  128.77  125.93  126.53   85741900\n",
      "\n",
      "[215 rows x 5 columns]), ('600028.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  10.94  10.96  10.73  10.77  102815710\n",
      "2017-01-04 15:00:00  11.06  11.10  10.84  10.88  100776181\n",
      "2017-01-05 15:00:00  11.42  11.54  11.00  11.02  238696195\n",
      "2017-01-06 15:00:00  11.64  11.94  11.40  11.48  328610278\n",
      "2017-01-09 15:00:00  11.64  11.98  11.58  11.66  208411605\n",
      "2017-01-10 15:00:00  11.72  11.74  11.40  11.52  128561870\n",
      "2017-01-11 15:00:00  11.44  11.74  11.44  11.64  113641256\n",
      "2017-01-12 15:00:00  11.58  11.74  11.40  11.48  147010014\n",
      "2017-01-13 15:00:00  11.68  11.86  11.48  11.56  131011620\n",
      "2017-01-16 15:00:00  11.84  11.88  11.58  11.70  255346046\n",
      "2017-01-17 15:00:00  11.90  12.06  11.80  11.80  196012021\n",
      "2017-01-18 15:00:00  11.86  11.96  11.78  11.92  105178283\n",
      "2017-01-19 15:00:00  11.64  11.84  11.46  11.80  227101241\n",
      "2017-01-20 15:00:00  11.66  11.68  11.52  11.56   77266346\n",
      "2017-01-23 15:00:00  11.68  11.72  11.54  11.66  120755318\n",
      "2017-01-24 15:00:00  12.04  12.06  11.62  11.66  220286860\n",
      "2017-01-25 15:00:00  12.02  12.08  11.88  12.00   99007984\n",
      "2017-01-26 15:00:00  11.98  12.10  11.86  12.02   88278289\n",
      "2017-02-03 15:00:00  11.82  12.00  11.72  11.98   59129160\n",
      "2017-02-06 15:00:00  11.82  11.90  11.70  11.82   91669407\n",
      "2017-02-07 15:00:00  11.64  11.80  11.58  11.76  119009811\n",
      "2017-02-08 15:00:00  11.64  11.68  11.50  11.58  145172865\n",
      "2017-02-09 15:00:00  11.56  11.62  11.40  11.62  297648217\n",
      "2017-02-10 15:00:00  11.66  11.68  11.46  11.50  195616383\n",
      "2017-02-13 15:00:00  11.66  11.78  11.60  11.68  171441064\n",
      "2017-02-14 15:00:00  11.60  11.66  11.54  11.62   89132705\n",
      "2017-02-15 15:00:00  11.62  11.70  11.58  11.62  126868773\n",
      "2017-02-16 15:00:00  11.54  11.62  11.48  11.60  119104863\n",
      "2017-02-17 15:00:00  11.50  11.64  11.48  11.54  104112488\n",
      "2017-02-20 15:00:00  11.68  11.68  11.48  11.52  150441810\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  11.62  11.68  11.58  11.66   32963600\n",
      "2017-10-11 15:00:00  11.64  11.66  11.60  11.64   28671100\n",
      "2017-10-12 15:00:00  11.56  11.64  11.52  11.62   39935700\n",
      "2017-10-13 15:00:00  11.54  11.54  11.46  11.52   37999200\n",
      "2017-10-16 15:00:00  11.54  11.56  11.48  11.54   44761800\n",
      "2017-10-17 15:00:00  11.56  11.60  11.52  11.56   26122800\n",
      "2017-10-18 15:00:00  11.72  11.74  11.54  11.56   77196500\n",
      "2017-10-19 15:00:00  11.76  11.76  11.62  11.68   67757000\n",
      "2017-10-20 15:00:00  11.64  11.72  11.62  11.68   24583500\n",
      "2017-10-23 15:00:00  11.62  11.66  11.56  11.64   25774800\n",
      "2017-10-24 15:00:00  11.76  11.80  11.58  11.60   69603400\n",
      "2017-10-25 15:00:00  11.74  11.80  11.68  11.78   37222500\n",
      "2017-10-26 15:00:00  11.70  11.74  11.62  11.74   49063500\n",
      "2017-10-27 15:00:00  11.66  11.72  11.62  11.72   34555300\n",
      "2017-10-30 15:00:00  11.90  11.94  11.66  11.70  115187900\n",
      "2017-10-31 15:00:00  11.86  11.92  11.80  11.92   56979300\n",
      "2017-11-01 15:00:00  12.14  12.18  11.86  11.88  148525400\n",
      "2017-11-02 15:00:00  12.16  12.24  12.06  12.08   84569300\n",
      "2017-11-03 15:00:00  12.22  12.28  12.04  12.18  118974800\n",
      "2017-11-06 15:00:00  12.31  12.49  12.24  12.31  123065400\n",
      "2017-11-07 15:00:00  12.49  12.71  12.37  12.43  182445700\n",
      "2017-11-08 15:00:00  12.35  12.47  12.28  12.45  107714400\n",
      "2017-11-09 15:00:00  12.37  12.37  12.24  12.29   56689200\n",
      "2017-11-10 15:00:00  12.10  12.41  12.08  12.35  105204300\n",
      "2017-11-13 15:00:00  12.16  12.20  12.04  12.14   88736700\n",
      "2017-11-14 15:00:00  12.06  12.20  12.02  12.14   57014700\n",
      "2017-11-15 15:00:00  11.82  12.00  11.78  11.96  124386800\n",
      "2017-11-16 15:00:00  11.76  11.88  11.72  11.78   59124700\n",
      "2017-11-17 15:00:00  11.92  11.96  11.70  11.76  123692800\n",
      "2017-11-20 15:00:00  11.92  12.00  11.82  11.86   64670000\n",
      "\n",
      "[215 rows x 5 columns]), ('600029.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  11.64  11.69  11.54  11.55   26749400\n",
      "2017-01-04 15:00:00  11.72  11.75  11.55  11.62   45710506\n",
      "2017-01-05 15:00:00  11.80  11.93  11.77  11.82   56905338\n",
      "2017-01-06 15:00:00  11.80  11.92  11.77  11.82   42445959\n",
      "2017-01-09 15:00:00  11.85  11.93  11.65  11.77   41821281\n",
      "2017-01-10 15:00:00  12.73  13.04  11.77  11.80  346225902\n",
      "2017-01-11 15:00:00  12.13  12.50  12.08  12.38  233991787\n",
      "2017-01-12 15:00:00  11.98  12.13  11.93  12.08   90647970\n",
      "2017-01-13 15:00:00  11.97  12.08  11.92  11.97   79221712\n",
      "2017-01-16 15:00:00  12.02  12.12  11.75  12.02  110640920\n",
      "2017-01-17 15:00:00  11.97  12.02  11.74  11.95   53969652\n",
      "2017-01-18 15:00:00  12.03  12.18  11.95  12.00   74535719\n",
      "2017-01-19 15:00:00  11.98  12.15  11.90  11.97   46340714\n",
      "2017-01-20 15:00:00  12.03  12.10  11.93  11.95   42929824\n",
      "2017-01-23 15:00:00  12.17  12.22  12.02  12.03   48898730\n",
      "2017-01-24 15:00:00  12.18  12.20  12.07  12.17   35647109\n",
      "2017-01-25 15:00:00  12.22  12.25  12.12  12.12   41192883\n",
      "2017-01-26 15:00:00  12.08  12.23  12.02  12.22   57074034\n",
      "2017-02-03 15:00:00  12.03  12.13  11.98  12.07   25940965\n",
      "2017-02-06 15:00:00  11.89  12.03  11.75  12.02   86849669\n",
      "2017-02-07 15:00:00  11.89  11.90  11.82  11.84   37250692\n",
      "2017-02-08 15:00:00  11.95  12.00  11.84  11.89   46333598\n",
      "2017-02-09 15:00:00  11.98  12.03  11.92  11.95   65151228\n",
      "2017-02-10 15:00:00  12.15  12.17  11.93  12.00  104405867\n",
      "2017-02-13 15:00:00  12.20  12.25  12.05  12.10   93942073\n",
      "2017-02-14 15:00:00  12.18  12.33  12.15  12.23   82076654\n",
      "2017-02-15 15:00:00  12.30  12.94  12.18  12.20  171391771\n",
      "2017-02-16 15:00:00  12.48  12.56  12.23  12.28  122694512\n",
      "2017-02-17 15:00:00  12.30  12.63  12.23  12.46  111556469\n",
      "2017-02-20 15:00:00  12.68  12.79  12.30  12.31  141170127\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  13.65  13.70  13.59  13.67   15492000\n",
      "2017-10-11 15:00:00  13.67  13.77  13.62  13.63   15555200\n",
      "2017-10-12 15:00:00  13.52  13.68  13.45  13.68   17959900\n",
      "2017-10-13 15:00:00  13.57  13.57  13.45  13.50   11328800\n",
      "2017-10-16 15:00:00  13.47  13.60  13.44  13.50   20595400\n",
      "2017-10-17 15:00:00  13.32  13.49  13.30  13.45   17865700\n",
      "2017-10-18 15:00:00  13.44  13.47  13.29  13.30   20601600\n",
      "2017-10-19 15:00:00  13.55  13.55  13.35  13.39   16498500\n",
      "2017-10-20 15:00:00  13.65  13.73  13.49  13.50   15825100\n",
      "2017-10-23 15:00:00  13.68  13.73  13.55  13.68   10644200\n",
      "2017-10-24 15:00:00  13.85  13.87  13.60  13.68   24210400\n",
      "2017-10-25 15:00:00  13.82  13.90  13.75  13.80   13983600\n",
      "2017-10-26 15:00:00  13.83  13.93  13.75  13.80   20431900\n",
      "2017-10-27 15:00:00  14.11  14.34  13.78  13.87   42619200\n",
      "2017-10-30 15:00:00  14.25  14.43  14.03  14.20   39022300\n",
      "2017-10-31 15:00:00  14.39  14.53  14.15  14.36   37462300\n",
      "2017-11-01 15:00:00  15.10  15.19  14.41  14.44   94550400\n",
      "2017-11-02 15:00:00  15.15  15.76  15.05  15.30   77065900\n",
      "2017-11-03 15:00:00  15.22  15.29  14.82  15.05   46433900\n",
      "2017-11-06 15:00:00  14.97  15.15  14.69  15.14   40965000\n",
      "2017-11-07 15:00:00  14.89  15.10  14.69  14.79   51390000\n",
      "2017-11-08 15:00:00  14.99  15.09  14.72  14.84   40682700\n",
      "2017-11-09 15:00:00  14.71  14.89  14.51  14.86   32921000\n",
      "2017-11-10 15:00:00  15.07  15.12  14.56  14.71   54910000\n",
      "2017-11-13 15:00:00  15.35  15.52  14.81  15.00   58973600\n",
      "2017-11-14 15:00:00  16.00  16.26  15.14  15.20   73045100\n",
      "2017-11-15 15:00:00  16.04  16.64  15.83  15.85   61735000\n",
      "2017-11-16 15:00:00  16.29  16.62  15.68  16.04   44111500\n",
      "2017-11-17 15:00:00  16.97  17.66  16.13  16.13   75547100\n",
      "2017-11-20 15:00:00  17.05  17.55  16.42  17.07   49395200\n",
      "\n",
      "[212 rows x 5 columns]), ('600030.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  61.83  61.98  61.25  61.41   62299748\n",
      "2017-01-04 15:00:00  61.94  62.13  61.60  61.79   51671672\n",
      "2017-01-05 15:00:00  61.64  62.09  61.56  62.02   47861389\n",
      "2017-01-06 15:00:00  61.14  61.75  61.06  61.75   51664011\n",
      "2017-01-09 15:00:00  61.41  61.56  60.99  61.14   39824935\n",
      "2017-01-10 15:00:00  61.48  61.90  61.18  61.22   45374066\n",
      "2017-01-11 15:00:00  61.52  62.02  61.48  61.64   39875510\n",
      "2017-01-12 15:00:00  61.67  62.17  61.44  61.52   55959182\n",
      "2017-01-13 15:00:00  61.94  62.44  61.18  61.64   82487638\n",
      "2017-01-16 15:00:00  62.44  62.74  61.18  61.79  172059479\n",
      "2017-01-17 15:00:00  62.09  62.32  61.56  62.09   45559832\n",
      "2017-01-18 15:00:00  62.09  62.74  61.79  61.90   48042608\n",
      "2017-01-19 15:00:00  62.17  62.59  61.98  61.98   39826494\n",
      "2017-01-20 15:00:00  62.70  62.74  62.06  62.17   63151972\n",
      "2017-01-23 15:00:00  62.82  63.35  62.63  62.63   47492145\n",
      "2017-01-24 15:00:00  62.55  62.86  62.44  62.86   40236933\n",
      "2017-01-25 15:00:00  62.55  62.59  62.32  62.55   32214153\n",
      "2017-01-26 15:00:00  62.93  63.24  62.74  62.74   46822871\n",
      "2017-02-03 15:00:00  62.51  63.20  62.48  63.20   27278298\n",
      "2017-02-06 15:00:00  62.40  62.74  62.09  62.67   44772227\n",
      "2017-02-07 15:00:00  62.25  62.48  62.02  62.36   31782402\n",
      "2017-02-08 15:00:00  63.12  63.39  61.83  62.21   79992911\n",
      "2017-02-09 15:00:00  63.05  63.62  62.82  62.90   64756663\n",
      "2017-02-10 15:00:00  63.66  64.00  63.05  63.05   80275242\n",
      "2017-02-13 15:00:00  63.77  64.27  63.58  63.74   74870190\n",
      "2017-02-14 15:00:00  63.51  64.19  63.28  63.96   60529946\n",
      "2017-02-15 15:00:00  63.24  64.04  63.12  63.51   60121453\n",
      "2017-02-16 15:00:00  63.89  63.93  63.05  63.24   66816149\n",
      "2017-02-17 15:00:00  63.66  65.22  63.47  64.04  121070921\n",
      "2017-02-20 15:00:00  64.54  64.58  63.32  63.66   94231932\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  69.62  69.65  68.66  69.23   32993600\n",
      "2017-10-11 15:00:00  68.93  69.58  68.78  69.50   31736000\n",
      "2017-10-12 15:00:00  68.74  69.12  68.47  68.93   25135300\n",
      "2017-10-13 15:00:00  68.74  69.12  68.47  68.81   23640400\n",
      "2017-10-16 15:00:00  68.62  69.58  68.55  68.85   43820400\n",
      "2017-10-17 15:00:00  68.36  68.89  68.28  68.55   20378400\n",
      "2017-10-18 15:00:00  68.93  69.01  67.94  68.55   48011200\n",
      "2017-10-19 15:00:00  67.94  68.74  67.82  68.74   31682000\n",
      "2017-10-20 15:00:00  67.90  68.36  67.52  67.67   21019500\n",
      "2017-10-23 15:00:00  67.13  67.94  67.06  67.90   24558800\n",
      "2017-10-24 15:00:00  67.94  68.13  66.98  67.10   30098100\n",
      "2017-10-25 15:00:00  68.17  68.39  67.71  67.94   22143200\n",
      "2017-10-26 15:00:00  68.43  68.89  67.63  68.09   38156400\n",
      "2017-10-27 15:00:00  68.20  68.51  67.94  68.36   23840500\n",
      "2017-10-30 15:00:00  66.71  68.09  65.68  67.94   52047200\n",
      "2017-10-31 15:00:00  66.14  66.75  65.87  66.45   27261000\n",
      "2017-11-01 15:00:00  65.76  66.94  65.64  66.29   31192200\n",
      "2017-11-02 15:00:00  65.80  66.06  64.84  65.91   50189900\n",
      "2017-11-03 15:00:00  65.95  65.99  64.69  65.68   38081700\n",
      "2017-11-06 15:00:00  65.42  65.64  64.88  65.42   22288000\n",
      "2017-11-07 15:00:00  66.91  67.10  65.49  65.80   52327400\n",
      "2017-11-08 15:00:00  69.16  70.72  66.75  66.94  127297400\n",
      "2017-11-09 15:00:00  69.81  69.96  68.74  68.85   69224800\n",
      "2017-11-10 15:00:00  70.23  70.53  69.08  69.96   80211300\n",
      "2017-11-13 15:00:00  69.65  71.03  69.43  70.15   58826700\n",
      "2017-11-14 15:00:00  69.27  69.85  68.70  69.81   53138900\n",
      "2017-11-15 15:00:00  69.04  69.73  68.55  69.16   51847900\n",
      "2017-11-16 15:00:00  68.05  69.20  67.90  68.89   44417200\n",
      "2017-11-17 15:00:00  69.88  70.00  68.13  68.36  113025400\n",
      "2017-11-20 15:00:00  67.71  69.54  66.52  69.23   83231000\n",
      "\n",
      "[215 rows x 5 columns]), ('600036.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00   69.31   69.39   67.80   67.92  30449820\n",
      "2017-01-04 15:00:00   69.42   69.89   68.88   69.08  25665746\n",
      "2017-01-05 15:00:00   69.85   70.27   69.58   69.66  24562635\n",
      "2017-01-06 15:00:00   69.35   70.08   69.31   69.85  17487854\n",
      "2017-01-09 15:00:00   69.23   69.96   69.12   69.66  17341504\n",
      "2017-01-10 15:00:00   69.23   69.81   69.12   69.27  10668237\n",
      "2017-01-11 15:00:00   69.27   69.73   69.19   69.58  13428968\n",
      "2017-01-12 15:00:00   69.46   69.96   69.23   69.27  14095858\n",
      "2017-01-13 15:00:00   70.27   70.93   69.39   69.46  25113771\n",
      "2017-01-16 15:00:00   71.62   71.74   70.08   70.16  75103166\n",
      "2017-01-17 15:00:00   71.20   71.74   71.12   71.39  23566010\n",
      "2017-01-18 15:00:00   71.74   71.82   71.28   71.35  17879565\n",
      "2017-01-19 15:00:00   71.47   72.32   71.43   71.59  13110922\n",
      "2017-01-20 15:00:00   71.66   71.97   71.28   71.55  21739051\n",
      "2017-01-23 15:00:00   71.39   72.40   71.04   72.09  19875392\n",
      "2017-01-24 15:00:00   72.78   72.86   71.39   71.74  25543630\n",
      "2017-01-25 15:00:00   72.86   73.13   72.09   72.59  15272178\n",
      "2017-01-26 15:00:00   73.32   74.29   72.63   72.94  27318666\n",
      "2017-02-03 15:00:00   72.20   73.63   72.01   73.63  23302810\n",
      "2017-02-06 15:00:00   71.78   72.94   71.55   72.86  23996219\n",
      "2017-02-07 15:00:00   71.70   72.09   71.59   71.89  22940249\n",
      "2017-02-08 15:00:00   71.78   71.78   71.31   71.59  19599726\n",
      "2017-02-09 15:00:00   72.36   73.05   71.74   71.74  22249868\n",
      "2017-02-10 15:00:00   72.94   73.21   72.28   72.78  39642313\n",
      "2017-02-13 15:00:00   73.24   73.67   72.90   72.94  25320767\n",
      "2017-02-14 15:00:00   72.78   73.44   72.59   73.32  23787741\n",
      "2017-02-15 15:00:00   73.82   74.21   72.94   73.21  59678978\n",
      "2017-02-16 15:00:00   73.82   74.63   73.48   74.05  35223424\n",
      "2017-02-17 15:00:00   73.40   74.21   73.24   74.05  17980208\n",
      "2017-02-20 15:00:00   74.94   75.25   73.24   73.44  44607085\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  104.23  105.82  101.47  103.95  51590600\n",
      "2017-10-11 15:00:00  103.91  104.75  103.39  103.95  23650400\n",
      "2017-10-12 15:00:00  105.23  105.90  103.95  104.35  23267400\n",
      "2017-10-13 15:00:00  104.55  105.74  104.39  105.34  16395500\n",
      "2017-10-16 15:00:00  107.22  107.54  104.55  105.07  34795900\n",
      "2017-10-17 15:00:00  107.86  109.06  106.54  106.54  27227800\n",
      "2017-10-18 15:00:00  108.18  108.90  107.38  108.06  19014200\n",
      "2017-10-19 15:00:00  108.14  108.94  107.42  108.18  20272600\n",
      "2017-10-20 15:00:00  106.82  107.90  106.58  107.58  14128700\n",
      "2017-10-23 15:00:00  105.74  107.26  105.70  106.66  18036600\n",
      "2017-10-24 15:00:00  106.22  107.06  105.42  105.58  18542300\n",
      "2017-10-25 15:00:00  106.94  107.30  105.38  106.02  17211500\n",
      "2017-10-26 15:00:00  105.94  108.50  105.46  106.38  35886900\n",
      "2017-10-27 15:00:00  112.13  112.29  106.54  106.66  56214600\n",
      "2017-10-30 15:00:00  110.89  111.93  109.81  111.05  50826500\n",
      "2017-10-31 15:00:00  108.14  109.85  107.42  109.61  29707800\n",
      "2017-11-01 15:00:00  107.34  108.46  106.38  108.34  32890100\n",
      "2017-11-02 15:00:00  107.78  107.82  106.66  106.90  18322000\n",
      "2017-11-03 15:00:00  107.98  108.34  106.22  107.34  34042900\n",
      "2017-11-06 15:00:00  106.18  107.50  104.87  107.34  34867200\n",
      "2017-11-07 15:00:00  107.86  108.78  105.86  106.10  36048200\n",
      "2017-11-08 15:00:00  108.10  109.41  106.94  107.66  34603200\n",
      "2017-11-09 15:00:00  108.02  109.49  107.10  107.70  18438200\n",
      "2017-11-10 15:00:00  108.02  108.58  106.10  107.38  35885400\n",
      "2017-11-13 15:00:00  110.41  113.13  108.46  108.46  64037400\n",
      "2017-11-14 15:00:00  111.81  112.81  110.57  110.93  42886800\n",
      "2017-11-15 15:00:00  111.25  112.73  110.21  111.65  34028800\n",
      "2017-11-16 15:00:00  112.13  112.13  109.73  110.77  33138100\n",
      "2017-11-17 15:00:00  117.24  117.67  112.93  112.93  74014200\n",
      "2017-11-20 15:00:00  121.82  122.50  116.20  116.92  64388900\n",
      "\n",
      "[215 rows x 5 columns]), ('600048.XSHG',                       close    high     low    open     volume\n",
      "datetime                                                      \n",
      "2017-01-03 15:00:00  170.27  170.45  168.04  168.79   34924355\n",
      "2017-01-04 15:00:00  170.64  171.01  168.79  169.71   38400678\n",
      "2017-01-05 15:00:00  170.08  171.75  169.90  170.64   35343982\n",
      "2017-01-06 15:00:00  169.53  171.01  168.97  170.08   29979926\n",
      "2017-01-09 15:00:00  169.90  170.45  169.16  169.34   19811592\n",
      "2017-01-10 15:00:00  170.08  170.45  169.34  169.71   29608708\n",
      "2017-01-11 15:00:00  169.16  170.27  168.97  170.27   23281515\n",
      "2017-01-12 15:00:00  167.49  169.16  167.30  168.42   32029256\n",
      "2017-01-13 15:00:00  168.23  170.27  167.49  168.42   41298916\n",
      "2017-01-16 15:00:00  170.27  171.93  165.27  168.04  120603057\n",
      "2017-01-17 15:00:00  169.16  170.08  168.23  169.90   25788142\n",
      "2017-01-18 15:00:00  169.71  170.82  168.79  169.34   23022230\n",
      "2017-01-19 15:00:00  169.90  171.56  168.97  169.53   25835670\n",
      "2017-01-20 15:00:00  171.56  171.93  169.53  169.90   34451015\n",
      "2017-01-23 15:00:00  171.75  172.49  171.01  171.93   32685553\n",
      "2017-01-24 15:00:00  170.64  171.93  169.71  171.75   44676501\n",
      "2017-01-25 15:00:00  170.27  170.82  169.16  169.34   21285607\n",
      "2017-01-26 15:00:00  170.82  171.19  170.08  170.64   22763722\n",
      "2017-02-03 15:00:00  169.90  171.38  169.34  170.82   18700147\n",
      "2017-02-06 15:00:00  169.53  169.90  168.60  169.90   26964459\n",
      "2017-02-07 15:00:00  169.71  170.08  169.34  169.53   21541839\n",
      "2017-02-08 15:00:00  171.93  172.12  168.79  169.71   44698337\n",
      "2017-02-09 15:00:00  175.63  178.59  171.93  172.12   88002715\n",
      "2017-02-10 15:00:00  175.45  176.93  173.97  175.63   37728507\n",
      "2017-02-13 15:00:00  176.00  176.74  173.97  175.26   33376258\n",
      "2017-02-14 15:00:00  176.00  176.56  175.08  175.82   21436391\n",
      "2017-02-15 15:00:00  173.60  176.37  173.23  176.19   45361398\n",
      "2017-02-16 15:00:00  174.89  175.26  172.86  173.41   29937982\n",
      "2017-02-17 15:00:00  172.30  176.00  172.12  174.89   43957151\n",
      "2017-02-20 15:00:00  177.30  177.67  172.30  172.49   67052914\n",
      "...                     ...     ...     ...     ...        ...\n",
      "2017-10-10 15:00:00  199.75  202.99  198.60  201.85   39318800\n",
      "2017-10-11 15:00:00  199.36  202.04  198.03  200.13   39061100\n",
      "2017-10-12 15:00:00  197.07  199.56  195.35  199.56   38717800\n",
      "2017-10-13 15:00:00  196.12  198.22  195.74  197.07   29470500\n",
      "2017-10-16 15:00:00  194.40  197.26  194.21  197.07   26546500\n",
      "2017-10-17 15:00:00  195.16  195.74  193.64  194.40   20828500\n",
      "2017-10-18 15:00:00  195.74  196.12  194.40  194.97   20336000\n",
      "2017-10-19 15:00:00  195.93  197.84  194.78  195.93   29549000\n",
      "2017-10-20 15:00:00  198.03  198.03  195.16  195.93   21290200\n",
      "2017-10-23 15:00:00  200.32  201.27  196.88  198.22   33730100\n",
      "2017-10-24 15:00:00  206.24  207.77  201.08  203.95   63293800\n",
      "2017-10-25 15:00:00  207.38  212.92  206.43  206.62   49367600\n",
      "2017-10-26 15:00:00  203.18  209.10  201.85  206.62   55264600\n",
      "2017-10-27 15:00:00  203.18  208.53  200.70  204.33   63436000\n",
      "2017-10-30 15:00:00  205.67  205.67  201.08  202.99   65220700\n",
      "2017-10-31 15:00:00  207.96  208.53  203.76  206.05   50697900\n",
      "2017-11-01 15:00:00  205.67  213.88  204.52  208.72   89985400\n",
      "2017-11-02 15:00:00  206.81  207.96  203.57  204.71   42591700\n",
      "2017-11-03 15:00:00  203.57  206.81  199.17  206.24   51570200\n",
      "2017-11-06 15:00:00  198.22  202.99  196.50  202.04   40899800\n",
      "2017-11-07 15:00:00  199.36  201.08  197.26  198.98   40869700\n",
      "2017-11-08 15:00:00  200.13  202.42  198.22  198.22   34277600\n",
      "2017-11-09 15:00:00  202.99  203.57  199.75  200.13   26411300\n",
      "2017-11-10 15:00:00  199.36  204.33  198.41  204.14   41324400\n",
      "2017-11-13 15:00:00  197.07  200.89  196.31  199.36   41923700\n",
      "2017-11-14 15:00:00  199.75  200.89  194.78  196.31   39601400\n",
      "2017-11-15 15:00:00  204.52  204.90  198.03  198.41   48866900\n",
      "2017-11-16 15:00:00  218.27  218.27  204.33  204.52  131741600\n",
      "2017-11-17 15:00:00  224.00  224.38  216.36  217.89  128100300\n",
      "2017-11-20 15:00:00  224.19  224.38  216.93  222.09   65306700\n",
      "\n",
      "[215 rows x 5 columns]), ('600050.XSHG',                      close   high   low  open     volume\n",
      "datetime                                                \n",
      "2017-01-03 15:00:00   8.99   9.14  8.73  8.76  242291182\n",
      "2017-01-04 15:00:00   8.98   9.04  8.82  8.95  200960890\n",
      "2017-01-05 15:00:00   9.48   9.50  8.91  8.93  360200783\n",
      "2017-01-06 15:00:00   9.27   9.51  9.21  9.37  281319845\n",
      "2017-01-09 15:00:00   9.31   9.40  9.08  9.26  226362121\n",
      "2017-01-10 15:00:00   9.13   9.43  9.09  9.27  215168388\n",
      "2017-01-11 15:00:00   8.34   9.09  8.21  9.04  495678055\n",
      "2017-01-12 15:00:00   8.06   8.30  7.89  8.20  355817269\n",
      "2017-01-13 15:00:00   8.03   8.22  7.95  7.98  203917286\n",
      "2017-01-16 15:00:00   7.97   8.08  7.49  7.97  424075096\n",
      "2017-01-17 15:00:00   7.93   7.98  7.75  7.86  192407086\n",
      "2017-01-18 15:00:00   8.00   8.15  7.94  7.95  172834505\n",
      "2017-01-19 15:00:00   7.58   7.98  7.52  7.92  267161746\n",
      "2017-01-20 15:00:00   7.64   7.72  7.43  7.56  187056014\n",
      "2017-01-23 15:00:00   7.68   7.72  7.59  7.62  132404937\n",
      "2017-01-24 15:00:00   7.64   7.72  7.62  7.66  125013790\n",
      "2017-01-25 15:00:00   7.95   8.01  7.56  7.62  270528427\n",
      "2017-01-26 15:00:00   7.91   7.99  7.80  7.86  172185601\n",
      "2017-02-03 15:00:00   7.89   8.00  7.87  7.87  107861625\n",
      "2017-02-06 15:00:00   7.88   7.91  7.68  7.87  172975435\n",
      "2017-02-07 15:00:00   7.86   7.98  7.76  7.83  133634919\n",
      "2017-02-08 15:00:00   8.21   8.27  7.80  7.85  332565377\n",
      "2017-02-09 15:00:00   8.22   8.24  8.12  8.16  189751017\n",
      "2017-02-10 15:00:00   8.20   8.40  8.15  8.20  204190412\n",
      "2017-02-13 15:00:00   8.28   8.30  8.10  8.12  140538713\n",
      "2017-02-14 15:00:00   8.26   8.32  8.16  8.26  123744001\n",
      "2017-02-15 15:00:00   8.14   8.26  8.11  8.26  127670069\n",
      "2017-02-16 15:00:00   8.14   8.20  8.05  8.15  130119687\n",
      "2017-02-17 15:00:00   7.87   8.11  7.83  8.09  210428805\n",
      "2017-02-20 15:00:00   7.91   7.97  7.75  7.80  125274073\n",
      "...                    ...    ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   8.70   8.84  8.64  8.79  162456800\n",
      "2017-10-11 15:00:00   8.64   8.70  8.56  8.68  133459300\n",
      "2017-10-12 15:00:00   8.85   8.96  8.63  8.70  191269600\n",
      "2017-10-13 15:00:00   8.76   8.81  8.73  8.80   87707600\n",
      "2017-10-16 15:00:00   8.72   8.92  8.70  8.81   97031200\n",
      "2017-10-17 15:00:00   8.72   8.75  8.64  8.68   59643800\n",
      "2017-10-18 15:00:00   8.66   8.76  8.63  8.73   65895000\n",
      "2017-10-19 15:00:00   8.37   8.63  8.37  8.63  136186200\n",
      "2017-10-20 15:00:00   8.45   8.50  8.41  8.45   70756800\n",
      "2017-10-23 15:00:00   8.61   8.64  8.43  8.49  115910000\n",
      "2017-10-24 15:00:00   8.53   8.59  8.47  8.58   65061500\n",
      "2017-10-25 15:00:00   8.56   8.64  8.49  8.52   58797800\n",
      "2017-10-26 15:00:00   8.62   8.64  8.52  8.53   89867300\n",
      "2017-10-27 15:00:00   8.88   9.09  8.72  8.72  310285400\n",
      "2017-10-30 15:00:00   9.25   9.25  8.76  8.91  345852800\n",
      "2017-10-31 15:00:00   9.24   9.28  9.09  9.16  176024200\n",
      "2017-11-01 15:00:00   9.43   9.57  9.19  9.26  271357400\n",
      "2017-11-02 15:00:00   9.25   9.51  9.19  9.43  188956300\n",
      "2017-11-03 15:00:00   9.02   9.24  8.91  9.21  181070100\n",
      "2017-11-06 15:00:00   9.15   9.16  8.87  9.05  155031700\n",
      "2017-11-07 15:00:00   9.63   9.65  9.15  9.16  328336900\n",
      "2017-11-08 15:00:00   9.50   9.71  9.47  9.59  228177200\n",
      "2017-11-09 15:00:00   9.90   9.94  9.45  9.51  289860800\n",
      "2017-11-10 15:00:00   9.97  10.01  9.83  9.88  234600300\n",
      "2017-11-13 15:00:00   9.96  10.01  9.84  9.95  164283500\n",
      "2017-11-14 15:00:00   9.49   9.91  9.44  9.91  278058200\n",
      "2017-11-15 15:00:00   9.68   9.82  9.43  9.45  196509900\n",
      "2017-11-16 15:00:00   9.61   9.68  9.44  9.61  138455500\n",
      "2017-11-17 15:00:00   9.63   9.96  9.59  9.66  272769100\n",
      "2017-11-20 15:00:00   9.80   9.82  9.37  9.45  214754300\n",
      "\n",
      "[120 rows x 5 columns]), ('600100.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  210.96  211.86  209.14  209.44  15917733\n",
      "2017-01-04 15:00:00  212.01  212.01  210.05  210.96  24225418\n",
      "2017-01-05 15:00:00  210.80  212.01  210.50  212.01  18340087\n",
      "2017-01-06 15:00:00  209.29  211.26  208.99  211.26  18490821\n",
      "2017-01-09 15:00:00  210.65  211.11  208.69  209.29  19874278\n",
      "2017-01-10 15:00:00  210.05  211.71  209.90  210.80  19831794\n",
      "2017-01-11 15:00:00  207.33  210.20  207.18  210.20  22673233\n",
      "2017-01-12 15:00:00  203.55  208.84  203.10  207.63  25180295\n",
      "2017-01-13 15:00:00  201.89  203.85  200.08  203.55  21595765\n",
      "2017-01-16 15:00:00  204.91  205.97  198.41  201.74  37848253\n",
      "2017-01-17 15:00:00  204.91  205.21  202.49  203.70  12527684\n",
      "2017-01-18 15:00:00  202.80  205.06  202.49  204.61  12981623\n",
      "2017-01-19 15:00:00  203.25  204.91  202.19  202.49  12793343\n",
      "2017-01-20 15:00:00  205.06  205.52  202.64  202.64  15600617\n",
      "2017-01-23 15:00:00  206.27  208.24  205.36  205.52  16392217\n",
      "2017-01-24 15:00:00  204.31  206.72  204.00  205.82  15111392\n",
      "2017-01-25 15:00:00  204.91  205.21  203.70  204.00   9944584\n",
      "2017-01-26 15:00:00  204.91  206.27  204.61  205.36  14577495\n",
      "2017-02-03 15:00:00  206.27  207.63  204.76  205.06  15138365\n",
      "2017-02-06 15:00:00  207.33  208.08  205.67  205.97  19025990\n",
      "2017-02-07 15:00:00  206.42  207.63  205.21  206.72  14580613\n",
      "2017-02-08 15:00:00  207.03  207.18  204.16  206.42  15556750\n",
      "2017-02-09 15:00:00  207.63  207.93  206.27  207.03  27941808\n",
      "2017-02-10 15:00:00  208.24  209.44  207.33  207.93  31204531\n",
      "2017-02-13 15:00:00  207.93  208.84  207.18  208.39  35412035\n",
      "2017-02-14 15:00:00  208.54  209.44  207.18  208.08  27148378\n",
      "2017-02-15 15:00:00  206.57  209.14  205.67  208.54  26448623\n",
      "2017-02-16 15:00:00  207.03  207.48  205.97  205.97  17508153\n",
      "2017-02-17 15:00:00  205.36  207.78  204.91  207.03  21277930\n",
      "2017-02-20 15:00:00  208.69  208.99  205.67  205.67  28034340\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  187.38  188.29  186.32  186.78  14276600\n",
      "2017-10-11 15:00:00  184.21  187.38  183.60  187.38  19631400\n",
      "2017-10-12 15:00:00  187.99  191.31  185.72  186.17  30776400\n",
      "2017-10-13 15:00:00  187.53  188.59  186.32  186.63  11407900\n",
      "2017-10-16 15:00:00  183.15  187.38  183.00  186.17  17581800\n",
      "2017-10-17 15:00:00  182.55  183.76  181.94  182.85   8986100\n",
      "2017-10-18 15:00:00  179.83  183.45  179.83  182.70  11057600\n",
      "2017-10-19 15:00:00  170.46  177.86  169.85  176.65  25997200\n",
      "2017-10-20 15:00:00  171.36  171.67  170.15  170.91   7739300\n",
      "2017-10-23 15:00:00  174.54  174.69  170.91  171.67  11206400\n",
      "2017-10-24 15:00:00  173.93  176.50  173.03  175.75   9688700\n",
      "2017-10-25 15:00:00  174.08  174.54  172.42  173.78   6796600\n",
      "2017-10-26 15:00:00  174.24  174.39  172.42  173.18   8881500\n",
      "2017-10-27 15:00:00  172.42  174.69  172.12  173.93   8692300\n",
      "2017-10-30 15:00:00  165.17  172.42  164.56  172.42  15022000\n",
      "2017-10-31 15:00:00  163.05  165.92  160.63  165.62  16267600\n",
      "2017-11-01 15:00:00  167.74  173.63  161.09  162.90  24139000\n",
      "2017-11-02 15:00:00  165.47  167.28  163.66  165.32  11719900\n",
      "2017-11-03 15:00:00  166.53  168.64  165.02  165.77   9693200\n",
      "2017-11-06 15:00:00  168.04  170.31  165.92  166.98   8669600\n",
      "2017-11-07 15:00:00  170.00  170.15  165.77  167.89  12754500\n",
      "2017-11-08 15:00:00  168.79  170.15  168.19  168.79  10859700\n",
      "2017-11-09 15:00:00  170.61  171.82  168.79  169.25  11046900\n",
      "2017-11-10 15:00:00  168.34  170.15  167.89  170.00  11328500\n",
      "2017-11-13 15:00:00  175.29  177.11  169.40  169.70  27095500\n",
      "2017-11-14 15:00:00  178.62  180.73  171.97  173.78  30157000\n",
      "2017-11-15 15:00:00  176.35  179.22  175.90  176.35  13213300\n",
      "2017-11-16 15:00:00  174.24  177.41  174.24  176.05   9749100\n",
      "2017-11-17 15:00:00  165.92  175.14  165.77  174.24  16558700\n",
      "2017-11-20 15:00:00  170.61  171.82  161.09  164.71  15284100\n",
      "\n",
      "[109 rows x 5 columns]), ('600104.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  141.29  143.71  139.39  139.39  36855207\n",
      "2017-01-04 15:00:00  143.71  144.89  141.29  141.76  33529297\n",
      "2017-01-05 15:00:00  142.17  144.19  141.64  144.19  20859375\n",
      "2017-01-06 15:00:00  141.41  142.88  140.64  142.17  22979601\n",
      "2017-01-09 15:00:00  142.88  143.24  141.46  141.52  25867270\n",
      "2017-01-10 15:00:00  142.00  143.12  141.76  142.82  17337268\n",
      "2017-01-11 15:00:00  141.17  142.35  140.58  142.29  18333284\n",
      "2017-01-12 15:00:00  141.64  142.59  141.17  141.29  23832507\n",
      "2017-01-13 15:00:00  142.82  143.24  140.40  141.41  24084587\n",
      "2017-01-16 15:00:00  145.84  148.21  142.12  143.36  57484957\n",
      "2017-01-17 15:00:00  146.43  147.26  144.01  145.19  16844204\n",
      "2017-01-18 15:00:00  147.79  147.91  145.49  145.55  21394536\n",
      "2017-01-19 15:00:00  148.98  149.15  147.20  147.20  20546684\n",
      "2017-01-20 15:00:00  149.03  152.35  148.92  149.15  26867283\n",
      "2017-01-23 15:00:00  147.56  151.99  146.79  149.63  37628717\n",
      "2017-01-24 15:00:00  147.79  148.68  146.37  147.38  22800105\n",
      "2017-01-25 15:00:00  150.04  150.22  146.73  147.32  18025552\n",
      "2017-01-26 15:00:00  149.80  150.81  149.33  150.04  13304504\n",
      "2017-02-03 15:00:00  148.44  150.22  147.85  149.63   8834386\n",
      "2017-02-06 15:00:00  150.22  152.11  149.03  149.33  24644429\n",
      "2017-02-07 15:00:00  150.57  152.17  150.10  150.28  14025143\n",
      "2017-02-08 15:00:00  148.86  150.28  147.67  150.10  20552873\n",
      "2017-02-09 15:00:00  148.27  149.63  147.26  149.09  25607979\n",
      "2017-02-10 15:00:00  148.86  149.03  146.55  147.38  31242424\n",
      "2017-02-13 15:00:00  146.96  149.03  146.79  148.15  50334011\n",
      "2017-02-14 15:00:00  147.02  147.56  146.20  147.08  20997047\n",
      "2017-02-15 15:00:00  147.08  148.38  146.25  146.96  24301793\n",
      "2017-02-16 15:00:00  146.08  147.44  145.07  147.44  25646092\n",
      "2017-02-17 15:00:00  147.26  148.09  145.78  146.14  23699873\n",
      "2017-02-20 15:00:00  150.34  151.05  147.26  147.32  51893615\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  190.18  196.11  186.81  194.92  30009000\n",
      "2017-10-11 15:00:00  197.98  198.54  191.49  191.49  26104600\n",
      "2017-10-12 15:00:00  200.29  201.35  196.86  198.98  12948100\n",
      "2017-10-13 15:00:00  199.41  203.34  198.79  200.10  10157600\n",
      "2017-10-16 15:00:00  199.66  201.78  196.23  200.66  11047800\n",
      "2017-10-17 15:00:00  196.54  200.16  196.42  199.35   8541400\n",
      "2017-10-18 15:00:00  203.78  204.40  196.79  196.79  16976800\n",
      "2017-10-19 15:00:00  205.71  206.65  202.78  204.09  13935400\n",
      "2017-10-20 15:00:00  203.16  205.90  201.97  204.59   6401400\n",
      "2017-10-23 15:00:00  202.03  205.78  201.47  204.96   6734600\n",
      "2017-10-24 15:00:00  204.59  205.53  201.66  202.10  10176500\n",
      "2017-10-25 15:00:00  204.96  205.71  202.91  204.84   7048400\n",
      "2017-10-26 15:00:00  201.41  209.83  200.85  204.28  16316000\n",
      "2017-10-27 15:00:00  202.28  203.34  198.85  201.10  10582400\n",
      "2017-10-30 15:00:00  204.84  205.21  200.41  202.84  11427000\n",
      "2017-10-31 15:00:00  196.42  204.84  196.36  204.84  20231100\n",
      "2017-11-01 15:00:00  191.68  197.23  190.56  197.04  24658900\n",
      "2017-11-02 15:00:00  191.87  192.93  191.24  192.12  10093400\n",
      "2017-11-03 15:00:00  192.68  192.86  189.37  192.12  13303000\n",
      "2017-11-06 15:00:00  192.86  194.30  190.74  191.99  15327000\n",
      "2017-11-07 15:00:00  195.61  200.60  193.18  193.36  28637700\n",
      "2017-11-08 15:00:00  195.67  197.85  193.49  195.80  15640900\n",
      "2017-11-09 15:00:00  196.11  197.48  193.80  196.36  12715300\n",
      "2017-11-10 15:00:00  202.41  203.72  196.54  197.73  24812500\n",
      "2017-11-13 15:00:00  202.72  205.15  201.03  204.90  17890100\n",
      "2017-11-14 15:00:00  204.03  207.46  201.97  203.65  15922400\n",
      "2017-11-15 15:00:00  202.78  203.78  198.98  202.91  15468700\n",
      "2017-11-16 15:00:00  200.97  201.85  199.29  201.53  10831700\n",
      "2017-11-17 15:00:00  207.21  207.33  199.48  202.41  23342900\n",
      "2017-11-20 15:00:00  206.46  207.27  202.10  205.90  17196600\n",
      "\n",
      "[215 rows x 5 columns]), ('600111.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  183.22  183.66  181.74  182.04  12894901\n",
      "2017-01-04 15:00:00  184.69  185.13  182.63  183.07  13007430\n",
      "2017-01-05 15:00:00  184.25  185.28  183.66  185.28  12527447\n",
      "2017-01-06 15:00:00  183.36  184.84  182.63  184.84  12252499\n",
      "2017-01-09 15:00:00  183.51  184.10  182.48  183.36   9798895\n",
      "2017-01-10 15:00:00  184.25  185.28  182.77  183.51  16256991\n",
      "2017-01-11 15:00:00  183.51  185.28  182.77  184.25  14557642\n",
      "2017-01-12 15:00:00  179.97  183.66  179.24  183.22  16234489\n",
      "2017-01-13 15:00:00  177.91  180.56  177.02  179.97  15882301\n",
      "2017-01-16 15:00:00  179.24  181.00  171.72  176.88  39199840\n",
      "2017-01-17 15:00:00  177.91  178.65  175.26  178.65   9585140\n",
      "2017-01-18 15:00:00  176.88  178.50  176.73  177.91   7306801\n",
      "2017-01-19 15:00:00  175.99  177.47  175.55  176.88   7910625\n",
      "2017-01-20 15:00:00  177.02  177.32  175.55  175.85   8135381\n",
      "2017-01-23 15:00:00  178.79  180.56  177.47  177.76  12564741\n",
      "2017-01-24 15:00:00  178.06  179.09  177.32  178.94   7475534\n",
      "2017-01-25 15:00:00  178.94  179.38  177.61  177.91   8190982\n",
      "2017-01-26 15:00:00  184.25  185.28  178.79  179.09  30595509\n",
      "2017-02-03 15:00:00  183.07  185.43  182.48  183.66  15364977\n",
      "2017-02-06 15:00:00  182.77  183.66  181.30  183.22  12366919\n",
      "2017-02-07 15:00:00  183.81  184.54  182.33  183.07  13248443\n",
      "2017-02-08 15:00:00  183.51  183.95  181.89  183.66  11281511\n",
      "2017-02-09 15:00:00  184.39  184.69  183.07  183.81  21625373\n",
      "2017-02-10 15:00:00  185.13  186.31  183.66  184.39  24664486\n",
      "2017-02-13 15:00:00  186.16  189.41  185.43  185.72  38051747\n",
      "2017-02-14 15:00:00  186.31  186.31  184.25  186.02  21167092\n",
      "2017-02-15 15:00:00  183.51  186.90  183.07  185.87  24221559\n",
      "2017-02-16 15:00:00  191.18  194.27  184.84  184.84  84608466\n",
      "2017-02-17 15:00:00  188.23  190.00  187.49  189.85  37688774\n",
      "2017-02-20 15:00:00  188.96  189.85  187.20  187.79  22429154\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  229.42  237.09  225.14  236.79  60260700\n",
      "2017-10-11 15:00:00  228.68  231.92  225.58  228.68  39108700\n",
      "2017-10-12 15:00:00  225.43  226.76  220.56  226.32  47779100\n",
      "2017-10-13 15:00:00  225.58  227.20  224.25  225.14  26912700\n",
      "2017-10-16 15:00:00  226.91  228.97  221.74  225.88  40893400\n",
      "2017-10-17 15:00:00  221.01  223.96  219.09  223.96  32598500\n",
      "2017-10-18 15:00:00  216.14  223.07  215.25  220.56  33392200\n",
      "2017-10-19 15:00:00  216.88  218.94  213.78  214.51  32980300\n",
      "2017-10-20 15:00:00  223.37  224.25  215.70  216.29  48335200\n",
      "2017-10-23 15:00:00  222.04  223.81  219.53  221.60  24036600\n",
      "2017-10-24 15:00:00  223.81  225.28  220.56  221.89  27933200\n",
      "2017-10-25 15:00:00  222.78  224.25  220.12  224.10  25240400\n",
      "2017-10-26 15:00:00  226.02  227.50  219.97  222.63  46633300\n",
      "2017-10-27 15:00:00  219.53  224.99  218.94  224.10  32903700\n",
      "2017-10-30 15:00:00  209.79  221.01  209.65  218.50  38145800\n",
      "2017-10-31 15:00:00  214.22  214.66  208.76  209.65  25109600\n",
      "2017-11-01 15:00:00  213.92  216.29  212.45  214.07  23862100\n",
      "2017-11-02 15:00:00  211.27  215.99  210.83  215.55  25204500\n",
      "2017-11-03 15:00:00  203.60  210.53  201.53  209.79  36798000\n",
      "2017-11-06 15:00:00  208.61  208.76  203.89  205.22  29563600\n",
      "2017-11-07 15:00:00  211.12  213.48  205.81  208.02  38429500\n",
      "2017-11-08 15:00:00  212.30  216.14  208.91  209.65  35037100\n",
      "2017-11-09 15:00:00  212.30  215.25  210.68  211.42  21893200\n",
      "2017-11-10 15:00:00  211.12  212.89  208.61  211.86  23694500\n",
      "2017-11-13 15:00:00  218.79  219.24  209.94  211.42  53112400\n",
      "2017-11-14 15:00:00  220.27  222.19  216.73  218.50  55992500\n",
      "2017-11-15 15:00:00  208.17  218.06  208.02  218.06  46411400\n",
      "2017-11-16 15:00:00  205.96  209.94  204.78  205.07  22540100\n",
      "2017-11-17 15:00:00  193.86  207.58  192.53  205.81  39885100\n",
      "2017-11-20 15:00:00  196.07  196.52  188.84  195.19  23845900\n",
      "\n",
      "[215 rows x 5 columns]), ('600340.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  298.85  300.23  296.48  299.10   6917735\n",
      "2017-01-04 15:00:00  302.86  305.24  300.36  305.24   9207000\n",
      "2017-01-05 15:00:00  303.86  306.11  302.36  302.98   4800610\n",
      "2017-01-06 15:00:00  302.36  304.99  301.61  304.24   4905880\n",
      "2017-01-09 15:00:00  309.49  310.62  302.86  302.86   8220009\n",
      "2017-01-10 15:00:00  306.61  309.99  305.74  307.87   3732909\n",
      "2017-01-11 15:00:00  302.86  306.36  302.36  306.36   4284579\n",
      "2017-01-12 15:00:00  301.86  305.99  301.23  302.61   5710237\n",
      "2017-01-13 15:00:00  303.61  304.49  299.73  302.86   5926465\n",
      "2017-01-16 15:00:00  308.49  309.12  300.23  302.86  15047733\n",
      "2017-01-17 15:00:00  306.99  307.87  304.74  307.87   3702855\n",
      "2017-01-18 15:00:00  307.11  309.74  305.36  306.11   5608531\n",
      "2017-01-19 15:00:00  303.36  307.24  301.48  304.24   4760066\n",
      "2017-01-20 15:00:00  304.99  307.24  301.73  301.73   4027584\n",
      "2017-01-23 15:00:00  299.10  305.11  297.35  304.24  13004692\n",
      "2017-01-24 15:00:00  298.10  300.98  297.98  298.98   5630760\n",
      "2017-01-25 15:00:00  300.61  301.23  297.48  297.60   5054979\n",
      "2017-01-26 15:00:00  303.99  304.74  299.86  300.73   7491379\n",
      "2017-02-03 15:00:00  303.99  304.99  302.61  303.86   2936724\n",
      "2017-02-06 15:00:00  305.74  306.61  302.98  303.23   4908146\n",
      "2017-02-07 15:00:00  303.49  306.24  301.73  305.11   4783057\n",
      "2017-02-08 15:00:00  303.99  304.61  301.98  303.23   5270251\n",
      "2017-02-09 15:00:00  317.75  319.13  303.36  303.99  21603675\n",
      "2017-02-10 15:00:00  321.51  328.39  316.88  317.38  21611318\n",
      "2017-02-13 15:00:00  318.75  325.26  318.25  322.13   8529570\n",
      "2017-02-14 15:00:00  321.76  324.51  317.25  318.75   6817891\n",
      "2017-02-15 15:00:00  319.00  326.64  318.50  321.63   7445950\n",
      "2017-02-16 15:00:00  322.13  324.89  319.25  319.25   5845322\n",
      "2017-02-17 15:00:00  324.01  327.26  322.01  322.26  11838567\n",
      "2017-02-20 15:00:00  332.27  336.65  325.14  325.39  19107752\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  391.59  396.44  385.98  396.18  17337200\n",
      "2017-10-11 15:00:00  391.59  394.91  390.70  392.10   9612800\n",
      "2017-10-12 15:00:00  395.03  396.82  390.32  392.23   7198200\n",
      "2017-10-13 15:00:00  397.33  398.35  394.27  394.65   7325100\n",
      "2017-10-16 15:00:00  393.12  399.37  391.46  398.86   8480600\n",
      "2017-10-17 15:00:00  396.69  398.22  391.85  394.14   6388700\n",
      "2017-10-18 15:00:00  395.03  399.75  394.40  397.97   7420000\n",
      "2017-10-19 15:00:00  388.40  394.14  387.26  394.14   8633400\n",
      "2017-10-20 15:00:00  390.70  391.08  386.24  387.38   4515800\n",
      "2017-10-23 15:00:00  392.48  393.50  388.91  391.34   5324500\n",
      "2017-10-24 15:00:00  396.44  396.95  391.08  393.12   7445700\n",
      "2017-10-25 15:00:00  397.58  401.54  395.54  396.95   6914500\n",
      "2017-10-26 15:00:00  396.82  397.58  394.91  397.46   6128900\n",
      "2017-10-27 15:00:00  393.50  395.54  393.12  395.03   6999700\n",
      "2017-10-30 15:00:00  393.63  394.14  386.49  394.14   9212600\n",
      "2017-10-31 15:00:00  392.48  394.78  391.21  394.65   5991000\n",
      "2017-11-01 15:00:00  393.89  398.73  390.44  390.95   8015200\n",
      "2017-11-02 15:00:00  394.27  394.78  388.53  394.40   7496900\n",
      "2017-11-03 15:00:00  393.89  394.65  387.51  393.50   8209600\n",
      "2017-11-06 15:00:00  389.30  392.10  387.77  391.97   6396600\n",
      "2017-11-07 15:00:00  386.49  390.19  385.22  389.68   8529100\n",
      "2017-11-08 15:00:00  388.79  391.97  386.36  387.00   7798900\n",
      "2017-11-09 15:00:00  388.02  389.17  386.36  388.91   5777800\n",
      "2017-11-10 15:00:00  388.28  390.83  384.58  387.64   9468900\n",
      "2017-11-13 15:00:00  389.42  390.95  385.60  389.42   8710100\n",
      "2017-11-14 15:00:00  400.01  402.81  388.66  388.79  16783800\n",
      "2017-11-15 15:00:00  399.88  403.58  396.95  397.84  11658400\n",
      "2017-11-16 15:00:00  400.64  402.68  397.97  399.88   8994400\n",
      "2017-11-17 15:00:00  410.72  410.85  401.15  401.79  19586100\n",
      "2017-11-20 15:00:00  405.49  412.50  400.39  411.36  13180000\n",
      "\n",
      "[212 rows x 5 columns]), ('600485.XSHG', Empty DataFrame\n",
      "Columns: []\n",
      "Index: []), ('600518.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  626.11  629.60  613.51  619.81  19199090\n",
      "2017-01-04 15:00:00  623.66  629.60  620.86  624.36  11587855\n",
      "2017-01-05 15:00:00  616.66  624.36  616.66  623.66   7521005\n",
      "2017-01-06 15:00:00  607.92  619.46  607.92  617.71  10798815\n",
      "2017-01-09 15:00:00  608.27  611.42  604.42  607.92   8546521\n",
      "2017-01-10 15:00:00  605.47  610.02  604.07  606.87   7558274\n",
      "2017-01-11 15:00:00  605.12  609.32  604.07  605.12   6690905\n",
      "2017-01-12 15:00:00  598.47  606.52  598.12  604.77   6528735\n",
      "2017-01-13 15:00:00  604.07  605.12  597.42  598.82   7828623\n",
      "2017-01-16 15:00:00  613.51  616.31  592.88  602.67  34188433\n",
      "2017-01-17 15:00:00  615.96  615.96  604.42  612.46   8721547\n",
      "2017-01-18 15:00:00  614.91  615.96  609.32  612.12   6402670\n",
      "2017-01-19 15:00:00  614.91  614.91  609.67  610.37   5843786\n",
      "2017-01-20 15:00:00  615.61  616.66  610.72  614.91  10471449\n",
      "2017-01-23 15:00:00  615.26  617.71  610.37  615.61   9684691\n",
      "2017-01-24 15:00:00  617.71  619.46  608.62  614.91  12107555\n",
      "2017-01-25 15:00:00  621.91  622.61  612.81  614.56   9915099\n",
      "2017-01-26 15:00:00  629.25  629.60  618.41  621.56  20861014\n",
      "2017-02-03 15:00:00  634.85  634.85  618.06  629.60  10549280\n",
      "2017-02-06 15:00:00  625.41  627.86  618.76  625.41  10138223\n",
      "2017-02-07 15:00:00  621.21  623.66  617.01  623.66   6039713\n",
      "2017-02-08 15:00:00  623.31  623.31  614.91  620.86  10870804\n",
      "2017-02-09 15:00:00  618.76  621.56  613.16  621.56  16695261\n",
      "2017-02-10 15:00:00  620.16  623.31  617.71  619.11  11515346\n",
      "2017-02-13 15:00:00  620.16  622.61  617.36  620.16  13047696\n",
      "2017-02-14 15:00:00  624.71  626.46  618.41  620.16  11863584\n",
      "2017-02-15 15:00:00  611.77  626.46  611.77  626.11  11353097\n",
      "2017-02-16 15:00:00  614.91  614.91  609.67  611.77   8617635\n",
      "2017-02-17 15:00:00  607.92  613.51  606.17  613.16   8560817\n",
      "2017-02-20 15:00:00  610.37  612.46  606.87  607.92  17588586\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  712.36  716.24  701.41  706.00   8730100\n",
      "2017-10-11 15:00:00  723.65  726.48  710.59  713.41  13078900\n",
      "2017-10-12 15:00:00  724.00  726.83  719.77  725.77   6219000\n",
      "2017-10-13 15:00:00  721.18  731.06  720.47  721.89   7554200\n",
      "2017-10-16 15:00:00  721.53  724.71  715.18  724.71   6359800\n",
      "2017-10-17 15:00:00  718.36  723.65  715.89  717.65   3787600\n",
      "2017-10-18 15:00:00  747.66  748.36  717.30  721.18  21615000\n",
      "2017-10-19 15:00:00  753.30  754.36  741.65  748.36  14418100\n",
      "2017-10-20 15:00:00  747.30  758.95  745.18  752.95   7519300\n",
      "2017-10-23 15:00:00  751.54  761.78  745.18  748.71   9948100\n",
      "2017-10-24 15:00:00  763.19  764.60  748.71  751.54  12018600\n",
      "2017-10-25 15:00:00  760.72  766.01  757.54  766.01   7720200\n",
      "2017-10-26 15:00:00  746.24  767.78  742.36  760.72  14487300\n",
      "2017-10-27 15:00:00  742.01  753.30  737.77  747.66  12096700\n",
      "2017-10-30 15:00:00  763.54  764.60  741.30  748.36  17585000\n",
      "2017-10-31 15:00:00  754.01  766.01  745.54  766.01  13269900\n",
      "2017-11-01 15:00:00  745.18  762.13  738.12  762.13  18122300\n",
      "2017-11-02 15:00:00  747.30  749.07  731.77  743.07   9156700\n",
      "2017-11-03 15:00:00  750.13  752.95  735.30  743.07  12289400\n",
      "2017-11-06 15:00:00  795.31  804.84  743.42  752.24  33141100\n",
      "2017-11-07 15:00:00  799.55  821.79  784.37  797.43  30541400\n",
      "2017-11-08 15:00:00  787.90  807.31  773.78  802.72  29005100\n",
      "2017-11-09 15:00:00  799.55  800.25  778.01  782.96  15984700\n",
      "2017-11-10 15:00:00  796.37  810.84  788.60  798.84  15695200\n",
      "2017-11-13 15:00:00  788.96  809.08  782.96  798.84  17684300\n",
      "2017-11-14 15:00:00  801.67  802.37  783.31  790.72  14580900\n",
      "2017-11-15 15:00:00  807.31  812.26  794.25  797.78  17154800\n",
      "2017-11-16 15:00:00  829.20  834.49  801.67  803.08  22330400\n",
      "2017-11-17 15:00:00  842.97  843.67  818.96  824.61  27649500\n",
      "2017-11-20 15:00:00  836.97  842.26  809.78  842.26  27341300\n",
      "\n",
      "[215 rows x 5 columns]), ('600519.XSHG',                        close     high      low     open   volume\n",
      "datetime                                                        \n",
      "2017-01-03 15:00:00  2078.80  2093.78  2067.74  2076.88  2071689\n",
      "2017-01-04 15:00:00  2186.35  2188.03  2078.86  2078.99  6525738\n",
      "2017-01-05 15:00:00  2155.78  2183.55  2146.21  2174.54  4170448\n",
      "2017-01-06 15:00:00  2180.14  2235.31  2150.31  2153.67  6809562\n",
      "2017-01-09 15:00:00  2165.23  2192.44  2153.05  2160.88  3540300\n",
      "2017-01-10 15:00:00  2169.33  2186.97  2153.42  2164.91  3172364\n",
      "2017-01-11 15:00:00  2147.21  2162.12  2134.16  2162.12  2359851\n",
      "2017-01-12 15:00:00  2156.59  2158.39  2140.44  2153.11  1777940\n",
      "2017-01-13 15:00:00  2141.99  2158.33  2136.52  2155.78  1828025\n",
      "2017-01-16 15:00:00  2118.94  2142.24  2104.96  2138.07  3676445\n",
      "2017-01-17 15:00:00  2169.70  2183.86  2124.84  2128.57  3517038\n",
      "2017-01-18 15:00:00  2206.73  2216.61  2157.21  2167.59  4600570\n",
      "2017-01-19 15:00:00  2203.50  2227.23  2185.11  2205.61  2850136\n",
      "2017-01-20 15:00:00  2205.42  2220.52  2193.37  2204.99  2133917\n",
      "2017-01-23 15:00:00  2181.07  2235.43  2171.19  2217.29  3257918\n",
      "2017-01-24 15:00:00  2174.54  2191.94  2154.35  2182.44  2683458\n",
      "2017-01-25 15:00:00  2157.83  2174.42  2150.94  2174.42  2298936\n",
      "2017-01-26 15:00:00  2139.50  2167.09  2120.49  2162.99  3782617\n",
      "2017-02-03 15:00:00  2155.22  2169.45  2143.48  2149.69  2093443\n",
      "2017-02-06 15:00:00  2154.91  2167.65  2143.23  2165.16  1567479\n",
      "2017-02-07 15:00:00  2135.46  2158.39  2131.92  2154.91  2051783\n",
      "2017-02-08 15:00:00  2138.76  2146.59  2129.00  2135.78  1908554\n",
      "2017-02-09 15:00:00  2161.44  2167.03  2141.06  2143.48  2332438\n",
      "2017-02-10 15:00:00  2144.10  2173.43  2143.48  2165.97  2405659\n",
      "2017-02-13 15:00:00  2174.11  2186.35  2124.34  2137.27  5357864\n",
      "2017-02-14 15:00:00  2175.91  2190.70  2168.95  2171.69  2655668\n",
      "2017-02-15 15:00:00  2165.91  2189.70  2157.15  2183.86  2624596\n",
      "2017-02-16 15:00:00  2162.74  2165.97  2146.65  2165.23  1764230\n",
      "2017-02-17 15:00:00  2177.65  2202.13  2159.01  2167.71  2908234\n",
      "2017-02-20 15:00:00  2248.17  2251.09  2174.61  2177.09  6184740\n",
      "...                      ...      ...      ...      ...      ...\n",
      "2017-10-10 15:00:00  3355.38  3356.94  3276.23  3276.73  1558300\n",
      "2017-10-11 15:00:00  3389.43  3423.98  3343.21  3352.09  1627300\n",
      "2017-10-12 15:00:00  3380.42  3398.88  3356.13  3386.08   964000\n",
      "2017-10-13 15:00:00  3455.35  3458.09  3367.50  3379.86  1388600\n",
      "2017-10-16 15:00:00  3483.56  3520.28  3454.42  3479.15  1462600\n",
      "2017-10-17 15:00:00  3458.95  3483.50  3444.17  3483.50  1040800\n",
      "2017-10-18 15:00:00  3483.74  3494.80  3448.14  3448.14   953300\n",
      "2017-10-19 15:00:00  3619.68  3635.53  3483.74  3486.66  2084300\n",
      "2017-10-20 15:00:00  3568.30  3603.53  3552.58  3602.91  1473100\n",
      "2017-10-23 15:00:00  3562.59  3603.53  3529.04  3576.82  1177500\n",
      "2017-10-24 15:00:00  3524.81  3565.01  3502.82  3553.83  1495600\n",
      "2017-10-25 15:00:00  3514.50  3550.72  3492.32  3540.16  1223000\n",
      "2017-10-26 15:00:00  3759.41  3808.56  3677.53  3727.79  5272700\n",
      "2017-10-27 15:00:00  4036.14  4068.76  3727.98  3740.90  4197800\n",
      "2017-10-30 15:00:00  3864.97  3998.99  3858.39  3995.26  3902900\n",
      "2017-10-31 15:00:00  3839.81  3898.34  3801.60  3863.86  2513200\n",
      "2017-11-01 15:00:00  3870.75  3923.44  3849.25  3856.96  2126000\n",
      "2017-11-02 15:00:00  3895.04  3912.25  3859.69  3894.92  1646800\n",
      "2017-11-03 15:00:00  3971.15  3997.25  3908.09  3908.59  2406700\n",
      "2017-11-06 15:00:00  4057.45  4085.60  3978.36  3988.74  2425100\n",
      "2017-11-07 15:00:00  3989.17  4082.86  3965.56  4038.32  2772300\n",
      "2017-11-08 15:00:00  4040.80  4066.09  3994.89  3994.95  2168200\n",
      "2017-11-09 15:00:00  4038.87  4064.22  4006.75  4031.61  1677100\n",
      "2017-11-10 15:00:00  4212.09  4244.40  4047.32  4047.32  3711800\n",
      "2017-11-13 15:00:00  4273.79  4303.11  4199.98  4224.21  2478400\n",
      "2017-11-14 15:00:00  4217.06  4269.56  4208.37  4267.08  2286600\n",
      "2017-11-15 15:00:00  4275.03  4286.34  4189.10  4212.40  2341500\n",
      "2017-11-16 15:00:00  4467.82  4472.11  4268.32  4268.32  3020800\n",
      "2017-11-17 15:00:00  4288.51  4398.79  4212.40  4330.45  6143200\n",
      "2017-11-20 15:00:00  4219.55  4255.89  4100.69  4204.95  4418300\n",
      "\n",
      "[215 rows x 5 columns]), ('600547.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  323.38  324.34  318.19  320.12  15751625\n",
      "2017-01-04 15:00:00  324.61  325.75  321.00  323.73  18402142\n",
      "2017-01-05 15:00:00  330.94  335.95  325.49  328.04  40187175\n",
      "2017-01-06 15:00:00  327.69  336.74  327.16  333.05  30836424\n",
      "2017-01-09 15:00:00  323.46  326.89  321.27  326.89  18881353\n",
      "2017-01-10 15:00:00  329.27  329.53  324.61  326.72  22803364\n",
      "2017-01-11 15:00:00  326.72  329.88  324.43  329.53  13843965\n",
      "2017-01-12 15:00:00  331.47  331.56  327.16  328.04  22139756\n",
      "2017-01-13 15:00:00  321.44  328.48  320.39  328.48  19110695\n",
      "2017-01-16 15:00:00  325.93  327.16  314.14  321.88  26221394\n",
      "2017-01-17 15:00:00  332.52  334.63  322.06  324.17  29840457\n",
      "2017-01-18 15:00:00  335.07  338.15  331.47  334.72  35851186\n",
      "2017-01-19 15:00:00  326.72  329.80  324.34  329.80  19233773\n",
      "2017-01-20 15:00:00  327.86  330.50  325.49  326.37  14281268\n",
      "2017-01-23 15:00:00  332.96  337.45  330.41  330.41  22012942\n",
      "2017-01-24 15:00:00  331.29  336.30  330.94  336.30  15091379\n",
      "2017-01-25 15:00:00  326.63  329.00  324.26  325.40  16688782\n",
      "2017-01-26 15:00:00  325.49  326.37  322.76  324.17  15696593\n",
      "2017-02-03 15:00:00  329.00  335.07  328.65  332.87  21427470\n",
      "2017-02-06 15:00:00  332.70  335.16  331.38  331.38  16246124\n",
      "2017-02-07 15:00:00  340.53  341.93  333.31  336.48  37861841\n",
      "2017-02-08 15:00:00  338.06  341.23  336.04  337.71  21667527\n",
      "2017-02-09 15:00:00  338.50  341.05  336.74  340.09  22173858\n",
      "2017-02-10 15:00:00  332.87  333.93  331.29  332.43  21895892\n",
      "2017-02-13 15:00:00  333.14  334.81  331.38  332.52  17819851\n",
      "2017-02-14 15:00:00  332.00  332.17  328.13  331.29  16621861\n",
      "2017-02-15 15:00:00  325.84  330.59  325.40  329.97  20113734\n",
      "2017-02-16 15:00:00  327.33  329.27  325.93  328.13  14224997\n",
      "2017-02-17 15:00:00  327.16  329.71  326.10  329.71  12617882\n",
      "2017-02-20 15:00:00  326.28  326.37  321.53  325.40  12648857\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  277.89  279.30  276.74  278.59   5022500\n",
      "2017-10-11 15:00:00  275.33  278.42  274.80  278.42   5627000\n",
      "2017-10-12 15:00:00  276.21  277.18  273.74  276.12   4960400\n",
      "2017-10-13 15:00:00  275.15  276.56  274.36  276.47   4111100\n",
      "2017-10-16 15:00:00  269.86  275.06  266.50  274.27   8880700\n",
      "2017-10-17 15:00:00  263.85  267.12  262.97  267.03   5499900\n",
      "2017-10-18 15:00:00  267.03  267.21  261.65  261.91   5005000\n",
      "2017-10-19 15:00:00  267.30  267.38  262.97  265.53   5394600\n",
      "2017-10-20 15:00:00  266.24  267.38  264.38  267.38   2283400\n",
      "2017-10-23 15:00:00  263.77  265.62  262.62  265.62   2854400\n",
      "2017-10-24 15:00:00  267.47  268.88  263.77  263.94   4020600\n",
      "2017-10-25 15:00:00  267.21  268.71  264.30  265.44   3390500\n",
      "2017-10-26 15:00:00  268.09  268.62  266.24  266.77   3319300\n",
      "2017-10-27 15:00:00  262.80  265.44  262.44  264.30   4656300\n",
      "2017-10-30 15:00:00  258.38  263.85  255.38  263.59   5691300\n",
      "2017-10-31 15:00:00  260.41  261.47  258.56  258.56   2551800\n",
      "2017-11-01 15:00:00  261.65  261.74  257.77  257.77   3507300\n",
      "2017-11-02 15:00:00  266.24  268.09  260.68  261.47   7603000\n",
      "2017-11-03 15:00:00  267.21  267.38  262.09  265.53   6171900\n",
      "2017-11-06 15:00:00  264.65  265.97  263.24  264.12   3436400\n",
      "2017-11-07 15:00:00  266.33  269.77  264.83  265.80   5409600\n",
      "2017-11-08 15:00:00  266.50  267.30  263.94  266.15   4384200\n",
      "2017-11-09 15:00:00  266.59  267.56  264.91  266.06   4235300\n",
      "2017-11-10 15:00:00  264.65  267.83  264.30  267.83   4574200\n",
      "2017-11-13 15:00:00  259.62  262.62  257.59  261.74   6630000\n",
      "2017-11-14 15:00:00  259.62  260.50  257.77  258.82   3424600\n",
      "2017-11-15 15:00:00  270.47  270.65  260.50  260.50  15387000\n",
      "2017-11-16 15:00:00  269.77  270.47  266.24  267.91   7224800\n",
      "2017-11-17 15:00:00  273.91  275.68  268.62  269.15  13466500\n",
      "2017-11-20 15:00:00  272.06  279.21  270.12  276.91   9484100\n",
      "\n",
      "[186 rows x 5 columns]), ('600606.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  73.88  74.13  73.45  73.45  26599849\n",
      "2017-01-04 15:00:00  74.38  74.89  73.54  73.71  63761990\n",
      "2017-01-05 15:00:00  73.62  74.30  73.54  74.05  44794129\n",
      "2017-01-06 15:00:00  72.61  73.71  72.36  73.37  57920129\n",
      "2017-01-09 15:00:00  73.20  73.45  72.02  72.19  41265917\n",
      "2017-01-10 15:00:00  72.78  73.29  72.61  73.03  26910026\n",
      "2017-01-11 15:00:00  72.44  73.12  72.27  72.78  23427750\n",
      "2017-01-12 15:00:00  72.53  73.03  72.27  72.53  29770698\n",
      "2017-01-13 15:00:00  72.86  73.37  72.53  72.86  42638424\n",
      "2017-01-16 15:00:00  73.03  73.37  70.50  72.86  87052379\n",
      "2017-01-17 15:00:00  72.61  72.78  71.68  72.61  30952778\n",
      "2017-01-18 15:00:00  73.03  73.29  72.19  72.61  27454048\n",
      "2017-01-19 15:00:00  72.78  73.03  72.53  72.78  20559496\n",
      "2017-01-20 15:00:00  73.20  73.54  72.36  72.44  35481978\n",
      "2017-01-23 15:00:00  73.37  73.71  73.03  73.03  30535384\n",
      "2017-01-24 15:00:00  72.86  73.37  72.61  73.20  24226334\n",
      "2017-01-25 15:00:00  72.69  72.95  72.27  72.61  21674100\n",
      "2017-01-26 15:00:00  72.78  72.95  72.61  72.61  16628123\n",
      "2017-02-03 15:00:00  72.86  73.20  72.69  72.95  20131812\n",
      "2017-02-06 15:00:00  72.86  73.03  72.44  72.86  23795295\n",
      "2017-02-07 15:00:00  72.61  72.95  72.36  72.95  26439798\n",
      "2017-02-08 15:00:00  72.69  72.78  71.93  72.36  31535623\n",
      "2017-02-09 15:00:00  73.79  74.89  72.78  72.86  72297320\n",
      "2017-02-10 15:00:00  73.88  74.47  73.45  73.54  54772419\n",
      "2017-02-13 15:00:00  74.64  74.97  73.88  74.38  56942754\n",
      "2017-02-14 15:00:00  74.21  74.72  73.96  74.64  29811104\n",
      "2017-02-15 15:00:00  74.05  75.56  73.71  74.30  56809399\n",
      "2017-02-16 15:00:00  74.30  74.80  73.88  73.88  46349218\n",
      "2017-02-17 15:00:00  73.62  74.72  73.54  74.21  44306058\n",
      "2017-02-20 15:00:00  74.97  75.06  73.37  73.54  56644344\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  66.67  66.93  66.32  66.41  23705600\n",
      "2017-10-11 15:00:00  66.76  67.11  66.50  66.76  26347000\n",
      "2017-10-12 15:00:00  66.50  66.93  65.98  66.93  20642100\n",
      "2017-10-13 15:00:00  66.50  66.67  66.32  66.41  13323800\n",
      "2017-10-16 15:00:00  65.37  66.76  65.37  66.67  21845100\n",
      "2017-10-17 15:00:00  65.28  65.80  65.10  65.37  15487900\n",
      "2017-10-18 15:00:00  64.76  66.06  64.76  65.45  25460700\n",
      "2017-10-19 15:00:00  64.14  65.02  64.06  64.84  21122800\n",
      "2017-10-20 15:00:00  64.67  64.84  64.23  64.23  16303800\n",
      "2017-10-23 15:00:00  64.58  64.67  64.23  64.58  11655400\n",
      "2017-10-24 15:00:00  65.37  65.63  64.49  64.49  27809200\n",
      "2017-10-25 15:00:00  65.63  66.24  65.19  65.28  28261300\n",
      "2017-10-26 15:00:00  65.19  65.71  64.93  65.45  22062000\n",
      "2017-10-27 15:00:00  65.37  65.98  65.10  65.19  22365900\n",
      "2017-10-30 15:00:00  64.58  65.89  64.14  65.71  28739300\n",
      "2017-10-31 15:00:00  65.63  65.63  64.32  64.41  19591600\n",
      "2017-11-01 15:00:00  65.71  66.67  65.37  65.71  32907000\n",
      "2017-11-02 15:00:00  65.37  65.63  64.76  65.54  25039100\n",
      "2017-11-03 15:00:00  64.23  65.98  63.80  65.98  26280300\n",
      "2017-11-06 15:00:00  64.58  64.76  63.97  64.32  18148400\n",
      "2017-11-07 15:00:00  66.06  66.15  64.58  64.84  32046800\n",
      "2017-11-08 15:00:00  66.15  67.72  65.54  65.80  57750700\n",
      "2017-11-09 15:00:00  66.41  66.41  65.54  65.80  26586200\n",
      "2017-11-10 15:00:00  65.37  66.24  65.28  66.24  25436900\n",
      "2017-11-13 15:00:00  64.76  65.37  64.49  65.10  22098100\n",
      "2017-11-14 15:00:00  64.84  65.10  64.32  64.84  17367200\n",
      "2017-11-15 15:00:00  64.49  64.93  64.32  64.76  13961600\n",
      "2017-11-16 15:00:00  65.19  65.63  64.23  64.32  31750800\n",
      "2017-11-17 15:00:00  64.49  65.80  64.14  64.76  35015200\n",
      "2017-11-20 15:00:00  63.10  64.14  62.05  63.97  31629700\n",
      "\n",
      "[215 rows x 5 columns]), ('600837.XSHG',                       close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00  322.08  324.13  320.65  322.49  12188382\n",
      "2017-01-04 15:00:00  322.70  323.31  319.63  321.47  10541741\n",
      "2017-01-05 15:00:00  320.45  324.13  320.04  324.13  11223292\n",
      "2017-01-06 15:00:00  315.13  321.26  314.11  321.06  19381625\n",
      "2017-01-09 15:00:00  318.61  319.63  315.13  315.13  10098426\n",
      "2017-01-10 15:00:00  323.10  323.72  317.99  317.99  13603681\n",
      "2017-01-11 15:00:00  326.17  327.81  321.47  321.47  25494065\n",
      "2017-01-12 15:00:00  329.65  332.51  325.35  325.97  23729975\n",
      "2017-01-13 15:00:00  333.53  336.81  329.04  329.44  29517467\n",
      "2017-01-16 15:00:00  338.85  340.90  330.06  331.69  59293287\n",
      "2017-01-17 15:00:00  337.83  338.65  334.56  337.42  15731161\n",
      "2017-01-18 15:00:00  339.26  340.69  334.56  338.24  17424414\n",
      "2017-01-19 15:00:00  337.83  340.28  334.97  337.62  21383440\n",
      "2017-01-20 15:00:00  339.67  340.08  336.40  338.65  21716190\n",
      "2017-01-23 15:00:00  338.65  342.74  338.24  340.08  12354088\n",
      "2017-01-24 15:00:00  332.92  340.08  332.51  338.65  13444492\n",
      "2017-01-25 15:00:00  332.51  335.37  331.08  332.92  14798622\n",
      "2017-01-26 15:00:00  332.31  335.37  331.69  333.33   7899352\n",
      "2017-02-03 15:00:00  329.04  334.35  328.42  334.35   7939600\n",
      "2017-02-06 15:00:00  329.65  332.72  328.01  330.06  13034155\n",
      "2017-02-07 15:00:00  326.58  330.47  325.35  329.24  10916856\n",
      "2017-02-08 15:00:00  328.42  330.26  323.51  327.19  24512674\n",
      "2017-02-09 15:00:00  327.19  329.44  326.58  328.22  25099045\n",
      "2017-02-10 15:00:00  328.01  329.44  325.76  327.60  27155880\n",
      "2017-02-13 15:00:00  328.42  329.44  326.58  328.22  38110677\n",
      "2017-02-14 15:00:00  325.97  328.83  325.15  328.83  25150686\n",
      "2017-02-15 15:00:00  324.95  327.60  324.33  326.17  22071714\n",
      "2017-02-16 15:00:00  323.72  325.76  322.70  325.15  30212842\n",
      "2017-02-17 15:00:00  323.51  329.85  323.10  324.74  54735407\n",
      "2017-02-20 15:00:00  324.13  324.33  319.22  322.70  44594343\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  303.88  304.29  302.66  302.86   9442600\n",
      "2017-10-11 15:00:00  303.06  304.70  302.66  304.09  10808600\n",
      "2017-10-12 15:00:00  302.04  303.88  301.84  303.47   8139400\n",
      "2017-10-13 15:00:00  303.27  303.88  302.04  302.45   6838400\n",
      "2017-10-16 15:00:00  303.47  305.72  302.66  303.88  15121500\n",
      "2017-10-17 15:00:00  300.81  302.86  300.61  302.66  11309500\n",
      "2017-10-18 15:00:00  303.06  304.50  300.61  301.22  21378300\n",
      "2017-10-19 15:00:00  298.97  302.86  298.57  302.45  13054200\n",
      "2017-10-20 15:00:00  300.20  301.84  297.95  298.36   7431400\n",
      "2017-10-23 15:00:00  298.57  300.61  297.54  300.41   7147400\n",
      "2017-10-24 15:00:00  302.66  303.06  298.36  298.36  21532700\n",
      "2017-10-25 15:00:00  301.84  303.68  300.61  302.45  10062800\n",
      "2017-10-26 15:00:00  301.43  303.27  300.00  301.84   9096800\n",
      "2017-10-27 15:00:00  300.61  302.45  300.20  301.43   6028700\n",
      "2017-10-30 15:00:00  299.79  301.22  292.02  300.20  25579200\n",
      "2017-10-31 15:00:00  296.11  298.16  294.68  297.13   9649500\n",
      "2017-11-01 15:00:00  294.27  296.93  294.27  296.32   8495200\n",
      "2017-11-02 15:00:00  295.29  296.72  293.45  295.09   9673300\n",
      "2017-11-03 15:00:00  296.52  296.93  292.43  295.29  16675500\n",
      "2017-11-06 15:00:00  294.48  295.91  293.86  295.29   6894500\n",
      "2017-11-07 15:00:00  296.32  297.75  294.07  295.91  13242900\n",
      "2017-11-08 15:00:00  299.18  303.88  295.29  296.11  24775800\n",
      "2017-11-09 15:00:00  298.57  300.20  296.52  298.16  10415300\n",
      "2017-11-10 15:00:00  297.34  298.77  295.29  298.16  11882400\n",
      "2017-11-13 15:00:00  295.91  299.38  295.50  297.95  10113500\n",
      "2017-11-14 15:00:00  293.66  296.32  293.25  296.32  10920200\n",
      "2017-11-15 15:00:00  293.25  294.48  291.00  291.00  17512600\n",
      "2017-11-16 15:00:00  287.32  292.84  287.11  292.43  13493300\n",
      "2017-11-17 15:00:00  295.70  296.32  285.27  287.93  42595400\n",
      "2017-11-20 15:00:00  290.18  295.91  289.36  293.04  17649400\n",
      "\n",
      "[215 rows x 5 columns]), ('600887.XSHG',                        close     high      low     open    volume\n",
      "datetime                                                         \n",
      "2017-01-03 15:00:00  1084.32  1096.56  1072.68  1077.58  29028916\n",
      "2017-01-04 15:00:00  1095.95  1096.56  1079.42  1084.32  35946842\n",
      "2017-01-05 15:00:00  1094.72  1100.85  1091.66  1095.95  17001644\n",
      "2017-01-06 15:00:00  1081.25  1099.01  1078.81  1099.01  27249114\n",
      "2017-01-09 15:00:00  1081.87  1084.93  1076.36  1076.97  21433622\n",
      "2017-01-10 15:00:00  1091.05  1094.11  1082.48  1086.15  31006829\n",
      "2017-01-11 15:00:00  1083.09  1089.83  1081.25  1089.83  18363804\n",
      "2017-01-12 15:00:00  1073.29  1086.76  1071.46  1083.70  19916660\n",
      "2017-01-13 15:00:00  1076.97  1083.70  1064.11  1072.07  29010279\n",
      "2017-01-16 15:00:00  1095.34  1099.62  1067.78  1086.15  64209013\n",
      "2017-01-17 15:00:00  1103.91  1104.52  1093.50  1099.62  28057941\n",
      "2017-01-18 15:00:00  1108.19  1114.32  1098.40  1103.30  25834654\n",
      "2017-01-19 15:00:00  1114.93  1124.72  1107.58  1108.19  28914918\n",
      "2017-01-20 15:00:00  1119.21  1125.34  1117.38  1117.99  23866981\n",
      "2017-01-23 15:00:00  1117.99  1132.07  1110.03  1121.66  26321302\n",
      "2017-01-24 15:00:00  1114.93  1123.50  1110.03  1114.32  15435032\n",
      "2017-01-25 15:00:00  1125.95  1129.01  1112.48  1120.44  20127594\n",
      "2017-01-26 15:00:00  1127.17  1136.97  1124.11  1127.79  17500686\n",
      "2017-02-03 15:00:00  1116.77  1128.40  1111.25  1127.17  16572924\n",
      "2017-02-06 15:00:00  1111.87  1120.44  1107.58  1116.77  22058671\n",
      "2017-02-07 15:00:00  1107.58  1113.09  1106.36  1112.48  17797339\n",
      "2017-02-08 15:00:00  1108.19  1110.03  1096.56  1109.42  23473988\n",
      "2017-02-09 15:00:00  1108.81  1116.15  1104.52  1110.03  31116598\n",
      "2017-02-10 15:00:00  1111.87  1117.38  1108.19  1109.42  28665836\n",
      "2017-02-13 15:00:00  1135.13  1139.42  1105.13  1111.87  77467899\n",
      "2017-02-14 15:00:00  1114.32  1138.81  1110.64  1131.46  48673037\n",
      "2017-02-15 15:00:00  1095.95  1115.54  1091.66  1114.93  64665798\n",
      "2017-02-16 15:00:00  1092.27  1102.07  1087.38  1093.50  39607092\n",
      "2017-02-17 15:00:00  1100.85  1105.13  1092.27  1093.50  42009206\n",
      "2017-02-20 15:00:00  1113.70  1121.66  1097.17  1100.23  77931487\n",
      "...                      ...      ...      ...      ...       ...\n",
      "2017-10-10 15:00:00  1746.11  1815.72  1703.70  1758.76  36772700\n",
      "2017-10-11 15:00:00  1808.13  1813.19  1749.27  1753.07  25984400\n",
      "2017-10-12 15:00:00  1803.07  1808.13  1775.22  1800.53  25229300\n",
      "2017-10-13 15:00:00  1746.74  1789.14  1745.47  1789.14  37985200\n",
      "2017-10-16 15:00:00  1752.44  1792.94  1740.41  1741.04  27122300\n",
      "2017-10-17 15:00:00  1765.73  1777.75  1742.94  1749.27  19940000\n",
      "2017-10-18 15:00:00  1869.52  1873.31  1758.13  1770.16  36950500\n",
      "2017-10-19 15:00:00  1883.44  1885.97  1840.40  1860.66  28512700\n",
      "2017-10-20 15:00:00  1846.10  1872.68  1824.58  1866.99  21211900\n",
      "2017-10-23 15:00:00  1866.99  1896.73  1847.37  1851.16  20684800\n",
      "2017-10-24 15:00:00  1878.38  1897.36  1849.90  1867.62  23982200\n",
      "2017-10-25 15:00:00  1885.34  1892.30  1863.82  1882.81  14527500\n",
      "2017-10-26 15:00:00  1882.17  1975.84  1865.09  1898.63  41677300\n",
      "2017-10-27 15:00:00  1910.65  1916.98  1827.75  1866.99  37732600\n",
      "2017-10-30 15:00:00  1921.41  1922.68  1860.02  1904.96  33282800\n",
      "2017-10-31 15:00:00  1870.15  1911.92  1851.16  1885.34  39612500\n",
      "2017-11-01 15:00:00  1804.96  1873.31  1789.14  1872.05  54884800\n",
      "2017-11-02 15:00:00  1820.79  1830.91  1792.94  1794.20  30319900\n",
      "2017-11-03 15:00:00  1860.66  1877.74  1823.95  1825.85  37253100\n",
      "2017-11-06 15:00:00  1941.67  1961.92  1884.71  1884.71  44867100\n",
      "2017-11-07 15:00:00  1916.35  1984.70  1893.57  1945.46  47761000\n",
      "2017-11-08 15:00:00  1887.87  1930.27  1867.62  1908.12  43135300\n",
      "2017-11-09 15:00:00  1885.34  1898.00  1829.01  1893.57  38071900\n",
      "2017-11-10 15:00:00  1952.42  1961.28  1872.05  1879.64  51081900\n",
      "2017-11-13 15:00:00  1932.17  1958.12  1918.88  1951.79  34586800\n",
      "2017-11-14 15:00:00  1853.06  1952.42  1851.80  1942.93  37945800\n",
      "2017-11-15 15:00:00  1858.76  1887.24  1842.30  1846.10  31431600\n",
      "2017-11-16 15:00:00  1936.60  1939.77  1855.59  1855.59  44528600\n",
      "2017-11-17 15:00:00  1994.19  1995.46  1889.77  1917.62  71239500\n",
      "2017-11-20 15:00:00  1974.57  1984.07  1923.94  1968.25  41873700\n",
      "\n",
      "[211 rows x 5 columns]), ('600919.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00   9.74   9.76   9.64   9.64   29370560\n",
      "2017-01-04 15:00:00   9.80   9.82   9.69   9.75   27035255\n",
      "2017-01-05 15:00:00   9.73   9.80   9.73   9.80   19594291\n",
      "2017-01-06 15:00:00   9.63   9.74   9.62   9.73   21413300\n",
      "2017-01-09 15:00:00   9.66   9.68   9.61   9.63   12957359\n",
      "2017-01-10 15:00:00   9.62   9.66   9.60   9.65   15095276\n",
      "2017-01-11 15:00:00   9.51   9.63   9.50   9.61   21686017\n",
      "2017-01-12 15:00:00   9.27   9.51   9.23   9.50   37214011\n",
      "2017-01-13 15:00:00   9.35   9.44   9.07   9.24   50427486\n",
      "2017-01-16 15:00:00   9.50   9.54   9.10   9.28   86952804\n",
      "2017-01-17 15:00:00   9.45   9.50   9.36   9.40   22496763\n",
      "2017-01-18 15:00:00   9.34   9.44   9.33   9.42   19265897\n",
      "2017-01-19 15:00:00   9.34   9.40   9.32   9.35   16276999\n",
      "2017-01-20 15:00:00   9.45   9.49   9.30   9.31   21977834\n",
      "2017-01-23 15:00:00   9.46   9.53   9.43   9.43   17571809\n",
      "2017-01-24 15:00:00   9.42   9.48   9.39   9.47   11552591\n",
      "2017-01-25 15:00:00   9.47   9.49   9.36   9.39   12152401\n",
      "2017-01-26 15:00:00   9.59   9.60   9.47   9.47   24029855\n",
      "2017-02-03 15:00:00   9.54   9.59   9.52   9.58   10887640\n",
      "2017-02-06 15:00:00   9.60   9.60   9.51   9.55   14603496\n",
      "2017-02-07 15:00:00   9.52   9.60   9.48   9.57   14795744\n",
      "2017-02-08 15:00:00   9.59   9.59   9.40   9.49   23322988\n",
      "2017-02-09 15:00:00   9.61   9.65   9.53   9.55   23998861\n",
      "2017-02-10 15:00:00   9.78   9.88   9.60   9.60   58040151\n",
      "2017-02-13 15:00:00  10.01  10.36   9.81   9.88  102697271\n",
      "2017-02-14 15:00:00   9.90  10.06   9.81  10.04   44467718\n",
      "2017-02-15 15:00:00  10.10  10.30   9.88   9.90  106628334\n",
      "2017-02-16 15:00:00  10.26  10.35  10.00  10.07   80325382\n",
      "2017-02-17 15:00:00   9.97  10.29   9.95  10.19   68502625\n",
      "2017-02-20 15:00:00  10.59  10.70   9.91   9.93  168522937\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00   8.55   8.57   8.51   8.57   10540600\n",
      "2017-10-11 15:00:00   8.56   8.59   8.52   8.55   11792900\n",
      "2017-10-12 15:00:00   8.54   8.57   8.52   8.55    8573300\n",
      "2017-10-13 15:00:00   8.56   8.56   8.52   8.53    7794600\n",
      "2017-10-16 15:00:00   8.47   8.56   8.46   8.55   14117000\n",
      "2017-10-17 15:00:00   8.54   8.57   8.45   8.48   16407800\n",
      "2017-10-18 15:00:00   8.51   8.56   8.48   8.55    7971600\n",
      "2017-10-19 15:00:00   8.38   8.51   8.37   8.50   13259600\n",
      "2017-10-20 15:00:00   8.41   8.42   8.37   8.38    9026000\n",
      "2017-10-23 15:00:00   8.40   8.41   8.37   8.40    7838900\n",
      "2017-10-24 15:00:00   8.39   8.41   8.37   8.39    7953700\n",
      "2017-10-25 15:00:00   8.42   8.46   8.39   8.40   11152900\n",
      "2017-10-26 15:00:00   8.44   8.48   8.39   8.42   13854400\n",
      "2017-10-27 15:00:00   8.48   8.51   8.41   8.43   19053900\n",
      "2017-10-30 15:00:00   8.29   8.49   8.28   8.47   23301400\n",
      "2017-10-31 15:00:00   8.28   8.32   8.24   8.31   10688100\n",
      "2017-11-01 15:00:00   8.27   8.31   8.26   8.28   11388700\n",
      "2017-11-02 15:00:00   8.16   8.28   8.15   8.27   17385500\n",
      "2017-11-03 15:00:00   8.06   8.17   8.03   8.16   16455900\n",
      "2017-11-06 15:00:00   8.07   8.09   8.03   8.06   10859200\n",
      "2017-11-07 15:00:00   8.15   8.18   8.04   8.06   18531700\n",
      "2017-11-08 15:00:00   8.15   8.22   8.10   8.16   14135800\n",
      "2017-11-09 15:00:00   8.14   8.17   8.11   8.14    9740400\n",
      "2017-11-10 15:00:00   8.10   8.15   8.08   8.14   10127700\n",
      "2017-11-13 15:00:00   8.26   8.34   8.11   8.12   42470900\n",
      "2017-11-14 15:00:00   8.14   8.24   8.13   8.23   16329100\n",
      "2017-11-15 15:00:00   8.09   8.16   8.08   8.13   12713500\n",
      "2017-11-16 15:00:00   7.92   8.05   7.92   8.05   22765300\n",
      "2017-11-17 15:00:00   7.92   7.99   7.88   7.88   16707300\n",
      "2017-11-20 15:00:00   7.94   7.95   7.78   7.87   16905000\n",
      "\n",
      "[215 rows x 5 columns]), ('600958.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  16.09  16.15  15.99  16.04  10227663\n",
      "2017-01-04 15:00:00  16.11  16.13  16.03  16.10   8653171\n",
      "2017-01-05 15:00:00  15.91  16.10  15.89  16.10  13888394\n",
      "2017-01-06 15:00:00  15.74  15.94  15.73  15.93  14430820\n",
      "2017-01-09 15:00:00  15.74  15.79  15.67  15.68   8685359\n",
      "2017-01-10 15:00:00  15.71  15.81  15.71  15.75   8072853\n",
      "2017-01-11 15:00:00  15.60  15.76  15.57  15.70   9823852\n",
      "2017-01-12 15:00:00  15.52  15.66  15.51  15.57   9198402\n",
      "2017-01-13 15:00:00  15.67  15.71  15.39  15.51  15999425\n",
      "2017-01-16 15:00:00  15.94  16.00  15.07  15.62  48544277\n",
      "2017-01-17 15:00:00  15.72  15.77  15.50  15.76   9240830\n",
      "2017-01-18 15:00:00  15.66  15.78  15.59  15.65   6676094\n",
      "2017-01-19 15:00:00  15.65  15.74  15.54  15.55   6330912\n",
      "2017-01-20 15:00:00  15.73  15.77  15.60  15.63   6502134\n",
      "2017-01-23 15:00:00  15.74  15.79  15.68  15.72   6508759\n",
      "2017-01-24 15:00:00  15.64  15.78  15.62  15.76   4753601\n",
      "2017-01-25 15:00:00  15.61  15.67  15.56  15.61   4959405\n",
      "2017-01-26 15:00:00  15.68  15.69  15.61  15.64   5242097\n",
      "2017-02-03 15:00:00  15.62  15.77  15.59  15.65   4245941\n",
      "2017-02-14 15:00:00  15.87  16.23  15.83  15.98  32756116\n",
      "2017-02-15 15:00:00  15.75  15.97  15.70  15.78  16265014\n",
      "2017-02-16 15:00:00  15.95  16.01  15.67  15.73  19659189\n",
      "2017-02-17 15:00:00  15.98  16.42  15.94  15.99  32459867\n",
      "2017-02-20 15:00:00  16.08  16.08  15.80  15.90  17273604\n",
      "2017-02-21 15:00:00  16.05  16.21  15.94  16.06  20144982\n",
      "2017-02-22 15:00:00  15.91  16.05  15.85  16.02  16248121\n",
      "2017-02-23 15:00:00  15.82  15.97  15.75  15.96  12325364\n",
      "2017-02-24 15:00:00  15.83  15.88  15.78  15.81  10866800\n",
      "2017-02-27 15:00:00  15.74  15.88  15.73  15.84   9911890\n",
      "2017-02-28 15:00:00  15.74  15.83  15.70  15.74   8207329\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  16.65  16.72  16.38  16.54  12998500\n",
      "2017-10-11 15:00:00  16.62  16.76  16.50  16.60  12106500\n",
      "2017-10-12 15:00:00  16.65  16.69  16.54  16.65   8208300\n",
      "2017-10-13 15:00:00  16.58  16.68  16.50  16.67   9244300\n",
      "2017-10-16 15:00:00  16.26  16.71  16.26  16.66  16099600\n",
      "2017-10-17 15:00:00  16.08  16.35  16.03  16.26   9945100\n",
      "2017-10-18 15:00:00  16.08  16.40  16.04  16.13  10740400\n",
      "2017-10-19 15:00:00  15.73  16.17  15.68  16.08  13583000\n",
      "2017-10-20 15:00:00  15.82  15.83  15.68  15.70   6699900\n",
      "2017-10-23 15:00:00  15.83  15.87  15.74  15.87   7652400\n",
      "2017-10-24 15:00:00  16.05  16.08  15.75  15.77  13241400\n",
      "2017-10-25 15:00:00  16.07  16.16  15.95  16.00   8241400\n",
      "2017-10-26 15:00:00  16.13  16.32  15.95  16.06  13336500\n",
      "2017-10-27 15:00:00  16.07  16.22  16.04  16.04   8286500\n",
      "2017-10-30 15:00:00  15.90  16.00  15.49  15.98  17079100\n",
      "2017-10-31 15:00:00  15.70  15.83  15.62  15.79   8758100\n",
      "2017-11-01 15:00:00  15.64  15.86  15.63  15.70  12983700\n",
      "2017-11-02 15:00:00  15.82  16.13  15.61  15.64  16009300\n",
      "2017-11-03 15:00:00  15.89  15.91  15.67  15.77  10755400\n",
      "2017-11-06 15:00:00  15.75  15.90  15.66  15.84   8401900\n",
      "2017-11-07 15:00:00  16.15  16.33  15.75  15.77  25124100\n",
      "2017-11-08 15:00:00  16.47  17.01  16.04  16.05  36173300\n",
      "2017-11-09 15:00:00  16.60  16.70  16.37  16.39  16424600\n",
      "2017-11-10 15:00:00  16.60  16.77  16.40  16.76  16071100\n",
      "2017-11-13 15:00:00  16.58  16.87  16.52  16.69  16110500\n",
      "2017-11-14 15:00:00  16.33  16.57  16.24  16.48  14761100\n",
      "2017-11-15 15:00:00  16.41  16.75  16.26  16.26  20097100\n",
      "2017-11-16 15:00:00  15.85  16.38  15.80  16.32  16748800\n",
      "2017-11-17 15:00:00  16.21  16.24  15.70  15.78  23021300\n",
      "2017-11-20 15:00:00  16.07  16.09  15.76  15.99  10930900\n",
      "\n",
      "[209 rows x 5 columns]), ('600999.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  24.71  24.92  24.39  24.41  23592667\n",
      "2017-01-04 15:00:00  24.90  24.93  24.65  24.71  14879364\n",
      "2017-01-05 15:00:00  24.86  24.96  24.83  24.96   9389337\n",
      "2017-01-06 15:00:00  24.69  24.92  24.66  24.89   9141263\n",
      "2017-01-09 15:00:00  24.65  24.83  24.59  24.65   9132766\n",
      "2017-01-10 15:00:00  24.66  24.75  24.54  24.65   6423482\n",
      "2017-01-11 15:00:00  24.42  24.72  24.41  24.59  10325932\n",
      "2017-01-12 15:00:00  24.36  24.57  24.32  24.39   8628129\n",
      "2017-01-13 15:00:00  24.50  24.62  24.24  24.30   9945168\n",
      "2017-01-16 15:00:00  24.87  24.99  24.05  24.30  39556971\n",
      "2017-01-17 15:00:00  24.74  24.83  24.50  24.69   7573050\n",
      "2017-01-18 15:00:00  24.77  25.02  24.60  24.74   8783235\n",
      "2017-01-19 15:00:00  24.83  25.01  24.71  24.77   8238616\n",
      "2017-01-20 15:00:00  25.08  25.20  24.86  24.89  11607227\n",
      "2017-01-23 15:00:00  25.14  25.26  24.99  25.05   9270923\n",
      "2017-01-24 15:00:00  24.98  25.08  24.93  25.07   6498848\n",
      "2017-01-25 15:00:00  24.96  25.10  24.84  24.99   7725057\n",
      "2017-01-26 15:00:00  25.08  25.22  24.98  24.99   7198486\n",
      "2017-02-03 15:00:00  24.74  25.22  24.65  25.08   6953676\n",
      "2017-02-06 15:00:00  24.74  24.81  24.59  24.69   6200084\n",
      "2017-02-07 15:00:00  24.63  24.72  24.51  24.68   7690541\n",
      "2017-02-08 15:00:00  25.16  25.17  24.57  24.62  15206082\n",
      "2017-02-09 15:00:00  25.17  25.32  24.99  25.07  14237792\n",
      "2017-02-10 15:00:00  25.25  25.41  25.07  25.14  15821478\n",
      "2017-02-13 15:00:00  25.41  25.58  25.16  25.25  17244438\n",
      "2017-02-14 15:00:00  25.28  25.50  25.19  25.44  10049307\n",
      "2017-02-15 15:00:00  25.19  25.56  25.07  25.55  14614835\n",
      "2017-02-16 15:00:00  25.37  25.56  24.99  25.08  11511431\n",
      "2017-02-17 15:00:00  25.38  26.10  25.35  25.49  26265663\n",
      "2017-02-20 15:00:00  25.59  25.67  25.25  25.37  15166631\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  31.25  31.97  30.77  31.68  16697000\n",
      "2017-10-11 15:00:00  30.99  31.37  30.80  31.14   9346500\n",
      "2017-10-12 15:00:00  30.74  31.16  30.45  31.13   8915900\n",
      "2017-10-13 15:00:00  30.32  30.86  30.22  30.72  11786800\n",
      "2017-10-16 15:00:00  30.26  30.56  30.11  30.32  10304600\n",
      "2017-10-17 15:00:00  30.20  30.47  30.08  30.23   8483100\n",
      "2017-10-18 15:00:00  30.68  30.75  30.20  30.23  13230200\n",
      "2017-10-19 15:00:00  29.98  30.62  29.26  30.48  16928500\n",
      "2017-10-20 15:00:00  29.57  29.92  29.48  29.69   6216700\n",
      "2017-10-23 15:00:00  29.09  29.66  28.96  29.62   7538700\n",
      "2017-10-24 15:00:00  29.53  29.57  29.03  29.03   7595000\n",
      "2017-10-25 15:00:00  29.50  29.69  29.26  29.45   4984900\n",
      "2017-10-26 15:00:00  29.59  29.87  29.15  29.48  11046900\n",
      "2017-10-27 15:00:00  29.80  29.83  29.44  29.48   7053300\n",
      "2017-10-30 15:00:00  28.34  29.75  27.61  29.75  22166100\n",
      "2017-10-31 15:00:00  27.94  28.23  27.72  27.99   7868300\n",
      "2017-11-01 15:00:00  27.49  28.31  27.39  28.00  12038600\n",
      "2017-11-02 15:00:00  27.57  27.91  27.09  27.58  11350200\n",
      "2017-11-03 15:00:00  27.67  27.73  27.06  27.49   8809900\n",
      "2017-11-06 15:00:00  27.36  27.69  27.15  27.48   9035400\n",
      "2017-11-07 15:00:00  27.75  28.06  27.33  27.36  15017700\n",
      "2017-11-08 15:00:00  28.63  29.45  27.60  27.73  22420800\n",
      "2017-11-09 15:00:00  29.14  29.15  28.34  28.34  15526000\n",
      "2017-11-10 15:00:00  29.12  29.60  28.66  29.03  13317300\n",
      "2017-11-13 15:00:00  28.96  29.77  28.93  29.30  14099800\n",
      "2017-11-14 15:00:00  28.51  29.21  28.14  29.15  11748500\n",
      "2017-11-15 15:00:00  28.37  28.81  28.15  28.28   8135500\n",
      "2017-11-16 15:00:00  27.84  28.43  27.70  28.23   8237700\n",
      "2017-11-17 15:00:00  28.84  28.85  27.58  27.85  18595000\n",
      "2017-11-20 15:00:00  28.21  28.49  27.78  28.46  12637800\n",
      "\n",
      "[215 rows x 5 columns]), ('601006.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  11.13  11.15  10.90  10.90  45438258\n",
      "2017-01-04 15:00:00  11.26  11.44  11.16  11.18  81618699\n",
      "2017-01-05 15:00:00  11.59  11.87  11.12  11.22  90662892\n",
      "2017-01-06 15:00:00  11.53  11.86  11.44  11.52  67365338\n",
      "2017-01-09 15:00:00  11.58  11.64  11.38  11.49  46674653\n",
      "2017-01-10 15:00:00  11.39  11.59  11.35  11.52  36567741\n",
      "2017-01-11 15:00:00  11.26  11.44  11.24  11.36  31126452\n",
      "2017-01-12 15:00:00  11.13  11.29  11.12  11.22  26745437\n",
      "2017-01-13 15:00:00  11.21  11.26  11.10  11.16  39179655\n",
      "2017-01-16 15:00:00  11.39  11.46  11.01  11.22  88749981\n",
      "2017-01-17 15:00:00  11.33  11.36  11.22  11.35  23752729\n",
      "2017-01-18 15:00:00  11.32  11.36  11.22  11.29  36097749\n",
      "2017-01-19 15:00:00  11.21  11.38  11.15  11.29  25806833\n",
      "2017-01-20 15:00:00  11.22  11.30  11.12  11.19  34550232\n",
      "2017-01-23 15:00:00  10.96  11.16  10.93  11.09  69047492\n",
      "2017-01-24 15:00:00  10.96  10.96  10.85  10.93  36720158\n",
      "2017-01-25 15:00:00  10.96  10.98  10.90  10.95  14024666\n",
      "2017-01-26 15:00:00  11.04  11.05  10.93  10.96  28725939\n",
      "2017-02-03 15:00:00  10.78  11.05  10.73  11.04  38938867\n",
      "2017-02-06 15:00:00  10.79  10.82  10.70  10.79  39688363\n",
      "2017-02-07 15:00:00  10.76  10.81  10.71  10.79  22763250\n",
      "2017-02-08 15:00:00  10.88  10.92  10.73  10.76  26831162\n",
      "2017-02-09 15:00:00  10.93  10.95  10.85  10.92  22618812\n",
      "2017-02-10 15:00:00  10.96  11.01  10.90  10.93  41061408\n",
      "2017-02-13 15:00:00  10.98  11.04  10.90  10.96  48360970\n",
      "2017-02-14 15:00:00  11.01  11.22  10.98  11.01  41774582\n",
      "2017-02-15 15:00:00  10.87  11.01  10.85  10.99  40972011\n",
      "2017-02-16 15:00:00  10.87  10.92  10.81  10.85  43304007\n",
      "2017-02-17 15:00:00  10.81  10.88  10.78  10.87  31735415\n",
      "2017-02-20 15:00:00  10.92  10.92  10.76  10.79  37470317\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  14.36  14.37  14.16  14.18  21743700\n",
      "2017-10-11 15:00:00  14.36  14.39  14.26  14.32  15840000\n",
      "2017-10-12 15:00:00  14.42  14.51  14.36  14.36  16620200\n",
      "2017-10-13 15:00:00  14.28  14.48  14.26  14.47  15718300\n",
      "2017-10-16 15:00:00  14.26  14.42  14.24  14.28  12927000\n",
      "2017-10-17 15:00:00  14.29  14.39  14.20  14.24  12872000\n",
      "2017-10-18 15:00:00  14.58  14.61  14.20  14.29  32841400\n",
      "2017-10-19 15:00:00  14.69  14.71  14.51  14.55  26758800\n",
      "2017-10-20 15:00:00  14.59  14.66  14.53  14.63  13726800\n",
      "2017-10-23 15:00:00  14.66  14.67  14.53  14.58  16938200\n",
      "2017-10-24 15:00:00  14.93  14.94  14.61  14.61  39468000\n",
      "2017-10-25 15:00:00  14.96  15.04  14.83  14.91  23016000\n",
      "2017-10-26 15:00:00  14.51  14.90  14.42  14.86  67801300\n",
      "2017-10-27 15:00:00  14.59  14.67  14.45  14.55  24941900\n",
      "2017-10-30 15:00:00  14.56  14.66  14.37  14.59  26973000\n",
      "2017-10-31 15:00:00  14.48  14.59  14.42  14.53  17655800\n",
      "2017-11-01 15:00:00  14.18  14.48  14.15  14.48  35074000\n",
      "2017-11-02 15:00:00  14.23  14.29  14.07  14.18  17833600\n",
      "2017-11-03 15:00:00  14.07  14.23  13.89  14.21  36191300\n",
      "2017-11-06 15:00:00  14.05  14.10  13.96  14.07  18313500\n",
      "2017-11-07 15:00:00  14.10  14.16  13.99  14.04  22462600\n",
      "2017-11-08 15:00:00  14.13  14.26  14.05  14.13  20613000\n",
      "2017-11-09 15:00:00  14.20  14.21  14.08  14.12  13591600\n",
      "2017-11-10 15:00:00  14.07  14.20  13.99  14.20  17761900\n",
      "2017-11-13 15:00:00  14.31  14.34  14.04  14.08  19950500\n",
      "2017-11-14 15:00:00  14.24  14.32  14.18  14.32  15550900\n",
      "2017-11-15 15:00:00  14.18  14.26  14.05  14.21  18189000\n",
      "2017-11-16 15:00:00  13.99  14.13  13.97  14.13  15263100\n",
      "2017-11-17 15:00:00  14.37  14.40  13.85  14.01  54863200\n",
      "2017-11-20 15:00:00  14.37  14.40  14.15  14.29  26076900\n",
      "\n",
      "[215 rows x 5 columns]), ('601088.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  21.45  21.63  21.29  21.47  11447203\n",
      "2017-01-04 15:00:00  21.61  21.68  21.36  21.44  13139456\n",
      "2017-01-05 15:00:00  21.63  21.86  21.60  21.69  11716844\n",
      "2017-01-06 15:00:00  21.74  21.82  21.48  21.68  11672156\n",
      "2017-01-09 15:00:00  21.89  22.05  21.68  21.68  12113563\n",
      "2017-01-10 15:00:00  22.08  22.18  21.72  21.74  11446593\n",
      "2017-01-11 15:00:00  21.92  22.35  21.89  22.08  21469462\n",
      "2017-01-12 15:00:00  21.82  22.18  21.81  21.90  10813118\n",
      "2017-01-13 15:00:00  22.01  22.08  21.77  21.93  12418202\n",
      "2017-01-16 15:00:00  22.41  22.46  21.88  22.16  30675860\n",
      "2017-01-17 15:00:00  22.35  22.43  22.18  22.28   8503900\n",
      "2017-01-18 15:00:00  22.61  22.77  22.22  22.42  14084420\n",
      "2017-01-19 15:00:00  22.53  22.79  22.41  22.58   7606468\n",
      "2017-01-20 15:00:00  22.67  22.70  22.43  22.45   7710133\n",
      "2017-01-23 15:00:00  22.71  22.87  22.69  22.70  10421834\n",
      "2017-01-24 15:00:00  22.94  22.99  22.57  22.74  14030148\n",
      "2017-01-25 15:00:00  22.78  23.03  22.71  23.03   8580556\n",
      "2017-01-26 15:00:00  22.83  22.87  22.45  22.67  19913984\n",
      "2017-02-03 15:00:00  22.43  22.82  22.42  22.69  11768362\n",
      "2017-02-06 15:00:00  22.21  22.51  22.01  22.50  17739662\n",
      "2017-02-07 15:00:00  22.16  22.29  22.04  22.09  10923463\n",
      "2017-02-08 15:00:00  22.34  22.38  22.08  22.08   8376942\n",
      "2017-02-09 15:00:00  22.39  22.55  22.30  22.30   9223760\n",
      "2017-02-10 15:00:00  22.61  22.74  22.37  22.46  14837218\n",
      "2017-02-13 15:00:00  22.81  23.28  22.74  23.02  23709079\n",
      "2017-02-14 15:00:00  22.95  23.00  22.74  22.77  10888306\n",
      "2017-02-15 15:00:00  22.94  23.18  22.78  22.91  18024083\n",
      "2017-02-16 15:00:00  23.07  23.14  22.87  22.94  15907076\n",
      "2017-02-17 15:00:00  22.70  23.18  22.66  23.11  16974718\n",
      "2017-02-20 15:00:00  22.91  22.94  22.61  22.71  16136365\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  27.15  27.50  26.89  27.46  16806000\n",
      "2017-10-11 15:00:00  27.27  27.31  27.04  27.14   6877700\n",
      "2017-10-12 15:00:00  26.86  27.31  26.68  27.29  11454300\n",
      "2017-10-13 15:00:00  27.09  27.19  26.93  26.96   6197300\n",
      "2017-10-16 15:00:00  27.11  27.25  27.00  27.18   5781600\n",
      "2017-10-17 15:00:00  26.85  27.29  26.84  27.11   8609500\n",
      "2017-10-18 15:00:00  27.23  27.26  26.85  26.85   8800900\n",
      "2017-10-19 15:00:00  27.43  27.45  26.98  27.19  10392200\n",
      "2017-10-20 15:00:00  27.19  27.46  27.11  27.45   5208200\n",
      "2017-10-23 15:00:00  27.00  27.18  26.92  27.18   4685900\n",
      "2017-10-24 15:00:00  27.29  27.34  26.93  26.96   7591400\n",
      "2017-10-25 15:00:00  27.46  27.65  27.18  27.21   6961900\n",
      "2017-10-26 15:00:00  27.37  28.19  27.25  27.47  16406900\n",
      "2017-10-27 15:00:00  27.46  27.79  27.23  27.45  11674300\n",
      "2017-10-30 15:00:00  27.31  27.51  26.85  27.31  11877000\n",
      "2017-10-31 15:00:00  27.54  27.66  27.13  27.18   7447000\n",
      "2017-11-01 15:00:00  27.07  27.83  27.06  27.49  12737800\n",
      "2017-11-02 15:00:00  27.14  27.22  26.90  27.11   7880900\n",
      "2017-11-03 15:00:00  27.26  27.29  26.70  27.14  11165200\n",
      "2017-11-06 15:00:00  27.04  27.21  26.89  27.06   6293000\n",
      "2017-11-07 15:00:00  27.10  27.25  26.82  27.14  11463300\n",
      "2017-11-08 15:00:00  27.22  27.34  26.98  27.10  11675200\n",
      "2017-11-09 15:00:00  29.24  29.30  27.39  27.39  36236600\n",
      "2017-11-10 15:00:00  28.64  29.10  28.44  28.85  24179200\n",
      "2017-11-13 15:00:00  29.62  29.98  28.48  28.48  31533000\n",
      "2017-11-14 15:00:00  31.20  31.99  29.70  29.83  40648800\n",
      "2017-11-15 15:00:00  31.70  31.82  30.38  30.83  28191600\n",
      "2017-11-16 15:00:00  31.25  31.36  30.51  31.30  20964300\n",
      "2017-11-17 15:00:00  30.99  31.15  29.81  30.96  35602700\n",
      "2017-11-20 15:00:00  31.41  31.44  29.98  30.52  20960800\n",
      "\n",
      "[151 rows x 5 columns]), ('601166.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  59.56  60.00  59.20  59.20   48199929\n",
      "2017-01-04 15:00:00  59.86  60.08  59.42  59.56   42410084\n",
      "2017-01-05 15:00:00  59.89  60.11  59.86  59.86   27695726\n",
      "2017-01-06 15:00:00  59.34  60.08  59.27  59.78   27771510\n",
      "2017-01-09 15:00:00  59.56  59.75  59.31  59.38   25154829\n",
      "2017-01-10 15:00:00  59.49  59.71  59.38  59.56   22349795\n",
      "2017-01-11 15:00:00  59.23  59.71  59.16  59.60   25058385\n",
      "2017-01-12 15:00:00  59.09  59.42  59.09  59.23   19409846\n",
      "2017-01-13 15:00:00  59.67  59.75  58.87  59.12   48681302\n",
      "2017-01-16 15:00:00  60.63  60.85  59.34  59.53  132750624\n",
      "2017-01-17 15:00:00  60.22  60.81  60.19  60.44   42782543\n",
      "2017-01-18 15:00:00  61.07  61.18  60.26  60.37   45018120\n",
      "2017-01-19 15:00:00  61.03  61.43  60.96  60.96   36651191\n",
      "2017-01-20 15:00:00  61.51  61.73  61.03  61.14   44222256\n",
      "2017-01-23 15:00:00  61.32  61.80  61.10  61.69   37060810\n",
      "2017-01-24 15:00:00  62.06  62.17  61.21  61.43   52776798\n",
      "2017-01-25 15:00:00  62.13  62.17  61.69  62.06   30796006\n",
      "2017-01-26 15:00:00  62.61  62.72  62.09  62.13   38763527\n",
      "2017-02-03 15:00:00  61.32  62.75  61.21  62.68   42366030\n",
      "2017-02-06 15:00:00  61.32  61.62  61.10  61.62   39873907\n",
      "2017-02-07 15:00:00  61.07  61.43  60.96  61.32   40464616\n",
      "2017-02-08 15:00:00  61.18  61.29  60.74  61.03   43172468\n",
      "2017-02-09 15:00:00  61.25  61.62  61.14  61.25   40258937\n",
      "2017-02-10 15:00:00  61.47  61.69  61.32  61.43   47135040\n",
      "2017-02-13 15:00:00  61.87  62.20  61.51  61.58   61514376\n",
      "2017-02-14 15:00:00  61.43  61.98  61.29  61.98   50106525\n",
      "2017-02-15 15:00:00  61.62  62.09  61.36  61.47   87274194\n",
      "2017-02-16 15:00:00  61.54  61.98  61.43  61.73   65673672\n",
      "2017-02-17 15:00:00  61.21  61.87  61.14  61.58   50743937\n",
      "2017-02-20 15:00:00  62.02  62.68  61.10  61.18  141648208\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  67.78  67.86  66.56  66.68   55540300\n",
      "2017-10-11 15:00:00  67.40  68.43  67.17  67.90   57814300\n",
      "2017-10-12 15:00:00  67.63  68.24  67.25  67.40   41699400\n",
      "2017-10-13 15:00:00  67.78  68.35  67.75  67.75   31486700\n",
      "2017-10-16 15:00:00  68.70  68.89  67.75  67.78   51917500\n",
      "2017-10-17 15:00:00  68.16  68.77  68.09  68.74   29170100\n",
      "2017-10-18 15:00:00  68.54  68.66  67.78  68.43   38108100\n",
      "2017-10-19 15:00:00  68.66  68.70  68.20  68.35   40870600\n",
      "2017-10-20 15:00:00  68.09  68.54  68.01  68.47   16884500\n",
      "2017-10-23 15:00:00  67.21  68.05  67.17  68.05   27988300\n",
      "2017-10-24 15:00:00  67.67  67.94  67.17  67.25   24125300\n",
      "2017-10-25 15:00:00  67.44  67.75  67.25  67.75   21629000\n",
      "2017-10-26 15:00:00  66.64  67.17  66.41  67.17   45420500\n",
      "2017-10-27 15:00:00  67.40  67.82  66.72  66.72   60229100\n",
      "2017-10-30 15:00:00  67.25  67.78  66.83  67.06   48991400\n",
      "2017-10-31 15:00:00  66.41  66.98  66.37  66.95   28206700\n",
      "2017-11-01 15:00:00  65.69  66.37  65.57  66.34   57691300\n",
      "2017-11-02 15:00:00  65.69  65.92  64.97  65.84   43715700\n",
      "2017-11-03 15:00:00  65.61  65.84  64.89  65.54   49214100\n",
      "2017-11-06 15:00:00  64.17  65.35  64.13  65.35   56585200\n",
      "2017-11-07 15:00:00  65.04  65.27  64.20  64.24   41999300\n",
      "2017-11-08 15:00:00  65.27  65.76  64.89  65.00   39748400\n",
      "2017-11-09 15:00:00  64.93  65.61  64.66  65.16   30147100\n",
      "2017-11-10 15:00:00  64.55  65.12  64.17  64.93   38392000\n",
      "2017-11-13 15:00:00  65.19  66.11  64.66  64.66   75448200\n",
      "2017-11-14 15:00:00  64.51  65.19  64.43  65.12   30735600\n",
      "2017-11-15 15:00:00  64.51  64.74  64.36  64.39   20789100\n",
      "2017-11-16 15:00:00  64.17  64.55  64.17  64.55   28865300\n",
      "2017-11-17 15:00:00  66.11  66.26  64.20  64.24   93679800\n",
      "2017-11-20 15:00:00  66.87  66.95  65.31  65.57   75879700\n",
      "\n",
      "[215 rows x 5 columns]), ('601169.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  24.89  25.04  24.56  24.61  19047727\n",
      "2017-01-04 15:00:00  24.84  25.07  24.76  24.84  18402676\n",
      "2017-01-05 15:00:00  24.89  25.04  24.84  24.94  18552723\n",
      "2017-01-06 15:00:00  24.79  24.94  24.76  24.92  10473063\n",
      "2017-01-09 15:00:00  24.81  24.94  24.64  24.92  15003847\n",
      "2017-01-10 15:00:00  24.84  24.89  24.71  24.79  12004703\n",
      "2017-01-11 15:00:00  24.69  24.94  24.59  24.94  16154346\n",
      "2017-01-12 15:00:00  24.69  24.81  24.51  24.71  10222687\n",
      "2017-01-13 15:00:00  24.89  24.97  24.61  24.61  27708600\n",
      "2017-01-16 15:00:00  25.34  25.42  24.81  24.92  63885135\n",
      "2017-01-17 15:00:00  25.09  25.39  25.04  25.34  25268648\n",
      "2017-01-18 15:00:00  25.27  25.34  25.07  25.12  12968847\n",
      "2017-01-19 15:00:00  25.24  25.49  25.17  25.17  14996698\n",
      "2017-01-20 15:00:00  25.29  25.42  25.17  25.24  23054885\n",
      "2017-01-23 15:00:00  25.39  25.42  25.24  25.39  12761234\n",
      "2017-01-24 15:00:00  25.42  25.47  25.24  25.42  14537364\n",
      "2017-01-25 15:00:00  25.37  25.42  25.24  25.34   9481754\n",
      "2017-01-26 15:00:00  25.42  25.52  25.29  25.37  12642179\n",
      "2017-02-03 15:00:00  25.24  25.49  25.22  25.47  11321827\n",
      "2017-02-06 15:00:00  25.27  25.34  25.19  25.32  13505695\n",
      "2017-02-07 15:00:00  25.29  25.34  25.22  25.24  11969415\n",
      "2017-02-08 15:00:00  25.24  25.29  24.97  25.22  16112898\n",
      "2017-02-09 15:00:00  25.07  25.24  25.07  25.19  15198893\n",
      "2017-02-10 15:00:00  25.09  25.17  25.02  25.17  21265279\n",
      "2017-02-13 15:00:00  25.29  25.34  25.09  25.12  26838155\n",
      "2017-02-14 15:00:00  25.12  25.34  25.04  25.32  20902122\n",
      "2017-02-15 15:00:00  25.39  25.55  25.12  25.19  34928066\n",
      "2017-02-16 15:00:00  25.57  25.60  25.32  25.32  26877856\n",
      "2017-02-17 15:00:00  25.39  25.57  25.37  25.55  20870030\n",
      "2017-02-20 15:00:00  25.70  25.80  25.39  25.42  65975276\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  19.00  19.02  18.84  18.92  17489700\n",
      "2017-10-11 15:00:00  18.97  19.05  18.89  18.97  11272100\n",
      "2017-10-12 15:00:00  18.89  19.02  18.84  18.97  11547600\n",
      "2017-10-13 15:00:00  18.92  18.94  18.79  18.87  10076200\n",
      "2017-10-16 15:00:00  18.84  18.94  18.79  18.94  15933400\n",
      "2017-10-17 15:00:00  18.87  18.92  18.77  18.87  10342900\n",
      "2017-10-18 15:00:00  18.77  18.89  18.77  18.87  12258800\n",
      "2017-10-19 15:00:00  18.57  18.79  18.54  18.77  18865000\n",
      "2017-10-20 15:00:00  18.67  18.67  18.54  18.59  11036600\n",
      "2017-10-23 15:00:00  18.62  18.67  18.57  18.64  13306100\n",
      "2017-10-24 15:00:00  18.62  18.69  18.57  18.59  15991000\n",
      "2017-10-25 15:00:00  18.67  18.72  18.59  18.64  12489200\n",
      "2017-10-26 15:00:00  18.62  18.67  18.57  18.64  15839900\n",
      "2017-10-27 15:00:00  18.67  18.79  18.59  18.62  25420300\n",
      "2017-10-30 15:00:00  18.64  18.69  18.49  18.64  21878500\n",
      "2017-10-31 15:00:00  18.49  18.62  18.49  18.59  17065900\n",
      "2017-11-01 15:00:00  18.52  18.57  18.47  18.49  18184000\n",
      "2017-11-02 15:00:00  18.54  18.59  18.29  18.49  30503100\n",
      "2017-11-03 15:00:00  18.59  18.64  18.39  18.49  21838900\n",
      "2017-11-06 15:00:00  18.39  18.57  18.37  18.54  16325400\n",
      "2017-11-07 15:00:00  18.42  18.54  18.31  18.42  25851000\n",
      "2017-11-08 15:00:00  18.49  18.54  18.37  18.39  18072100\n",
      "2017-11-09 15:00:00  18.42  18.57  18.37  18.52  18491300\n",
      "2017-11-10 15:00:00  18.34  18.44  18.29  18.39  22069400\n",
      "2017-11-13 15:00:00  18.52  18.67  18.37  18.37  32652900\n",
      "2017-11-14 15:00:00  18.47  18.54  18.37  18.49  17558800\n",
      "2017-11-15 15:00:00  18.44  18.52  18.42  18.44  20685900\n",
      "2017-11-16 15:00:00  18.29  18.47  18.26  18.42  15980300\n",
      "2017-11-17 15:00:00  18.77  18.79  18.19  18.31  74809300\n",
      "2017-11-20 15:00:00  18.72  18.82  18.49  18.54  36212200\n",
      "\n",
      "[207 rows x 5 columns]), ('601186.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  13.86  13.95  13.71  13.78   50295586\n",
      "2017-01-04 15:00:00  14.09  14.31  13.86  13.90   87136945\n",
      "2017-01-05 15:00:00  14.02  14.12  13.88  14.00   64009835\n",
      "2017-01-06 15:00:00  13.93  14.11  13.88  14.01   48604588\n",
      "2017-01-09 15:00:00  13.96  14.00  13.77  13.94   54153080\n",
      "2017-01-10 15:00:00  13.68  13.95  13.66  13.94   57429289\n",
      "2017-01-11 15:00:00  13.59  13.85  13.44  13.68   54614035\n",
      "2017-01-12 15:00:00  13.51  13.80  13.47  13.55   38118696\n",
      "2017-01-13 15:00:00  13.56  13.62  13.38  13.45   48410531\n",
      "2017-01-16 15:00:00  13.70  13.80  12.96  13.40   99359100\n",
      "2017-01-17 15:00:00  13.60  13.67  13.43  13.59   25050382\n",
      "2017-01-18 15:00:00  13.87  14.04  13.58  13.65   81485838\n",
      "2017-01-19 15:00:00  13.86  14.07  13.77  13.78   46955313\n",
      "2017-01-20 15:00:00  13.98  14.00  13.78  13.81   32757694\n",
      "2017-01-23 15:00:00  14.01  14.12  13.88  14.08   34746218\n",
      "2017-01-24 15:00:00  14.04  14.12  13.94  14.01   39635611\n",
      "2017-01-25 15:00:00  14.24  14.37  13.98  14.05   53242491\n",
      "2017-01-26 15:00:00  14.18  14.41  14.10  14.24   39525100\n",
      "2017-02-03 15:00:00  14.16  14.32  14.11  14.17   33215709\n",
      "2017-02-06 15:00:00  14.28  14.42  14.13  14.13   50369077\n",
      "2017-02-07 15:00:00  14.08  14.31  13.96  14.24   41725729\n",
      "2017-02-08 15:00:00  14.08  14.13  13.85  14.09   37043158\n",
      "2017-02-09 15:00:00  14.56  14.63  14.01  14.05  125505046\n",
      "2017-02-10 15:00:00  14.95  15.44  14.62  14.65  165835117\n",
      "2017-02-13 15:00:00  15.05  15.40  14.92  15.13  102810685\n",
      "2017-02-14 15:00:00  15.54  15.55  15.01  15.06  100988352\n",
      "2017-02-15 15:00:00  15.13  15.50  15.03  15.44   96316689\n",
      "2017-02-16 15:00:00  15.14  15.24  15.02  15.09   51224869\n",
      "2017-02-17 15:00:00  14.85  15.17  14.77  15.14   65191852\n",
      "2017-02-20 15:00:00  15.13  15.17  14.83  14.86   76616719\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  13.89  13.92  13.80  13.87    7681100\n",
      "2017-10-11 15:00:00  13.86  13.92  13.81  13.87    8914500\n",
      "2017-10-12 15:00:00  13.77  13.89  13.72  13.85   10442600\n",
      "2017-10-13 15:00:00  13.78  13.79  13.68  13.77   10222100\n",
      "2017-10-16 15:00:00  13.87  13.96  13.79  13.80   15886400\n",
      "2017-10-17 15:00:00  13.79  13.88  13.75  13.82   10791100\n",
      "2017-10-18 15:00:00  13.71  13.88  13.70  13.79   11082700\n",
      "2017-10-19 15:00:00  13.34  13.73  13.33  13.73   20112200\n",
      "2017-10-20 15:00:00  13.42  13.45  13.30  13.36    9784200\n",
      "2017-10-23 15:00:00  13.36  13.42  13.21  13.42   14137700\n",
      "2017-10-24 15:00:00  13.58  13.59  13.29  13.32   19821000\n",
      "2017-10-25 15:00:00  13.60  13.71  13.55  13.56   11613100\n",
      "2017-10-26 15:00:00  14.05  14.16  13.53  13.62   46312800\n",
      "2017-10-27 15:00:00  13.83  14.07  13.81  14.01   19332200\n",
      "2017-10-30 15:00:00  13.89  14.02  13.73  13.87   27206700\n",
      "2017-10-31 15:00:00  13.81  13.98  13.71  13.98   16870600\n",
      "2017-11-01 15:00:00  14.24  14.35  13.78  13.85   46653300\n",
      "2017-11-02 15:00:00  14.27  14.34  14.07  14.23   31650200\n",
      "2017-11-03 15:00:00  14.33  14.34  13.92  14.22   37550600\n",
      "2017-11-06 15:00:00  14.23  14.28  14.11  14.25   17380600\n",
      "2017-11-07 15:00:00  14.26  14.40  14.11  14.17   25019200\n",
      "2017-11-08 15:00:00  14.10  14.19  14.00  14.18   25561900\n",
      "2017-11-09 15:00:00  14.08  14.13  13.98  14.11   15742400\n",
      "2017-11-10 15:00:00  13.68  14.07  13.68  14.07   30202800\n",
      "2017-11-13 15:00:00  13.62  13.74  13.47  13.63   19410800\n",
      "2017-11-14 15:00:00  13.45  13.60  13.41  13.59   25212700\n",
      "2017-11-15 15:00:00  13.45  13.52  13.33  13.37   15011800\n",
      "2017-11-16 15:00:00  13.30  13.49  13.29  13.38   15830200\n",
      "2017-11-17 15:00:00  13.68  13.72  13.25  13.25   34621100\n",
      "2017-11-20 15:00:00  13.56  13.71  13.44  13.57   17016200\n",
      "\n",
      "[215 rows x 5 columns]), ('601198.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  20.53  20.59  20.33  20.35  10780413\n",
      "2017-01-04 15:00:00  20.56  20.58  20.40  20.51   9342823\n",
      "2017-01-05 15:00:00  20.40  20.54  20.36  20.54   7111448\n",
      "2017-01-06 15:00:00  19.95  20.38  19.95  20.37  10517361\n",
      "2017-01-09 15:00:00  20.01  20.11  19.89  19.98   6969826\n",
      "2017-01-10 15:00:00  19.84  20.07  19.80  20.00   7971149\n",
      "2017-01-11 15:00:00  19.78  19.99  19.74  19.84   6913478\n",
      "2017-01-12 15:00:00  19.60  19.90  19.57  19.77   7347497\n",
      "2017-01-13 15:00:00  19.60  19.69  19.31  19.59  10515529\n",
      "2017-01-16 15:00:00  19.78  19.82  18.87  19.57  22913945\n",
      "2017-01-17 15:00:00  19.43  19.60  19.22  19.59   7528070\n",
      "2017-01-18 15:00:00  19.28  19.55  19.25  19.44   5159364\n",
      "2017-01-19 15:00:00  19.30  19.46  19.19  19.28   5514908\n",
      "2017-01-20 15:00:00  19.44  19.54  19.24  19.28   6213296\n",
      "2017-01-23 15:00:00  19.48  19.59  19.39  19.41   5365684\n",
      "2017-01-24 15:00:00  19.36  19.48  19.35  19.47   4756825\n",
      "2017-01-25 15:00:00  19.36  19.43  19.32  19.35   3993245\n",
      "2017-01-26 15:00:00  19.47  19.56  19.37  19.39   5693061\n",
      "2017-02-03 15:00:00  19.43  19.52  19.41  19.49   3581607\n",
      "2017-02-06 15:00:00  19.49  19.50  19.36  19.45   5019867\n",
      "2017-02-07 15:00:00  19.27  19.50  19.15  19.50   7772744\n",
      "2017-02-08 15:00:00  19.76  19.88  19.00  19.27  17232535\n",
      "2017-02-09 15:00:00  19.73  19.85  19.62  19.69  11221564\n",
      "2017-02-10 15:00:00  19.69  19.92  19.57  19.71  16338234\n",
      "2017-02-13 15:00:00  19.85  20.02  19.67  19.73  14482295\n",
      "2017-02-14 15:00:00  19.85  20.05  19.83  19.91  11183003\n",
      "2017-02-15 15:00:00  19.58  19.98  19.55  19.81  12467650\n",
      "2017-02-16 15:00:00  19.89  19.95  19.51  19.56  14816697\n",
      "2017-02-17 15:00:00  19.98  20.79  19.91  19.96  39823711\n",
      "2017-02-20 15:00:00  20.07  20.09  19.62  19.85  15748054\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  18.62  18.83  18.46  18.83   5244400\n",
      "2017-10-11 15:00:00  18.50  18.62  18.49  18.62   2968800\n",
      "2017-10-12 15:00:00  18.27  18.57  18.26  18.52   3210100\n",
      "2017-10-13 15:00:00  18.32  18.42  18.29  18.33   2306400\n",
      "2017-10-16 15:00:00  18.17  18.48  18.15  18.31   3112600\n",
      "2017-10-17 15:00:00  17.92  18.23  17.91  18.23   3541600\n",
      "2017-10-18 15:00:00  18.09  18.13  17.92  17.95   3970300\n",
      "2017-10-19 15:00:00  17.55  18.04  17.54  18.01   3580800\n",
      "2017-10-20 15:00:00  17.59  17.61  17.44  17.44   1413000\n",
      "2017-10-23 15:00:00  17.57  17.62  17.48  17.61   1465300\n",
      "2017-10-24 15:00:00  17.81  17.83  17.49  17.53   4322000\n",
      "2017-10-25 15:00:00  17.81  17.84  17.66  17.76   1498900\n",
      "2017-10-26 15:00:00  17.84  17.99  17.70  17.71   1931800\n",
      "2017-10-27 15:00:00  17.57  17.86  17.56  17.86   1822300\n",
      "2017-10-30 15:00:00  17.42  17.68  17.02  17.60   3998600\n",
      "2017-10-31 15:00:00  17.29  17.40  17.25  17.30   1587500\n",
      "2017-11-01 15:00:00  17.13  17.56  17.02  17.29   2776900\n",
      "2017-11-02 15:00:00  17.21  17.48  17.08  17.13   3191800\n",
      "2017-11-03 15:00:00  17.29  17.31  17.02  17.19   3452000\n",
      "2017-11-06 15:00:00  17.29  17.29  17.11  17.21   1717900\n",
      "2017-11-07 15:00:00  17.47  17.57  17.28  17.28   3315500\n",
      "2017-11-08 15:00:00  17.70  18.08  17.41  17.41   6410700\n",
      "2017-11-09 15:00:00  17.61  17.71  17.53  17.59   2817500\n",
      "2017-11-10 15:00:00  17.46  17.74  17.37  17.61   3811000\n",
      "2017-11-13 15:00:00  17.44  17.65  17.42  17.51   2388400\n",
      "2017-11-14 15:00:00  17.24  17.54  17.20  17.46   2505200\n",
      "2017-11-15 15:00:00  17.24  17.33  17.16  17.21   2188000\n",
      "2017-11-16 15:00:00  16.94  17.27  16.92  17.27   2269800\n",
      "2017-11-17 15:00:00  17.41  17.45  16.52  16.94   8478500\n",
      "2017-11-20 15:00:00  17.34  17.43  17.10  17.23   3068600\n",
      "\n",
      "[215 rows x 5 columns]), ('601211.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  19.37  19.47  19.18  19.18  24331502\n",
      "2017-01-04 15:00:00  19.42  19.44  19.26  19.36  20948938\n",
      "2017-01-05 15:00:00  19.33  19.51  19.28  19.40  18707986\n",
      "2017-01-06 15:00:00  19.15  19.35  19.14  19.29  19333339\n",
      "2017-01-09 15:00:00  19.30  19.40  19.11  19.15  18779080\n",
      "2017-01-10 15:00:00  19.27  19.48  19.24  19.27  16695724\n",
      "2017-01-11 15:00:00  19.30  19.49  19.24  19.26  23336570\n",
      "2017-01-12 15:00:00  19.38  19.52  19.27  19.29  29228107\n",
      "2017-01-13 15:00:00  19.42  19.48  19.18  19.38  38189124\n",
      "2017-01-16 15:00:00  19.63  19.74  18.91  19.37  82882703\n",
      "2017-01-17 15:00:00  19.51  19.55  19.30  19.47  18978438\n",
      "2017-01-18 15:00:00  19.59  19.70  19.41  19.50  20679226\n",
      "2017-01-19 15:00:00  19.65  19.86  19.47  19.54  23486502\n",
      "2017-01-20 15:00:00  19.90  19.91  19.67  19.69  28650717\n",
      "2017-01-23 15:00:00  19.80  19.94  19.69  19.93  30479771\n",
      "2017-01-24 15:00:00  19.68  19.82  19.61  19.78  19747036\n",
      "2017-01-25 15:00:00  19.69  19.78  19.60  19.65  19171425\n",
      "2017-01-26 15:00:00  19.82  19.90  19.71  19.71  27545500\n",
      "2017-02-03 15:00:00  19.63  19.87  19.58  19.83  14266766\n",
      "2017-02-06 15:00:00  19.57  19.70  19.41  19.70  20482799\n",
      "2017-02-07 15:00:00  19.42  19.58  19.35  19.54  21628154\n",
      "2017-02-08 15:00:00  19.69  19.74  19.24  19.42  33961731\n",
      "2017-02-09 15:00:00  19.71  19.83  19.58  19.61  31764825\n",
      "2017-02-10 15:00:00  19.86  20.02  19.66  19.74  35675368\n",
      "2017-02-13 15:00:00  19.87  20.13  19.82  19.91  40832725\n",
      "2017-02-14 15:00:00  19.91  20.05  19.85  19.89  23627715\n",
      "2017-02-15 15:00:00  19.82  20.17  19.74  19.91  40201065\n",
      "2017-02-16 15:00:00  20.02  20.10  19.65  19.82  37432511\n",
      "2017-02-17 15:00:00  19.92  20.55  19.88  20.15  73730132\n",
      "2017-02-20 15:00:00  20.21  20.22  19.79  19.83  46427796\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  22.54  22.89  22.34  22.75  16090600\n",
      "2017-10-11 15:00:00  22.57  22.74  22.41  22.60  10166400\n",
      "2017-10-12 15:00:00  22.43  22.74  22.35  22.58   9186400\n",
      "2017-10-13 15:00:00  22.42  22.54  22.38  22.46   5448200\n",
      "2017-10-16 15:00:00  22.40  22.68  22.36  22.41   8111500\n",
      "2017-10-17 15:00:00  22.19  22.46  22.18  22.36   6889600\n",
      "2017-10-18 15:00:00  22.50  22.52  22.16  22.23  11370200\n",
      "2017-10-19 15:00:00  22.38  22.45  21.76  22.38  16457200\n",
      "2017-10-20 15:00:00  22.03  22.20  22.01  22.20   6167800\n",
      "2017-10-23 15:00:00  21.83  22.04  21.80  22.00   4438300\n",
      "2017-10-24 15:00:00  22.09  22.18  21.80  21.80  10233200\n",
      "2017-10-25 15:00:00  22.08  22.15  21.89  22.10   6290800\n",
      "2017-10-26 15:00:00  21.96  22.27  21.92  22.05  12969300\n",
      "2017-10-27 15:00:00  21.62  22.04  21.61  21.98  10078900\n",
      "2017-10-30 15:00:00  21.30  21.70  20.87  21.61  20404500\n",
      "2017-10-31 15:00:00  21.06  21.19  20.97  21.15   7733900\n",
      "2017-11-01 15:00:00  20.96  21.24  20.91  21.15   7535600\n",
      "2017-11-02 15:00:00  21.00  21.16  20.71  20.91   9947300\n",
      "2017-11-03 15:00:00  21.08  21.11  20.74  21.01   9990700\n",
      "2017-11-06 15:00:00  21.11  21.11  20.99  21.05   4854400\n",
      "2017-11-07 15:00:00  21.32  21.42  21.04  21.13  10559400\n",
      "2017-11-08 15:00:00  21.58  22.01  21.21  21.30  20040700\n",
      "2017-11-09 15:00:00  21.52  21.64  21.37  21.49   8347200\n",
      "2017-11-10 15:00:00  21.42  21.57  21.25  21.52   8771900\n",
      "2017-11-13 15:00:00  21.35  21.84  21.32  21.46  10462400\n",
      "2017-11-14 15:00:00  21.17  21.52  21.10  21.46   7583300\n",
      "2017-11-15 15:00:00  21.11  21.28  20.97  21.13  10547700\n",
      "2017-11-16 15:00:00  20.81  21.13  20.80  21.05   8125900\n",
      "2017-11-17 15:00:00  21.46  21.49  20.68  20.81  26350900\n",
      "2017-11-20 15:00:00  21.35  21.45  21.03  21.24  13184500\n",
      "\n",
      "[215 rows x 5 columns]), ('601229.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  23.59  23.78  23.31  23.33  20628485\n",
      "2017-01-04 15:00:00  23.71  23.80  23.55  23.59  17730203\n",
      "2017-01-05 15:00:00  23.51  23.76  23.47  23.74  17999621\n",
      "2017-01-06 15:00:00  23.17  23.56  23.12  23.45  20938854\n",
      "2017-01-09 15:00:00  23.24  23.30  23.08  23.12  12150030\n",
      "2017-01-10 15:00:00  22.98  23.23  22.96  23.23  17279254\n",
      "2017-01-11 15:00:00  22.53  22.94  22.45  22.91  25748350\n",
      "2017-01-12 15:00:00  22.30  22.61  22.28  22.48  15840549\n",
      "2017-01-13 15:00:00  22.04  22.30  21.90  22.25  23056066\n",
      "2017-01-16 15:00:00  22.43  22.64  21.88  22.05  40312335\n",
      "2017-01-17 15:00:00  22.45  22.55  22.08  22.24  22653272\n",
      "2017-01-18 15:00:00  22.30  22.46  22.26  22.39  16158086\n",
      "2017-01-19 15:00:00  22.54  22.73  22.12  22.23  25786422\n",
      "2017-01-20 15:00:00  22.94  23.04  22.45  22.48  34552897\n",
      "2017-01-23 15:00:00  23.03  23.27  22.90  22.91  27194865\n",
      "2017-01-24 15:00:00  22.96  23.05  22.88  23.04  11467673\n",
      "2017-01-25 15:00:00  23.03  23.10  22.81  22.88  10965625\n",
      "2017-01-26 15:00:00  23.28  23.29  23.06  23.06  17481967\n",
      "2017-02-03 15:00:00  22.94  23.32  22.90  23.28  11706985\n",
      "2017-02-06 15:00:00  23.04  23.12  22.89  22.97  11599300\n",
      "2017-02-07 15:00:00  22.80  23.04  22.71  23.03  14340470\n",
      "2017-02-08 15:00:00  23.02  23.03  22.60  22.80  16720735\n",
      "2017-02-09 15:00:00  23.12  23.22  22.92  22.98  21611436\n",
      "2017-02-10 15:00:00  23.45  23.69  23.10  23.14  40957967\n",
      "2017-02-13 15:00:00  24.12  24.59  23.46  23.46  64062244\n",
      "2017-02-14 15:00:00  23.88  24.24  23.66  24.16  29432249\n",
      "2017-02-15 15:00:00  24.12  24.56  23.76  23.85  55655734\n",
      "2017-02-16 15:00:00  24.19  24.35  23.83  24.06  39369956\n",
      "2017-02-17 15:00:00  23.71  24.35  23.69  24.00  35575002\n",
      "2017-02-20 15:00:00  24.93  25.25  23.61  23.65  83256961\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  18.06  18.06  17.96  17.97   2013000\n",
      "2017-10-11 15:00:00  17.99  18.12  17.95  18.10   1935300\n",
      "2017-10-12 15:00:00  17.93  18.02  17.90  18.00   1795800\n",
      "2017-10-13 15:00:00  17.89  17.95  17.83  17.93   2757700\n",
      "2017-10-16 15:00:00  17.83  17.91  17.80  17.90   3134800\n",
      "2017-10-17 15:00:00  17.89  17.90  17.81  17.83   2029900\n",
      "2017-10-18 15:00:00  17.72  17.90  17.71  17.89   3079600\n",
      "2017-10-19 15:00:00  17.46  17.75  17.45  17.71   4279400\n",
      "2017-10-20 15:00:00  17.53  17.59  17.42  17.50   1863600\n",
      "2017-10-23 15:00:00  17.47  17.53  17.40  17.51   2329400\n",
      "2017-10-24 15:00:00  17.35  17.49  17.31  17.45   3030600\n",
      "2017-10-25 15:00:00  17.39  17.43  17.31  17.35   2040600\n",
      "2017-10-26 15:00:00  17.50  17.51  17.32  17.38   2774000\n",
      "2017-10-27 15:00:00  17.65  17.76  17.45  17.47   5317800\n",
      "2017-10-30 15:00:00  17.56  17.74  17.43  17.65   4574700\n",
      "2017-10-31 15:00:00  17.62  17.69  17.51  17.53   2648200\n",
      "2017-11-01 15:00:00  17.45  17.64  17.37  17.64   3878000\n",
      "2017-11-02 15:00:00  17.44  17.46  17.34  17.40   3153100\n",
      "2017-11-03 15:00:00  17.14  17.45  17.12  17.41   3186100\n",
      "2017-11-06 15:00:00  17.11  17.17  16.99  17.12   2053600\n",
      "2017-11-07 15:00:00  17.35  17.36  17.12  17.12   2728700\n",
      "2017-11-08 15:00:00  17.39  17.50  17.25  17.28   3009000\n",
      "2017-11-09 15:00:00  17.30  17.38  17.23  17.35   2709500\n",
      "2017-11-10 15:00:00  17.18  17.28  17.13  17.21   2956700\n",
      "2017-11-13 15:00:00  17.55  17.75  17.06  17.09   9161800\n",
      "2017-11-14 15:00:00  17.25  17.51  17.23  17.43   5347800\n",
      "2017-11-15 15:00:00  17.12  17.30  17.10  17.20   3384300\n",
      "2017-11-16 15:00:00  15.41  15.41  15.41  15.41  15317200\n",
      "2017-11-17 15:00:00  15.08  15.41  14.18  14.18  69571900\n",
      "2017-11-20 15:00:00  15.09  15.15  14.57  14.57  57863000\n",
      "\n",
      "[215 rows x 5 columns]), ('601288.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   4.25  4.25  4.19  4.21  196742138\n",
      "2017-01-04 15:00:00   4.25  4.26  4.22  4.23  170689499\n",
      "2017-01-05 15:00:00   4.23  4.26  4.23  4.25  109437941\n",
      "2017-01-06 15:00:00   4.25  4.25  4.23  4.25  102293021\n",
      "2017-01-09 15:00:00   4.25  4.25  4.23  4.25  119507777\n",
      "2017-01-10 15:00:00   4.25  4.25  4.23  4.23  111608716\n",
      "2017-01-11 15:00:00   4.23  4.25  4.22  4.23  133690908\n",
      "2017-01-12 15:00:00   4.23  4.23  4.22  4.23   70060174\n",
      "2017-01-13 15:00:00   4.25  4.25  4.22  4.22  191580152\n",
      "2017-01-16 15:00:00   4.29  4.33  4.22  4.23  591578755\n",
      "2017-01-17 15:00:00   4.26  4.27  4.26  4.27  109513815\n",
      "2017-01-18 15:00:00   4.27  4.29  4.26  4.27  129814355\n",
      "2017-01-19 15:00:00   4.27  4.30  4.27  4.27  167097103\n",
      "2017-01-20 15:00:00   4.29  4.30  4.27  4.27  104237850\n",
      "2017-01-23 15:00:00   4.30  4.30  4.29  4.29  119371911\n",
      "2017-01-24 15:00:00   4.31  4.33  4.29  4.29  144529885\n",
      "2017-01-25 15:00:00   4.33  4.33  4.31  4.31   84775030\n",
      "2017-01-26 15:00:00   4.35  4.35  4.33  4.33   98947846\n",
      "2017-02-03 15:00:00   4.31  4.35  4.31  4.35   88652597\n",
      "2017-02-06 15:00:00   4.31  4.33  4.30  4.33  106306087\n",
      "2017-02-07 15:00:00   4.31  4.33  4.30  4.31   91980836\n",
      "2017-02-08 15:00:00   4.30  4.31  4.29  4.30  116499103\n",
      "2017-02-09 15:00:00   4.33  4.33  4.30  4.30  113199983\n",
      "2017-02-10 15:00:00   4.34  4.34  4.31  4.33  149269568\n",
      "2017-02-13 15:00:00   4.38  4.38  4.33  4.34  176126841\n",
      "2017-02-14 15:00:00   4.37  4.38  4.35  4.37   86673124\n",
      "2017-02-15 15:00:00   4.46  4.48  4.35  4.37  496183012\n",
      "2017-02-16 15:00:00   4.46  4.48  4.44  4.46  243779135\n",
      "2017-02-17 15:00:00   4.41  4.46  4.41  4.46  214862241\n",
      "2017-02-20 15:00:00   4.44  4.49  4.40  4.41  912158455\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   5.13  5.17  5.07  5.14  142608900\n",
      "2017-10-11 15:00:00   5.21  5.22  5.11  5.13  124651900\n",
      "2017-10-12 15:00:00   5.15  5.24  5.14  5.20  143030500\n",
      "2017-10-13 15:00:00   5.10  5.17  5.10  5.15  121193800\n",
      "2017-10-16 15:00:00   5.15  5.17  5.10  5.13  108691000\n",
      "2017-10-17 15:00:00   5.10  5.17  5.10  5.15  115668000\n",
      "2017-10-18 15:00:00   5.18  5.20  5.10  5.13  134494300\n",
      "2017-10-19 15:00:00   5.22  5.22  5.15  5.18  105437900\n",
      "2017-10-20 15:00:00   5.20  5.22  5.17  5.21   76089300\n",
      "2017-10-23 15:00:00   5.13  5.21  5.13  5.20   80939300\n",
      "2017-10-24 15:00:00   5.15  5.17  5.13  5.14   90662700\n",
      "2017-10-25 15:00:00   5.11  5.17  5.09  5.15   96342000\n",
      "2017-10-26 15:00:00   5.02  5.10  4.99  5.10  213369100\n",
      "2017-10-27 15:00:00   5.05  5.09  4.99  5.01  222736700\n",
      "2017-10-30 15:00:00   5.07  5.11  5.03  5.05  174958300\n",
      "2017-10-31 15:00:00   5.07  5.13  5.07  5.09  126491800\n",
      "2017-11-01 15:00:00   5.06  5.09  5.01  5.07  136903800\n",
      "2017-11-02 15:00:00   5.05  5.06  4.99  5.03  129428200\n",
      "2017-11-03 15:00:00   5.05  5.06  4.99  5.03  126360100\n",
      "2017-11-06 15:00:00   4.99  5.03  4.97  5.03  111458900\n",
      "2017-11-07 15:00:00   5.03  5.05  4.97  4.99  145092100\n",
      "2017-11-08 15:00:00   5.03  5.05  4.99  5.02  134333800\n",
      "2017-11-09 15:00:00   4.99  5.02  4.98  5.02   88747400\n",
      "2017-11-10 15:00:00   4.92  4.99  4.90  4.98  148707100\n",
      "2017-11-13 15:00:00   4.94  4.98  4.88  4.92  345475000\n",
      "2017-11-14 15:00:00   4.90  4.92  4.88  4.91   91586800\n",
      "2017-11-15 15:00:00   4.90  4.91  4.86  4.90  135782300\n",
      "2017-11-16 15:00:00   4.84  4.90  4.83  4.88  111749100\n",
      "2017-11-17 15:00:00   4.97  4.98  4.84  4.84  305244000\n",
      "2017-11-20 15:00:00   4.98  5.01  4.91  4.94  160366500\n",
      "\n",
      "[215 rows x 5 columns]), ('601318.XSHG',                       close    high     low    open     volume\n",
      "datetime                                                      \n",
      "2017-01-03 15:00:00   79.89   80.65   79.11   79.15   29687099\n",
      "2017-01-04 15:00:00   79.87   80.16   79.53   79.94   25257305\n",
      "2017-01-05 15:00:00   80.02   80.50   79.91   80.02   28689533\n",
      "2017-01-06 15:00:00   79.38   80.38   79.17   80.02   36284227\n",
      "2017-01-09 15:00:00   79.38   79.62   78.99   79.44   27061697\n",
      "2017-01-10 15:00:00   78.90   79.49   78.84   79.38   20534990\n",
      "2017-01-11 15:00:00   78.90   79.35   78.61   78.95   20993849\n",
      "2017-01-12 15:00:00   78.82   79.33   78.73   79.06   18718503\n",
      "2017-01-13 15:00:00   79.60   80.41   78.82   78.90   33069097\n",
      "2017-01-16 15:00:00   81.01   81.26   78.86   79.64  112904327\n",
      "2017-01-17 15:00:00   80.58   81.39   80.38   80.79   34949314\n",
      "2017-01-18 15:00:00   81.12   81.61   80.76   80.79   26686911\n",
      "2017-01-19 15:00:00   80.76   81.46   80.45   80.92   19962234\n",
      "2017-01-20 15:00:00   81.21   81.26   80.65   80.74   26025277\n",
      "2017-01-23 15:00:00   81.05   81.57   80.72   81.21   39800028\n",
      "2017-01-24 15:00:00   81.03   81.37   80.85   81.08   26866560\n",
      "2017-01-25 15:00:00   81.61   81.61   80.83   81.08   35887232\n",
      "2017-01-26 15:00:00   81.79   82.42   81.61   81.64   27719342\n",
      "2017-02-03 15:00:00   79.85   81.75   79.73   81.75   48925754\n",
      "2017-02-06 15:00:00   80.52   80.70   79.58   80.05   64881020\n",
      "2017-02-07 15:00:00   80.79   81.17   80.45   80.63   48607800\n",
      "2017-02-08 15:00:00   80.70   80.81   79.96   80.72   39626363\n",
      "2017-02-09 15:00:00   80.88   81.46   80.63   80.79   52754485\n",
      "2017-02-10 15:00:00   81.08   81.39   80.85   81.10   39921500\n",
      "2017-02-13 15:00:00   81.28   81.55   81.01   81.28   69351590\n",
      "2017-02-14 15:00:00   80.85   81.53   80.52   81.53   49092275\n",
      "2017-02-15 15:00:00   81.41   81.70   81.10   81.23   67273226\n",
      "2017-02-16 15:00:00   81.32   81.59   81.05   81.57   34775514\n",
      "2017-02-17 15:00:00   81.21   82.11   81.08   81.44   52550389\n",
      "2017-02-20 15:00:00   82.47   82.62   81.19   81.32   74110223\n",
      "...                     ...     ...     ...     ...        ...\n",
      "2017-10-10 15:00:00  123.00  124.30  120.59  123.07   47406600\n",
      "2017-10-11 15:00:00  123.88  124.77  122.18  122.94   31370100\n",
      "2017-10-12 15:00:00  127.91  128.04  123.52  123.54   45931600\n",
      "2017-10-13 15:00:00  127.84  128.63  127.10  127.53   25354500\n",
      "2017-10-16 15:00:00  128.04  131.07  127.86  128.78   37100400\n",
      "2017-10-17 15:00:00  129.77  130.49  128.13  128.96   33252100\n",
      "2017-10-18 15:00:00  132.10  132.17  129.63  130.22   35861700\n",
      "2017-10-19 15:00:00  133.46  134.27  131.74  132.34   36407300\n",
      "2017-10-20 15:00:00  132.19  133.11  131.36  132.21   21080500\n",
      "2017-10-23 15:00:00  134.11  134.79  132.61  133.91   24067100\n",
      "2017-10-24 15:00:00  134.83  136.76  133.78  133.87   35504100\n",
      "2017-10-25 15:00:00  134.56  135.35  133.76  134.38   18311600\n",
      "2017-10-26 15:00:00  137.50  139.38  134.09  134.38   41888900\n",
      "2017-10-27 15:00:00  143.18  143.25  137.74  137.74   43469300\n",
      "2017-10-30 15:00:00  143.48  146.21  141.46  143.30   58635600\n",
      "2017-10-31 15:00:00  144.15  144.42  141.95  142.22   25338200\n",
      "2017-11-01 15:00:00  143.61  148.40  142.76  144.46   49136000\n",
      "2017-11-02 15:00:00  143.65  144.13  141.17  143.95   42341900\n",
      "2017-11-03 15:00:00  144.35  145.20  142.18  143.12   34443700\n",
      "2017-11-06 15:00:00  143.36  144.80  140.99  144.80   45454800\n",
      "2017-11-07 15:00:00  146.41  149.03  144.15  144.15   57524500\n",
      "2017-11-08 15:00:00  144.71  148.58  144.10  146.59   43670000\n",
      "2017-11-09 15:00:00  148.56  148.67  144.26  144.69   34959100\n",
      "2017-11-10 15:00:00  156.53  156.65  147.71  147.71   62667000\n",
      "2017-11-13 15:00:00  157.12  158.06  155.66  157.34   38658500\n",
      "2017-11-14 15:00:00  157.72  159.62  156.29  158.39   39285200\n",
      "2017-11-15 15:00:00  154.99  157.72  153.64  156.56   51015200\n",
      "2017-11-16 15:00:00  163.52  163.72  154.32  154.47   58419700\n",
      "2017-11-17 15:00:00  168.58  168.69  160.97  162.69   77105700\n",
      "2017-11-20 15:00:00  169.57  171.27  166.19  167.46   55528000\n",
      "\n",
      "[215 rows x 5 columns]), ('601328.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00   9.28   9.32   9.19   9.19   94295692\n",
      "2017-01-04 15:00:00   9.30   9.35   9.24   9.27  100679109\n",
      "2017-01-05 15:00:00   9.25   9.32   9.25   9.30   55040486\n",
      "2017-01-06 15:00:00   9.24   9.27   9.20   9.27   68754796\n",
      "2017-01-09 15:00:00   9.25   9.28   9.22   9.25   47078935\n",
      "2017-01-10 15:00:00   9.27   9.28   9.22   9.25   46713227\n",
      "2017-01-11 15:00:00   9.25   9.30   9.24   9.27   56385175\n",
      "2017-01-12 15:00:00   9.25   9.30   9.24   9.25   44715663\n",
      "2017-01-13 15:00:00   9.32   9.38   9.24   9.27   93628631\n",
      "2017-01-16 15:00:00   9.48   9.52   9.30   9.33  209964282\n",
      "2017-01-17 15:00:00   9.41   9.51   9.40   9.43   56611375\n",
      "2017-01-18 15:00:00   9.48   9.48   9.41   9.44   56721220\n",
      "2017-01-19 15:00:00   9.48   9.59   9.43   9.46   65680412\n",
      "2017-01-20 15:00:00   9.54   9.60   9.43   9.49   66371597\n",
      "2017-01-23 15:00:00   9.48   9.59   9.43   9.56   76855573\n",
      "2017-01-24 15:00:00   9.56   9.59   9.48   9.49   70548075\n",
      "2017-01-25 15:00:00   9.54   9.59   9.51   9.54   55537767\n",
      "2017-01-26 15:00:00   9.64   9.70   9.56   9.57   63626910\n",
      "2017-02-03 15:00:00   9.54   9.65   9.52   9.65   37743392\n",
      "2017-02-06 15:00:00   9.56   9.62   9.52   9.56   44537027\n",
      "2017-02-07 15:00:00   9.51   9.59   9.48   9.56   49516289\n",
      "2017-02-08 15:00:00   9.54   9.54   9.48   9.51   38729565\n",
      "2017-02-09 15:00:00   9.60   9.62   9.52   9.52   43595589\n",
      "2017-02-10 15:00:00   9.64   9.65   9.59   9.60   51702548\n",
      "2017-02-13 15:00:00   9.70   9.73   9.65   9.65   63654896\n",
      "2017-02-14 15:00:00   9.67   9.70   9.64   9.68   37417916\n",
      "2017-02-15 15:00:00   9.80   9.84   9.67   9.68   95670805\n",
      "2017-02-16 15:00:00   9.84   9.91   9.78   9.84   71030179\n",
      "2017-02-17 15:00:00   9.78   9.92   9.78   9.86   61580715\n",
      "2017-02-20 15:00:00   9.99  10.10   9.76   9.78  149468631\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  10.20  10.23  10.10  10.12   41787900\n",
      "2017-10-11 15:00:00  10.20  10.24  10.13  10.20   38629600\n",
      "2017-10-12 15:00:00  10.10  10.21  10.10  10.18   39073400\n",
      "2017-10-13 15:00:00  10.08  10.16  10.08  10.12   25581400\n",
      "2017-10-16 15:00:00  10.15  10.15  10.08  10.13   29456000\n",
      "2017-10-17 15:00:00  10.07  10.15  10.07  10.15   41175300\n",
      "2017-10-18 15:00:00  10.15  10.16  10.07  10.08   43839200\n",
      "2017-10-19 15:00:00  10.21  10.21  10.12  10.15   44205200\n",
      "2017-10-20 15:00:00  10.16  10.20  10.13  10.20   18476100\n",
      "2017-10-23 15:00:00  10.10  10.16  10.10  10.15   27955900\n",
      "2017-10-24 15:00:00  10.15  10.20  10.08  10.12   34910000\n",
      "2017-10-25 15:00:00  10.10  10.18  10.08  10.13   28779800\n",
      "2017-10-26 15:00:00   9.99  10.12   9.96  10.10   58101000\n",
      "2017-10-27 15:00:00  10.04  10.10   9.96   9.97   42111100\n",
      "2017-10-30 15:00:00  10.00  10.08   9.94  10.07   53144500\n",
      "2017-10-31 15:00:00   9.94  10.00   9.92   9.97   29953600\n",
      "2017-11-01 15:00:00   9.86   9.96   9.84   9.94   49816700\n",
      "2017-11-02 15:00:00   9.88   9.89   9.78   9.86   34520800\n",
      "2017-11-03 15:00:00   9.91   9.94   9.81   9.86   59131700\n",
      "2017-11-06 15:00:00   9.84   9.91   9.83   9.88   29384300\n",
      "2017-11-07 15:00:00   9.92   9.96   9.83   9.86   59650200\n",
      "2017-11-08 15:00:00   9.94   9.99   9.89   9.91   50142500\n",
      "2017-11-09 15:00:00   9.86   9.96   9.84   9.92   39014900\n",
      "2017-11-10 15:00:00   9.76   9.86   9.75   9.86   57928600\n",
      "2017-11-13 15:00:00   9.80   9.89   9.76   9.78   69366000\n",
      "2017-11-14 15:00:00   9.72   9.80   9.68   9.78   55846700\n",
      "2017-11-15 15:00:00   9.70   9.73   9.65   9.72   35451000\n",
      "2017-11-16 15:00:00   9.67   9.72   9.64   9.72   31101700\n",
      "2017-11-17 15:00:00   9.94   9.97   9.65   9.67  127944800\n",
      "2017-11-20 15:00:00   9.92   9.97   9.81   9.91   76875200\n",
      "\n",
      "[215 rows x 5 columns]), ('601336.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  46.55  47.10  45.27  45.27   7842845\n",
      "2017-01-04 15:00:00  46.55  46.89  46.19  46.52   3761106\n",
      "2017-01-05 15:00:00  46.43  47.20  46.32  46.88   2822518\n",
      "2017-01-06 15:00:00  45.73  46.74  45.66  46.33   5750099\n",
      "2017-01-09 15:00:00  46.21  46.79  45.75  46.01   4605402\n",
      "2017-01-10 15:00:00  45.87  46.36  45.87  46.19   1278701\n",
      "2017-01-11 15:00:00  46.02  46.62  45.84  45.86   2949063\n",
      "2017-01-12 15:00:00  45.51  46.40  45.29  46.03   2318352\n",
      "2017-01-13 15:00:00  46.51  47.24  45.49  45.53  12192904\n",
      "2017-01-16 15:00:00  47.25  47.51  46.12  46.53  13630738\n",
      "2017-01-17 15:00:00  47.05  47.89  46.63  47.01   5603686\n",
      "2017-01-18 15:00:00  47.31  47.81  46.85  46.98   4203148\n",
      "2017-01-19 15:00:00  47.12  47.56  46.82  47.03   3076231\n",
      "2017-01-20 15:00:00  47.39  47.60  46.91  47.08   2554667\n",
      "2017-01-23 15:00:00  47.37  48.08  47.28  47.46   2960621\n",
      "2017-01-24 15:00:00  47.46  48.00  46.99  47.51   3763113\n",
      "2017-01-25 15:00:00  47.18  47.48  46.52  47.23   4851131\n",
      "2017-01-26 15:00:00  47.73  47.78  46.86  47.21   3238831\n",
      "2017-02-03 15:00:00  46.36  47.65  46.30  47.65   4024308\n",
      "2017-02-06 15:00:00  46.79  46.93  46.56  46.59   8914958\n",
      "2017-02-07 15:00:00  47.37  47.42  46.53  47.00   6653725\n",
      "2017-02-08 15:00:00  47.47  47.76  47.05  47.20   6148552\n",
      "2017-02-09 15:00:00  48.16  48.68  47.42  47.61   5674729\n",
      "2017-02-10 15:00:00  47.95  48.49  47.66  48.43   3632195\n",
      "2017-02-13 15:00:00  48.59  49.11  48.09  48.30   7393786\n",
      "2017-02-14 15:00:00  47.95  48.59  47.89  48.59   4022969\n",
      "2017-02-15 15:00:00  47.96  48.48  47.75  48.13   4370343\n",
      "2017-02-16 15:00:00  47.64  47.98  47.39  47.73   6389978\n",
      "2017-02-17 15:00:00  47.47  48.28  47.42  47.70   6797827\n",
      "2017-02-20 15:00:00  48.06  48.06  47.17  47.47   9455110\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  56.40  58.55  55.35  58.01  22649300\n",
      "2017-10-11 15:00:00  57.22  57.56  55.94  55.99  10729400\n",
      "2017-10-12 15:00:00  59.29  59.42  56.88  56.88  11119600\n",
      "2017-10-13 15:00:00  59.93  60.60  59.30  59.30  10336200\n",
      "2017-10-16 15:00:00  60.57  61.26  59.43  59.87   8812900\n",
      "2017-10-17 15:00:00  60.20  61.19  59.56  59.99   4187000\n",
      "2017-10-18 15:00:00  61.62  61.71  59.61  60.20   8314600\n",
      "2017-10-19 15:00:00  61.99  62.23  60.86  61.73   7514100\n",
      "2017-10-20 15:00:00  60.17  61.61  60.12  61.20   3754700\n",
      "2017-10-23 15:00:00  60.67  61.11  60.02  60.61   3271800\n",
      "2017-10-24 15:00:00  61.83  62.82  60.08  60.18   6572700\n",
      "2017-10-25 15:00:00  61.71  62.42  60.77  61.79   3906800\n",
      "2017-10-26 15:00:00  62.31  63.69  61.21  61.42   8090400\n",
      "2017-10-27 15:00:00  62.90  63.91  62.41  62.46   8674900\n",
      "2017-10-30 15:00:00  66.34  66.78  63.18  63.29  11132300\n",
      "2017-10-31 15:00:00  66.09  67.20  64.62  65.33   6537000\n",
      "2017-11-01 15:00:00  65.41  68.42  64.94  65.37   9816900\n",
      "2017-11-02 15:00:00  65.72  66.48  63.80  65.60   6902600\n",
      "2017-11-03 15:00:00  65.09  66.17  64.23  65.57   6328800\n",
      "2017-11-06 15:00:00  63.64  64.91  62.60  64.84   6921500\n",
      "2017-11-07 15:00:00  64.59  66.04  63.41  63.44   9230900\n",
      "2017-11-08 15:00:00  63.49  65.51  62.68  64.19   9921100\n",
      "2017-11-09 15:00:00  63.93  63.96  62.87  63.05   4911500\n",
      "2017-11-10 15:00:00  69.64  70.32  63.60  63.61  19953200\n",
      "2017-11-13 15:00:00  69.61  71.08  69.08  69.66  10523000\n",
      "2017-11-14 15:00:00  72.66  73.70  69.17  70.52  11823500\n",
      "2017-11-15 15:00:00  70.58  73.21  69.48  71.38   9567000\n",
      "2017-11-16 15:00:00  72.48  73.15  69.17  69.33  10869300\n",
      "2017-11-17 15:00:00  74.16  75.06  71.34  71.77  11220200\n",
      "2017-11-20 15:00:00  73.23  75.03  71.31  72.87   9684400\n",
      "\n",
      "[215 rows x 5 columns]), ('601390.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00   9.93  10.00   9.79   9.82   45706852\n",
      "2017-01-04 15:00:00  10.19  10.40   9.96   9.99   96250646\n",
      "2017-01-05 15:00:00  10.21  10.29  10.07  10.15   67223590\n",
      "2017-01-06 15:00:00  10.10  10.26  10.09  10.19   50827641\n",
      "2017-01-09 15:00:00  10.12  10.16  10.04  10.07   49215170\n",
      "2017-01-10 15:00:00   9.90  10.11   9.89  10.11   58535160\n",
      "2017-01-11 15:00:00   9.82  10.03   9.75   9.89   49541352\n",
      "2017-01-12 15:00:00   9.86   9.99   9.77   9.82   36823471\n",
      "2017-01-13 15:00:00   9.94   9.99   9.76   9.86   49146464\n",
      "2017-01-16 15:00:00  10.05  10.12   9.41   9.84  147514466\n",
      "2017-01-17 15:00:00   9.94  10.00   9.87   9.96   29393890\n",
      "2017-01-18 15:00:00  10.00  10.07   9.93   9.94   53717166\n",
      "2017-01-19 15:00:00   9.76   9.99   9.74   9.94   43181061\n",
      "2017-01-20 15:00:00   9.80   9.84   9.71   9.75   26665282\n",
      "2017-01-23 15:00:00   9.84   9.90   9.80   9.80   26760073\n",
      "2017-01-24 15:00:00   9.81   9.89   9.77   9.85   28715117\n",
      "2017-01-25 15:00:00   9.86   9.92   9.81   9.83   27126609\n",
      "2017-01-26 15:00:00   9.84   9.93   9.79   9.87   31151871\n",
      "2017-02-03 15:00:00   9.84   9.90   9.81   9.83   19467644\n",
      "2017-02-06 15:00:00   9.92   9.99   9.83   9.86   44379521\n",
      "2017-02-07 15:00:00   9.89   9.96   9.85   9.93   24428492\n",
      "2017-02-08 15:00:00   9.89   9.90   9.76   9.85   32110542\n",
      "2017-02-09 15:00:00  10.15  10.21   9.85   9.86  132998746\n",
      "2017-02-10 15:00:00  10.31  10.55  10.11  10.15  170529463\n",
      "2017-02-13 15:00:00  10.24  10.50  10.14  10.26  138385071\n",
      "2017-02-14 15:00:00  10.33  10.33  10.16  10.24   91556075\n",
      "2017-02-15 15:00:00  10.13  10.42  10.11  10.34  113560144\n",
      "2017-02-16 15:00:00  10.16  10.22  10.09  10.10   74702331\n",
      "2017-02-17 15:00:00  10.04  10.17  10.00  10.13   70684660\n",
      "2017-02-20 15:00:00  10.15  10.21  10.05  10.05   89840862\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00   9.71   9.72   9.65   9.66    8242900\n",
      "2017-10-11 15:00:00   9.72   9.76   9.69   9.73    9954500\n",
      "2017-10-12 15:00:00   9.66   9.72   9.64   9.71    6992000\n",
      "2017-10-13 15:00:00   9.64   9.69   9.63   9.65    7645000\n",
      "2017-10-16 15:00:00   9.75   9.86   9.64   9.66   23400800\n",
      "2017-10-17 15:00:00   9.80   9.85   9.72   9.73   14879900\n",
      "2017-10-18 15:00:00   9.74   9.85   9.73   9.85   10798600\n",
      "2017-10-19 15:00:00   9.54   9.77   9.53   9.77   15908400\n",
      "2017-10-20 15:00:00   9.54   9.57   9.49   9.52    9167000\n",
      "2017-10-23 15:00:00   9.52   9.56   9.50   9.55    9060200\n",
      "2017-10-24 15:00:00   9.75   9.79   9.50   9.51   24919800\n",
      "2017-10-25 15:00:00   9.75   9.84   9.73   9.79   21628800\n",
      "2017-10-26 15:00:00  10.09  10.19   9.72   9.75   85805300\n",
      "2017-10-27 15:00:00   9.97  10.14   9.94  10.03   37338900\n",
      "2017-10-30 15:00:00  10.03  10.20   9.89   9.99   59417100\n",
      "2017-10-31 15:00:00   9.94  10.06   9.85   9.94   43751400\n",
      "2017-11-01 15:00:00  10.31  10.36   9.89   9.91  101423700\n",
      "2017-11-02 15:00:00  10.33  10.34  10.14  10.24   72780500\n",
      "2017-11-03 15:00:00  10.27  10.34  10.01  10.25   72628600\n",
      "2017-11-06 15:00:00  10.07  10.21  10.02  10.19   40984900\n",
      "2017-11-07 15:00:00  10.05  10.21  10.00  10.04   51709900\n",
      "2017-11-08 15:00:00  10.03  10.09   9.94  10.04   37233700\n",
      "2017-11-09 15:00:00  10.05  10.07   9.95  10.00   30113500\n",
      "2017-11-10 15:00:00   9.77  10.02   9.75   9.96   53955800\n",
      "2017-11-13 15:00:00   9.64   9.79   9.61   9.72   37819600\n",
      "2017-11-14 15:00:00   9.57   9.70   9.56   9.64   21506300\n",
      "2017-11-15 15:00:00   9.59   9.65   9.53   9.56   17442600\n",
      "2017-11-16 15:00:00   9.45   9.64   9.45   9.63   24067600\n",
      "2017-11-17 15:00:00   9.70   9.73   9.33   9.40   57653500\n",
      "2017-11-20 15:00:00   9.65   9.70   9.54   9.62   21046500\n",
      "\n",
      "[215 rows x 5 columns]), ('601398.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   6.89  6.90  6.84  6.85  104140332\n",
      "2017-01-04 15:00:00   6.92  6.92  6.87  6.89  118920425\n",
      "2017-01-05 15:00:00   6.92  6.93  6.89  6.90   87355637\n",
      "2017-01-06 15:00:00   6.92  6.93  6.90  6.92   87008191\n",
      "2017-01-09 15:00:00   6.96  6.98  6.90  6.93  117453894\n",
      "2017-01-10 15:00:00   6.96  6.96  6.92  6.93   63661257\n",
      "2017-01-11 15:00:00   6.95  6.98  6.93  6.95   52387927\n",
      "2017-01-12 15:00:00   6.95  6.96  6.92  6.95   62166279\n",
      "2017-01-13 15:00:00   6.98  6.99  6.92  6.93   93841289\n",
      "2017-01-16 15:00:00   7.06  7.13  6.92  6.96  302309699\n",
      "2017-01-17 15:00:00   7.06  7.07  7.03  7.04   90022291\n",
      "2017-01-18 15:00:00   7.06  7.07  7.03  7.04   68290432\n",
      "2017-01-19 15:00:00   7.07  7.10  7.01  7.06  110598840\n",
      "2017-01-20 15:00:00   7.06  7.06  7.01  7.04   67869982\n",
      "2017-01-23 15:00:00   7.04  7.06  7.03  7.04   77005269\n",
      "2017-01-24 15:00:00   7.10  7.12  7.04  7.04  117283449\n",
      "2017-01-25 15:00:00   7.10  7.12  7.06  7.09   68255713\n",
      "2017-01-26 15:00:00   7.17  7.17  7.10  7.10   84487133\n",
      "2017-02-03 15:00:00   7.12  7.17  7.09  7.15   53137727\n",
      "2017-02-06 15:00:00   7.10  7.12  7.07  7.12   55128093\n",
      "2017-02-07 15:00:00   7.10  7.10  7.07  7.09   68414436\n",
      "2017-02-08 15:00:00   7.09  7.10  7.03  7.09   55507709\n",
      "2017-02-09 15:00:00   7.12  7.12  7.07  7.09   65501269\n",
      "2017-02-10 15:00:00   7.15  7.15  7.10  7.12   59715467\n",
      "2017-02-13 15:00:00   7.21  7.21  7.13  7.15   93996302\n",
      "2017-02-14 15:00:00   7.21  7.23  7.18  7.20   80645823\n",
      "2017-02-15 15:00:00   7.29  7.31  7.20  7.20  156644868\n",
      "2017-02-16 15:00:00   7.31  7.35  7.26  7.29  103168534\n",
      "2017-02-17 15:00:00   7.23  7.32  7.20  7.32   95376937\n",
      "2017-02-20 15:00:00   7.29  7.34  7.21  7.21  155623320\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   9.56  9.63  9.33  9.47  158813900\n",
      "2017-10-11 15:00:00   9.66  9.70  9.53  9.53  101600800\n",
      "2017-10-12 15:00:00   9.67  9.72  9.61  9.66   65102600\n",
      "2017-10-13 15:00:00   9.56  9.67  9.55  9.66   74258400\n",
      "2017-10-16 15:00:00   9.67  9.69  9.50  9.53   89021900\n",
      "2017-10-17 15:00:00   9.58  9.69  9.58  9.66   64094200\n",
      "2017-10-18 15:00:00   9.78  9.80  9.56  9.60  125053500\n",
      "2017-10-19 15:00:00   9.88  9.97  9.74  9.74  109263700\n",
      "2017-10-20 15:00:00   9.72  9.84  9.70  9.84   72949800\n",
      "2017-10-23 15:00:00   9.64  9.78  9.64  9.74   70992600\n",
      "2017-10-24 15:00:00   9.70  9.74  9.63  9.64   80787300\n",
      "2017-10-25 15:00:00   9.60  9.70  9.55  9.67   87454900\n",
      "2017-10-26 15:00:00   9.42  9.58  9.41  9.55  178375900\n",
      "2017-10-27 15:00:00   9.64  9.75  9.38  9.41  226956200\n",
      "2017-10-30 15:00:00   9.74  9.78  9.60  9.61  129027700\n",
      "2017-10-31 15:00:00   9.50  9.74  9.50  9.70  103405100\n",
      "2017-11-01 15:00:00   9.49  9.55  9.44  9.53  102326100\n",
      "2017-11-02 15:00:00   9.49  9.49  9.35  9.47  105157800\n",
      "2017-11-03 15:00:00   9.50  9.52  9.36  9.46  104655500\n",
      "2017-11-06 15:00:00   9.42  9.47  9.35  9.44   77145000\n",
      "2017-11-07 15:00:00   9.46  9.50  9.35  9.41  177576000\n",
      "2017-11-08 15:00:00   9.41  9.47  9.35  9.42  143333600\n",
      "2017-11-09 15:00:00   9.25  9.39  9.25  9.38  140232300\n",
      "2017-11-10 15:00:00   9.07  9.27  9.05  9.25  199631500\n",
      "2017-11-13 15:00:00   9.28  9.32  9.08  9.08  200635100\n",
      "2017-11-14 15:00:00   9.21  9.32  9.16  9.28   95385900\n",
      "2017-11-15 15:00:00   9.21  9.27  9.13  9.17   88717700\n",
      "2017-11-16 15:00:00   9.11  9.21  9.07  9.17  107566800\n",
      "2017-11-17 15:00:00   9.39  9.39  9.14  9.14  208974100\n",
      "2017-11-20 15:00:00   9.52  9.55  9.32  9.38  190749700\n",
      "\n",
      "[215 rows x 5 columns]), ('601601.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  33.37  33.67  32.80  32.93   7334641\n",
      "2017-01-04 15:00:00  33.59  33.67  33.25  33.40   8196174\n",
      "2017-01-05 15:00:00  33.74  33.93  33.55  33.59   5013751\n",
      "2017-01-06 15:00:00  33.31  33.97  33.25  33.84   3334847\n",
      "2017-01-09 15:00:00  33.79  33.93  33.43  33.47   5193118\n",
      "2017-01-10 15:00:00  33.43  33.85  33.39  33.78   2632364\n",
      "2017-01-11 15:00:00  33.47  33.73  33.37  33.71   2684977\n",
      "2017-01-12 15:00:00  33.16  33.60  33.11  33.41   3147097\n",
      "2017-01-13 15:00:00  33.50  33.97  33.16  33.21   6257515\n",
      "2017-01-16 15:00:00  34.17  34.40  33.25  33.50  17439261\n",
      "2017-01-17 15:00:00  34.41  34.66  33.75  33.98   7441340\n",
      "2017-01-18 15:00:00  34.59  34.72  34.28  34.30   3970993\n",
      "2017-01-19 15:00:00  34.17  34.83  33.92  34.30   3839837\n",
      "2017-01-20 15:00:00  34.27  34.62  34.15  34.29   8232177\n",
      "2017-01-23 15:00:00  34.42  34.64  34.33  34.33  10928688\n",
      "2017-01-24 15:00:00  34.49  34.64  34.33  34.55   4036953\n",
      "2017-01-25 15:00:00  34.67  34.72  34.23  34.36   9945845\n",
      "2017-01-26 15:00:00  34.58  34.76  34.35  34.51   5941179\n",
      "2017-02-03 15:00:00  33.71  34.78  33.66  34.78   3401167\n",
      "2017-02-06 15:00:00  33.92  34.08  33.74  33.97  11084803\n",
      "2017-02-07 15:00:00  33.85  34.14  33.71  33.97   5786269\n",
      "2017-02-08 15:00:00  33.52  33.73  33.28  33.67   7851723\n",
      "2017-02-09 15:00:00  33.36  33.58  33.24  33.52  14881172\n",
      "2017-02-10 15:00:00  33.39  33.52  33.28  33.52  15128390\n",
      "2017-02-13 15:00:00  33.44  33.61  33.30  33.39  22583061\n",
      "2017-02-14 15:00:00  33.03  33.47  32.99  33.44  13375832\n",
      "2017-02-15 15:00:00  33.09  33.18  32.90  33.13  11955569\n",
      "2017-02-16 15:00:00  32.96  33.15  32.84  33.08   9822459\n",
      "2017-02-17 15:00:00  32.97  33.21  32.90  32.93  20053809\n",
      "2017-02-20 15:00:00  33.36  33.36  32.97  33.02  29604382\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  42.88  44.39  42.28  43.81  19650700\n",
      "2017-10-11 15:00:00  43.73  44.02  42.81  42.86  13023800\n",
      "2017-10-12 15:00:00  44.52  44.77  43.47  43.55   7841900\n",
      "2017-10-13 15:00:00  44.27  44.96  44.24  44.62   6401400\n",
      "2017-10-16 15:00:00  45.97  46.17  43.80  44.10  13489200\n",
      "2017-10-17 15:00:00  46.19  46.44  45.36  45.86   7865700\n",
      "2017-10-18 15:00:00  47.16  47.32  45.66  45.95   9755100\n",
      "2017-10-19 15:00:00  47.54  47.59  46.88  47.08   7710500\n",
      "2017-10-20 15:00:00  46.34  47.16  46.15  46.91   5091600\n",
      "2017-10-23 15:00:00  46.76  47.26  46.32  46.84   5473100\n",
      "2017-10-24 15:00:00  47.15  47.80  46.31  46.48   7186300\n",
      "2017-10-25 15:00:00  47.26  47.57  46.70  47.08   4536800\n",
      "2017-10-26 15:00:00  48.33  48.87  46.95  47.02  10186400\n",
      "2017-10-27 15:00:00  49.49  49.82  48.27  48.50   8782800\n",
      "2017-10-30 15:00:00  50.13  51.11  49.38  49.88  10085200\n",
      "2017-10-31 15:00:00  50.99  51.24  49.32  49.67   8094400\n",
      "2017-11-01 15:00:00  51.42  52.59  50.67  50.89  12975600\n",
      "2017-11-02 15:00:00  51.45  51.48  49.58  51.07   8620100\n",
      "2017-11-03 15:00:00  51.70  51.76  50.57  50.97   7489500\n",
      "2017-11-06 15:00:00  50.44  51.31  49.49  51.25  10627700\n",
      "2017-11-07 15:00:00  52.07  52.56  50.26  50.58  13210500\n",
      "2017-11-08 15:00:00  50.52  52.44  49.82  51.78  14667000\n",
      "2017-11-09 15:00:00  50.67  50.80  49.82  50.29   9297400\n",
      "2017-11-10 15:00:00  52.93  53.80  50.21  50.54  21106500\n",
      "2017-11-13 15:00:00  52.73  54.45  52.12  53.28  12279500\n",
      "2017-11-14 15:00:00  52.26  53.70  51.45  53.18  15918900\n",
      "2017-11-15 15:00:00  52.00  53.16  51.34  51.73  11844300\n",
      "2017-11-16 15:00:00  54.90  55.55  51.72  51.85  15689200\n",
      "2017-11-17 15:00:00  56.90  56.94  54.61  54.83  19638700\n",
      "2017-11-20 15:00:00  56.87  58.49  55.79  56.14  16076800\n",
      "\n",
      "[215 rows x 5 columns]), ('601628.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  29.46  29.66  28.22  28.22  25846383\n",
      "2017-01-04 15:00:00  29.53  29.67  29.12  29.16  12798319\n",
      "2017-01-05 15:00:00  29.60  30.15  29.28  29.47  13200457\n",
      "2017-01-06 15:00:00  29.37  29.72  29.29  29.50  10040013\n",
      "2017-01-09 15:00:00  29.85  30.21  29.19  29.22  14413769\n",
      "2017-01-10 15:00:00  29.18  29.86  29.15  29.74  10097702\n",
      "2017-01-11 15:00:00  29.74  30.06  29.06  29.18  15354131\n",
      "2017-01-12 15:00:00  29.64  30.03  29.53  29.65   9261719\n",
      "2017-01-13 15:00:00  29.99  30.86  29.52  29.52  24764627\n",
      "2017-01-16 15:00:00  30.56  30.59  29.19  29.84  25974616\n",
      "2017-01-17 15:00:00  30.54  30.78  30.15  30.21  12494999\n",
      "2017-01-18 15:00:00  30.44  31.00  30.35  30.55  14282702\n",
      "2017-01-19 15:00:00  29.89  30.51  29.63  30.33  12736035\n",
      "2017-01-20 15:00:00  29.75  30.09  29.71  29.85  10487278\n",
      "2017-01-23 15:00:00  30.03  30.07  29.46  29.74  11771499\n",
      "2017-01-24 15:00:00  30.33  30.50  29.80  29.87  11010251\n",
      "2017-01-25 15:00:00  30.08  30.29  29.91  30.21   7594950\n",
      "2017-01-26 15:00:00  29.99  30.41  29.81  29.88  10615344\n",
      "2017-02-03 15:00:00  29.33  30.03  29.18  29.94  10029070\n",
      "2017-02-06 15:00:00  30.31  30.38  29.35  29.35  21737554\n",
      "2017-02-07 15:00:00  30.62  30.86  30.12  30.33  19554041\n",
      "2017-02-08 15:00:00  30.85  31.05  30.43  30.57  16437899\n",
      "2017-02-09 15:00:00  30.92  31.41  30.63  30.75  15992611\n",
      "2017-02-10 15:00:00  30.79  31.20  30.70  30.78  10901448\n",
      "2017-02-13 15:00:00  31.33  31.84  30.76  30.76  18297596\n",
      "2017-02-14 15:00:00  31.00  31.39  30.77  31.33  14997962\n",
      "2017-02-15 15:00:00  31.01  31.32  30.75  30.91  12052048\n",
      "2017-02-16 15:00:00  30.89  31.14  30.66  30.97   8302003\n",
      "2017-02-17 15:00:00  31.00  31.82  30.80  30.85  13589259\n",
      "2017-02-20 15:00:00  30.87  31.18  30.62  30.80  18885255\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  32.24  32.82  31.97  32.62   7532900\n",
      "2017-10-11 15:00:00  32.48  32.62  32.16  32.30   5423700\n",
      "2017-10-12 15:00:00  33.06  33.14  32.32  32.41   9121700\n",
      "2017-10-13 15:00:00  32.89  33.12  32.72  32.94   5397200\n",
      "2017-10-16 15:00:00  33.37  33.57  32.74  32.81  11482800\n",
      "2017-10-17 15:00:00  33.21  33.46  32.99  33.39   7083100\n",
      "2017-10-18 15:00:00  33.76  33.83  33.24  33.36  13674800\n",
      "2017-10-19 15:00:00  33.92  33.96  33.13  33.66  13360600\n",
      "2017-10-20 15:00:00  33.33  33.68  33.28  33.60   4934100\n",
      "2017-10-23 15:00:00  34.12  34.32  33.54  34.13  13961500\n",
      "2017-10-24 15:00:00  34.43  34.77  33.83  33.87  15408200\n",
      "2017-10-25 15:00:00  34.47  34.50  34.15  34.30   6841100\n",
      "2017-10-26 15:00:00  34.48  35.29  34.19  34.23  17185100\n",
      "2017-10-27 15:00:00  34.68  34.93  34.21  34.75  16818900\n",
      "2017-10-30 15:00:00  36.45  37.09  34.72  35.07  30491800\n",
      "2017-10-31 15:00:00  36.95  37.15  35.93  36.10  19085800\n",
      "2017-11-01 15:00:00  38.69  39.06  36.62  36.81  26844200\n",
      "2017-11-02 15:00:00  38.76  39.19  37.83  38.52  16134100\n",
      "2017-11-03 15:00:00  38.93  39.07  38.07  38.36  13812100\n",
      "2017-11-06 15:00:00  38.27  38.94  37.72  38.87  12916600\n",
      "2017-11-07 15:00:00  38.42  39.13  37.89  38.22  17023000\n",
      "2017-11-08 15:00:00  38.12  38.68  37.80  38.13  14509900\n",
      "2017-11-09 15:00:00  38.59  38.61  37.87  37.92  10172300\n",
      "2017-11-10 15:00:00  40.05  40.65  38.28  38.36  20968300\n",
      "2017-11-13 15:00:00  39.86  40.72  39.56  39.86  13604000\n",
      "2017-11-14 15:00:00  39.63  40.21  38.98  39.98  13560900\n",
      "2017-11-15 15:00:00  38.12  39.46  38.08  39.19  15248000\n",
      "2017-11-16 15:00:00  39.45  39.72  37.81  37.81  15232100\n",
      "2017-11-17 15:00:00  40.64  40.66  38.86  39.25  20092000\n",
      "2017-11-20 15:00:00  40.11  40.52  39.19  40.49  12343600\n",
      "\n",
      "[215 rows x 5 columns]), ('601668.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  10.66  10.73  10.51  10.61  219132838\n",
      "2017-01-04 15:00:00  10.78  10.86  10.58  10.62  265395529\n",
      "2017-01-05 15:00:00  10.73  10.80  10.61  10.75  218016053\n",
      "2017-01-06 15:00:00  10.67  10.85  10.64  10.75  186083350\n",
      "2017-01-09 15:00:00  10.75  10.85  10.57  10.67  252162216\n",
      "2017-01-10 15:00:00  10.68  10.82  10.63  10.74  199786312\n",
      "2017-01-11 15:00:00  10.49  10.67  10.40  10.63  284818410\n",
      "2017-01-12 15:00:00  10.32  10.55  10.31  10.45  186054805\n",
      "2017-01-13 15:00:00  10.23  10.38  10.08  10.32  321357805\n",
      "2017-01-16 15:00:00  10.38  10.44  10.01  10.21  397825162\n",
      "2017-01-17 15:00:00  10.33  10.39  10.23  10.31  113074539\n",
      "2017-01-18 15:00:00  10.50  10.62  10.30  10.33  229336708\n",
      "2017-01-19 15:00:00  10.43  10.56  10.33  10.43  149447520\n",
      "2017-01-20 15:00:00  10.46  10.51  10.36  10.39   99489687\n",
      "2017-01-23 15:00:00  10.61  10.62  10.45  10.45  159601947\n",
      "2017-01-24 15:00:00  10.57  10.66  10.55  10.58  132842436\n",
      "2017-01-25 15:00:00  10.79  10.90  10.55  10.58  279289898\n",
      "2017-01-26 15:00:00  10.75  10.88  10.66  10.81  197606138\n",
      "2017-02-03 15:00:00  10.61  10.73  10.57  10.70  113626822\n",
      "2017-02-06 15:00:00  10.67  10.78  10.58  10.61  171820738\n",
      "2017-02-07 15:00:00  10.57  10.67  10.49  10.67  159621145\n",
      "2017-02-08 15:00:00  10.61  10.63  10.48  10.55  146917112\n",
      "2017-02-09 15:00:00  10.67  10.80  10.58  10.61  391726579\n",
      "2017-02-10 15:00:00  11.03  11.18  10.64  10.66  774943207\n",
      "2017-02-13 15:00:00  11.08  11.15  10.94  11.00  417517697\n",
      "2017-02-14 15:00:00  11.06  11.11  10.96  11.08  289983656\n",
      "2017-02-15 15:00:00  10.85  11.04  10.82  11.03  275162541\n",
      "2017-02-16 15:00:00  10.90  10.91  10.78  10.86  193466968\n",
      "2017-02-17 15:00:00  10.68  10.88  10.67  10.86  194717931\n",
      "2017-02-20 15:00:00  10.90  10.92  10.64  10.67  253815493\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  11.61  11.66  11.56  11.64   37745000\n",
      "2017-10-11 15:00:00  11.69  11.73  11.60  11.62   43852000\n",
      "2017-10-12 15:00:00  11.64  11.74  11.62  11.67   30045200\n",
      "2017-10-13 15:00:00  11.53  11.67  11.51  11.67   51269800\n",
      "2017-10-16 15:00:00  11.55  11.61  11.50  11.56   50874300\n",
      "2017-10-17 15:00:00  11.55  11.62  11.48  11.53   40762400\n",
      "2017-10-18 15:00:00  11.66  11.73  11.53  11.56   79064900\n",
      "2017-10-19 15:00:00  11.46  11.68  11.44  11.67   71751300\n",
      "2017-10-20 15:00:00  11.48  11.52  11.40  11.40   35893800\n",
      "2017-10-23 15:00:00  11.36  11.50  11.33  11.48   55311100\n",
      "2017-10-24 15:00:00  11.53  11.56  11.36  11.37   90194400\n",
      "2017-10-25 15:00:00  11.60  11.73  11.52  11.53   77094700\n",
      "2017-10-26 15:00:00  11.89  12.01  11.61  11.66  165851800\n",
      "2017-10-27 15:00:00  11.88  11.93  11.77  11.84   83063900\n",
      "2017-10-30 15:00:00  11.78  11.84  11.51  11.83  126306300\n",
      "2017-10-31 15:00:00  11.67  11.72  11.60  11.71   54558100\n",
      "2017-11-01 15:00:00  12.14  12.20  11.63  11.67  227156200\n",
      "2017-11-02 15:00:00  12.17  12.23  12.01  12.10  162114000\n",
      "2017-11-03 15:00:00  12.03  12.15  11.77  12.14  139259500\n",
      "2017-11-06 15:00:00  11.88  11.94  11.78  11.94   90309700\n",
      "2017-11-07 15:00:00  11.82  12.11  11.73  11.84  143590700\n",
      "2017-11-08 15:00:00  11.88  11.98  11.74  11.79  124040800\n",
      "2017-11-09 15:00:00  11.90  11.91  11.78  11.85   75237900\n",
      "2017-11-10 15:00:00  11.61  11.91  11.58  11.91  126258400\n",
      "2017-11-13 15:00:00  11.46  11.61  11.42  11.52  125694900\n",
      "2017-11-14 15:00:00  11.48  11.55  11.42  11.45   71417300\n",
      "2017-11-15 15:00:00  11.48  11.52  11.37  11.45   62122000\n",
      "2017-11-16 15:00:00  11.39  11.53  11.37  11.46   69835800\n",
      "2017-11-17 15:00:00  11.64  11.68  11.34  11.36  164546700\n",
      "2017-11-20 15:00:00  11.57  11.66  11.44  11.58   87512200\n",
      "\n",
      "[215 rows x 5 columns]), ('601688.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  20.21  20.31  19.90  19.90  32286926\n",
      "2017-01-04 15:00:00  20.47  20.54  20.16  20.20  35758846\n",
      "2017-01-05 15:00:00  20.38  20.58  20.34  20.44  23906877\n",
      "2017-01-06 15:00:00  20.16  20.44  20.06  20.40  24394716\n",
      "2017-01-09 15:00:00  20.15  20.26  20.06  20.13  23063790\n",
      "2017-01-10 15:00:00  20.04  20.25  19.97  20.24  18397050\n",
      "2017-01-11 15:00:00  19.78  20.12  19.76  20.04  22828520\n",
      "2017-01-12 15:00:00  19.70  19.95  19.67  19.82  18198307\n",
      "2017-01-13 15:00:00  19.84  19.94  19.61  19.62  21451996\n",
      "2017-01-16 15:00:00  20.15  20.25  19.60  19.77  60849240\n",
      "2017-01-17 15:00:00  20.05  20.16  19.82  20.05  17151557\n",
      "2017-01-18 15:00:00  20.14  20.28  19.91  20.04  18077588\n",
      "2017-01-19 15:00:00  20.18  20.28  20.04  20.12  17406300\n",
      "2017-01-20 15:00:00  20.47  20.54  20.10  20.13  28451589\n",
      "2017-01-23 15:00:00  20.44  20.74  20.38  20.48  18800833\n",
      "2017-01-24 15:00:00  20.38  20.53  20.23  20.40  20032071\n",
      "2017-01-25 15:00:00  20.43  20.50  20.25  20.40  11541737\n",
      "2017-01-26 15:00:00  20.51  20.65  20.42  20.45  16773706\n",
      "2017-02-03 15:00:00  20.15  20.56  20.13  20.56  17283574\n",
      "2017-02-06 15:00:00  20.11  20.24  19.98  20.24  22148830\n",
      "2017-02-07 15:00:00  19.94  20.11  19.80  20.10  18863260\n",
      "2017-02-08 15:00:00  20.30  20.35  19.78  19.95  30839393\n",
      "2017-02-09 15:00:00  20.25  20.45  20.18  20.22  29650255\n",
      "2017-02-10 15:00:00  20.34  20.48  20.01  20.25  46655953\n",
      "2017-02-13 15:00:00  20.55  20.67  20.32  20.36  60690921\n",
      "2017-02-14 15:00:00  20.43  20.68  20.37  20.56  25137269\n",
      "2017-02-15 15:00:00  20.33  20.58  20.30  20.42  32693249\n",
      "2017-02-16 15:00:00  20.42  20.53  20.21  20.33  33105228\n",
      "2017-02-17 15:00:00  20.32  20.96  20.31  20.53  72375955\n",
      "2017-02-20 15:00:00  20.56  20.57  20.15  20.32  47431154\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  24.13  25.13  23.67  24.89  52524900\n",
      "2017-10-11 15:00:00  23.97  24.16  23.73  24.07  24060300\n",
      "2017-10-12 15:00:00  23.83  24.13  23.69  23.87  15142900\n",
      "2017-10-13 15:00:00  23.86  24.03  23.68  23.93  18725200\n",
      "2017-10-16 15:00:00  23.86  24.13  23.79  23.89  20865000\n",
      "2017-10-17 15:00:00  23.84  24.00  23.72  23.76  13595800\n",
      "2017-10-18 15:00:00  24.03  24.08  23.84  23.96  20654200\n",
      "2017-10-19 15:00:00  23.56  24.03  23.05  24.03  33465600\n",
      "2017-10-20 15:00:00  23.33  23.54  23.09  23.32  13833800\n",
      "2017-10-23 15:00:00  22.83  23.34  22.76  23.33  20580900\n",
      "2017-10-24 15:00:00  23.08  23.18  22.69  22.76  16314900\n",
      "2017-10-25 15:00:00  23.13  23.24  22.86  23.07  11585500\n",
      "2017-10-26 15:00:00  22.79  23.55  22.72  23.05  36045800\n",
      "2017-10-27 15:00:00  22.28  23.00  22.23  22.73  28303400\n",
      "2017-10-30 15:00:00  21.88  22.36  21.43  22.22  33903300\n",
      "2017-10-31 15:00:00  21.73  21.89  21.54  21.74  14135800\n",
      "2017-11-01 15:00:00  21.27  21.94  21.22  21.74  26984600\n",
      "2017-11-02 15:00:00  21.45  21.78  21.06  21.35  27441800\n",
      "2017-11-03 15:00:00  21.54  21.56  21.12  21.46  21982600\n",
      "2017-11-06 15:00:00  21.35  21.46  21.11  21.46  16775400\n",
      "2017-11-07 15:00:00  22.31  22.31  21.33  21.33  43857300\n",
      "2017-11-08 15:00:00  22.47  23.27  22.17  22.27  58666900\n",
      "2017-11-09 15:00:00  22.57  22.88  22.23  22.32  28700600\n",
      "2017-11-10 15:00:00  22.50  22.73  22.24  22.54  31171100\n",
      "2017-11-13 15:00:00  22.34  22.98  22.22  22.62  28908000\n",
      "2017-11-14 15:00:00  22.02  22.37  21.89  22.32  23263300\n",
      "2017-11-15 15:00:00  21.94  22.27  21.85  21.91  21133000\n",
      "2017-11-16 15:00:00  21.27  22.01  21.16  21.97  30883900\n",
      "2017-11-17 15:00:00  21.71  21.81  20.87  21.28  40758200\n",
      "2017-11-20 15:00:00  21.15  21.68  20.90  21.36  28774200\n",
      "\n",
      "[215 rows x 5 columns]), ('601766.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  11.21  11.27  11.11  11.11   60491044\n",
      "2017-01-04 15:00:00  11.32  11.36  11.20  11.22   87239971\n",
      "2017-01-05 15:00:00  11.28  11.32  11.24  11.32   70332294\n",
      "2017-01-06 15:00:00  11.32  11.45  11.28  11.29   98756783\n",
      "2017-01-09 15:00:00  11.54  11.55  11.29  11.30  129040314\n",
      "2017-01-10 15:00:00  11.46  11.55  11.40  11.53   79117223\n",
      "2017-01-11 15:00:00  11.35  11.49  11.32  11.45   76851890\n",
      "2017-01-12 15:00:00  11.24  11.45  11.24  11.33   70324682\n",
      "2017-01-13 15:00:00  11.29  11.32  11.11  11.22  102118301\n",
      "2017-01-16 15:00:00  11.39  11.46  11.03  11.22  185383271\n",
      "2017-01-17 15:00:00  11.32  11.35  11.20  11.33   55108393\n",
      "2017-01-18 15:00:00  11.32  11.40  11.28  11.30   51605830\n",
      "2017-01-19 15:00:00  11.24  11.31  11.21  11.31   38753549\n",
      "2017-01-20 15:00:00  11.31  11.33  11.21  11.22   38000215\n",
      "2017-01-23 15:00:00  11.36  11.41  11.29  11.30   39576152\n",
      "2017-01-24 15:00:00  11.37  11.40  11.32  11.37   47258430\n",
      "2017-01-25 15:00:00  11.40  11.42  11.35  11.38   45715891\n",
      "2017-01-26 15:00:00  11.39  11.44  11.38  11.41   37138512\n",
      "2017-02-03 15:00:00  11.37  11.46  11.36  11.42   26522571\n",
      "2017-02-06 15:00:00  11.40  11.45  11.35  11.37   46990436\n",
      "2017-02-07 15:00:00  11.33  11.40  11.30  11.40   39672846\n",
      "2017-02-08 15:00:00  11.32  11.33  11.20  11.30   49406157\n",
      "2017-02-09 15:00:00  11.45  11.53  11.29  11.31   89937858\n",
      "2017-02-10 15:00:00  11.78  12.01  11.45  11.45  231863163\n",
      "2017-02-13 15:00:00  11.86  12.17  11.74  11.79  195343598\n",
      "2017-02-14 15:00:00  11.90  11.94  11.76  11.82   85349083\n",
      "2017-02-15 15:00:00  11.81  12.13  11.78  11.88  157456688\n",
      "2017-02-16 15:00:00  11.82  11.85  11.69  11.81   76925049\n",
      "2017-02-17 15:00:00  11.69  11.84  11.63  11.80   80448657\n",
      "2017-02-20 15:00:00  11.82  11.82  11.68  11.69  123159678\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  11.21  11.21  11.13  11.16   11303000\n",
      "2017-10-11 15:00:00  11.20  11.24  11.17  11.23   11084700\n",
      "2017-10-12 15:00:00  11.20  11.24  11.16  11.21   15108400\n",
      "2017-10-13 15:00:00  11.24  11.32  11.20  11.22   23183600\n",
      "2017-10-16 15:00:00  11.39  11.55  11.27  11.27   64765100\n",
      "2017-10-17 15:00:00  11.40  11.42  11.31  11.42   22727700\n",
      "2017-10-18 15:00:00  11.32  11.44  11.31  11.41   18778100\n",
      "2017-10-19 15:00:00  11.24  11.42  11.22  11.37   18937200\n",
      "2017-10-20 15:00:00  11.30  11.32  11.20  11.22   15955000\n",
      "2017-10-23 15:00:00  11.41  11.54  11.30  11.32   36751500\n",
      "2017-10-24 15:00:00  11.63  11.65  11.37  11.39   81575600\n",
      "2017-10-25 15:00:00  11.61  11.66  11.53  11.63   39204200\n",
      "2017-10-26 15:00:00  12.51  12.72  11.54  11.58  193950200\n",
      "2017-10-27 15:00:00  12.17  12.50  12.09  12.42  110573100\n",
      "2017-10-30 15:00:00  12.75  12.96  12.21  12.28  195189500\n",
      "2017-10-31 15:00:00  13.04  13.28  12.60  12.62  165723800\n",
      "2017-11-01 15:00:00  12.99  13.26  12.86  12.95  114315400\n",
      "2017-11-02 15:00:00  12.99  13.09  12.75  12.91  110285600\n",
      "2017-11-03 15:00:00  12.92  13.03  12.56  12.93  122943900\n",
      "2017-11-06 15:00:00  12.76  12.80  12.61  12.78   76661300\n",
      "2017-11-07 15:00:00  12.99  13.28  12.72  12.76  141629500\n",
      "2017-11-08 15:00:00  12.71  12.97  12.67  12.92  107881800\n",
      "2017-11-09 15:00:00  12.81  12.96  12.61  12.73   84276000\n",
      "2017-11-10 15:00:00  12.43  12.73  12.39  12.66  111091800\n",
      "2017-11-13 15:00:00  12.46  12.56  12.36  12.39   61155900\n",
      "2017-11-14 15:00:00  12.10  12.55  12.09  12.50   80385700\n",
      "2017-11-15 15:00:00  12.07  12.13  11.91  12.04   70835700\n",
      "2017-11-16 15:00:00  11.77  12.10  11.76  12.02   55856500\n",
      "2017-11-17 15:00:00  12.11  12.12  11.65  11.74  101716000\n",
      "2017-11-20 15:00:00  12.14  12.21  11.86  11.98   56690700\n",
      "\n",
      "[215 rows x 5 columns]), ('601788.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  18.74  18.85  18.47  18.52  19451069\n",
      "2017-01-04 15:00:00  18.74  18.79  18.61  18.71  11481944\n",
      "2017-01-05 15:00:00  18.68  18.76  18.64  18.74   9631706\n",
      "2017-01-06 15:00:00  18.40  18.72  18.37  18.71  13292766\n",
      "2017-01-09 15:00:00  18.45  18.49  18.32  18.41  10270628\n",
      "2017-01-10 15:00:00  18.41  18.51  18.37  18.45   8613352\n",
      "2017-01-11 15:00:00  18.33  18.49  18.30  18.41  10200905\n",
      "2017-01-12 15:00:00  18.22  18.37  18.20  18.25  11086179\n",
      "2017-01-13 15:00:00  18.26  18.33  17.88  18.21  16805583\n",
      "2017-01-16 15:00:00  18.49  18.56  17.85  18.15  37618075\n",
      "2017-01-17 15:00:00  18.40  18.41  18.25  18.36   6700212\n",
      "2017-01-18 15:00:00  18.36  18.51  18.27  18.30   6912448\n",
      "2017-01-19 15:00:00  18.37  18.50  18.33  18.37   6901011\n",
      "2017-01-20 15:00:00  18.54  18.57  18.29  18.34  11288101\n",
      "2017-01-23 15:00:00  18.54  18.66  18.48  18.49   9013748\n",
      "2017-01-24 15:00:00  18.49  18.57  18.43  18.57   5637828\n",
      "2017-01-25 15:00:00  18.44  18.51  18.40  18.44   6056071\n",
      "2017-01-26 15:00:00  18.54  18.58  18.48  18.48   8920369\n",
      "2017-02-03 15:00:00  18.26  18.55  18.25  18.54   7628161\n",
      "2017-02-06 15:00:00  18.33  18.36  18.22  18.27   9884548\n",
      "2017-02-07 15:00:00  18.20  18.33  18.11  18.30   9469631\n",
      "2017-02-08 15:00:00  18.50  18.51  18.08  18.19  15406415\n",
      "2017-02-09 15:00:00  18.52  18.63  18.43  18.50  13522672\n",
      "2017-02-10 15:00:00  18.62  18.76  18.49  18.57  18734819\n",
      "2017-02-13 15:00:00  18.69  18.81  18.61  18.61  16501292\n",
      "2017-02-14 15:00:00  18.61  18.81  18.57  18.76  22101916\n",
      "2017-02-15 15:00:00  18.47  18.71  18.43  18.61  26212457\n",
      "2017-02-16 15:00:00  18.49  18.59  18.41  18.48  27758845\n",
      "2017-02-17 15:00:00  18.44  19.03  18.40  18.65  56614878\n",
      "2017-02-20 15:00:00  18.70  18.71  18.34  18.48  37995094\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  18.12  18.17  17.96  18.08   5643900\n",
      "2017-10-11 15:00:00  18.03  18.13  18.01  18.13   4204100\n",
      "2017-10-12 15:00:00  17.90  18.11  17.86  18.05   5024300\n",
      "2017-10-13 15:00:00  17.91  18.01  17.89  17.93   3439400\n",
      "2017-10-16 15:00:00  17.91  18.01  17.82  17.95   6990800\n",
      "2017-10-17 15:00:00  17.73  17.91  17.73  17.90   3405400\n",
      "2017-10-18 15:00:00  17.73  17.85  17.48  17.75   9534100\n",
      "2017-10-19 15:00:00  17.46  17.70  17.40  17.64   5687400\n",
      "2017-10-20 15:00:00  17.47  17.52  17.41  17.45   3843000\n",
      "2017-10-23 15:00:00  17.50  17.52  17.41  17.48   2694200\n",
      "2017-10-24 15:00:00  17.63  17.70  17.46  17.50   8890600\n",
      "2017-10-25 15:00:00  17.63  17.69  17.54  17.66   3821900\n",
      "2017-10-26 15:00:00  17.64  17.78  17.55  17.61   5339400\n",
      "2017-10-27 15:00:00  17.59  17.66  17.53  17.64   3324200\n",
      "2017-10-30 15:00:00  17.42  17.55  17.17  17.54   8962200\n",
      "2017-10-31 15:00:00  17.26  17.37  17.19  17.26   5588600\n",
      "2017-11-01 15:00:00  17.22  17.38  17.18  17.27   4246000\n",
      "2017-11-02 15:00:00  17.20  17.38  17.08  17.18   6266000\n",
      "2017-11-03 15:00:00  17.23  17.28  17.03  17.19   7260600\n",
      "2017-11-06 15:00:00  17.23  17.34  17.18  17.19   3721700\n",
      "2017-11-07 15:00:00  17.35  17.41  17.24  17.30   4393500\n",
      "2017-11-08 15:00:00  17.70  18.00  17.12  17.30  17113800\n",
      "2017-11-09 15:00:00  17.67  17.68  17.54  17.57   3780300\n",
      "2017-11-10 15:00:00  17.52  17.66  17.39  17.66   7812500\n",
      "2017-11-13 15:00:00  17.50  17.62  17.45  17.49   4314200\n",
      "2017-11-14 15:00:00  17.28  17.49  17.25  17.47   3682400\n",
      "2017-11-15 15:00:00  17.25  17.35  17.16  17.25   5305900\n",
      "2017-11-16 15:00:00  17.04  17.25  17.03  17.24   4028200\n",
      "2017-11-17 15:00:00  17.30  17.35  16.93  17.03  12905300\n",
      "2017-11-20 15:00:00  17.18  17.26  17.03  17.23   5448400\n",
      "\n",
      "[215 rows x 5 columns]), ('601800.XSHG',                      close   high    low   open    volume\n",
      "datetime                                                 \n",
      "2017-01-03 15:00:00  17.97  18.09  17.78  17.78  24740117\n",
      "2017-01-04 15:00:00  18.17  18.34  17.76  17.91  26222957\n",
      "2017-01-05 15:00:00  18.12  18.39  17.84  18.10  23918084\n",
      "2017-01-06 15:00:00  18.35  18.69  18.01  18.14  39215044\n",
      "2017-01-09 15:00:00  18.52  18.56  17.85  18.11  28392278\n",
      "2017-01-10 15:00:00  17.98  18.63  17.94  18.43  22185238\n",
      "2017-01-11 15:00:00  18.14  18.48  17.76  18.02  30934094\n",
      "2017-01-12 15:00:00  18.12  18.46  17.85  17.97  26235543\n",
      "2017-01-13 15:00:00  18.15  18.38  17.71  18.01  26052243\n",
      "2017-01-16 15:00:00  18.19  18.28  16.78  18.11  46773354\n",
      "2017-01-17 15:00:00  17.95  18.16  17.70  17.86  13375691\n",
      "2017-01-18 15:00:00  18.52  18.95  17.98  18.05  39923900\n",
      "2017-01-19 15:00:00  18.77  19.02  18.16  18.34  39677089\n",
      "2017-01-20 15:00:00  18.92  18.92  18.53  18.76  23312640\n",
      "2017-01-23 15:00:00  18.84  19.15  18.66  18.93  23645203\n",
      "2017-01-24 15:00:00  18.89  19.09  18.72  18.84  21915435\n",
      "2017-01-25 15:00:00  18.69  18.98  18.61  18.81  19340460\n",
      "2017-01-26 15:00:00  18.61  18.79  18.37  18.73  15347765\n",
      "2017-02-03 15:00:00  18.66  18.90  18.52  18.59  13567945\n",
      "2017-02-06 15:00:00  19.25  19.45  18.71  18.76  42479812\n",
      "2017-02-07 15:00:00  19.26  19.33  19.02  19.13  22049355\n",
      "2017-02-08 15:00:00  19.24  19.36  19.04  19.31  21029587\n",
      "2017-02-09 15:00:00  19.95  20.31  19.10  19.23  54277132\n",
      "2017-02-10 15:00:00  21.03  21.94  20.04  20.04  91878574\n",
      "2017-02-13 15:00:00  21.25  21.80  20.70  21.04  56645465\n",
      "2017-02-14 15:00:00  21.97  22.08  20.83  21.20  56907853\n",
      "2017-02-15 15:00:00  21.33  21.84  21.09  21.84  46576204\n",
      "2017-02-16 15:00:00  21.24  21.58  20.98  21.30  36135193\n",
      "2017-02-17 15:00:00  20.98  21.25  20.80  21.23  32838387\n",
      "2017-02-20 15:00:00  21.31  21.57  20.84  20.92  46789205\n",
      "...                    ...    ...    ...    ...       ...\n",
      "2017-10-10 15:00:00  18.30  18.35  18.20  18.32   6582800\n",
      "2017-10-11 15:00:00  18.16  18.32  18.13  18.30   8499500\n",
      "2017-10-12 15:00:00  17.99  18.20  17.92  18.18   8030900\n",
      "2017-10-13 15:00:00  18.05  18.15  17.86  17.98   7226700\n",
      "2017-10-16 15:00:00  18.10  18.24  17.97  18.02   9770300\n",
      "2017-10-17 15:00:00  18.10  18.20  17.96  18.09   4521500\n",
      "2017-10-18 15:00:00  17.97  18.18  17.97  18.09   5578000\n",
      "2017-10-19 15:00:00  17.61  18.02  17.60  17.98   7088300\n",
      "2017-10-20 15:00:00  17.70  17.76  17.54  17.58   4535500\n",
      "2017-10-23 15:00:00  17.70  17.77  17.55  17.69   4397700\n",
      "2017-10-24 15:00:00  18.01  18.15  17.66  17.67  10673700\n",
      "2017-10-25 15:00:00  17.99  18.14  17.90  18.08   7482700\n",
      "2017-10-26 15:00:00  18.33  18.48  17.89  17.97  20684100\n",
      "2017-10-27 15:00:00  18.18  18.41  18.16  18.27   8315500\n",
      "2017-10-30 15:00:00  18.22  18.34  17.94  18.23   9198700\n",
      "2017-10-31 15:00:00  17.94  18.13  17.84  18.07   6214100\n",
      "2017-11-01 15:00:00  18.29  18.40  17.84  17.94  15235900\n",
      "2017-11-02 15:00:00  18.26  18.32  17.96  18.23  10751000\n",
      "2017-11-03 15:00:00  18.15  18.21  17.78  18.10  11514800\n",
      "2017-11-06 15:00:00  17.90  18.03  17.83  18.01   6722500\n",
      "2017-11-07 15:00:00  17.83  17.98  17.77  17.96   8870400\n",
      "2017-11-08 15:00:00  17.85  17.94  17.65  17.83   8906300\n",
      "2017-11-09 15:00:00  17.74  17.91  17.70  17.88   7595300\n",
      "2017-11-10 15:00:00  17.59  17.78  17.55  17.71   7108600\n",
      "2017-11-13 15:00:00  17.35  17.63  17.28  17.55  10129000\n",
      "2017-11-14 15:00:00  17.39  17.50  17.27  17.35   7254700\n",
      "2017-11-15 15:00:00  17.34  17.41  17.25  17.35   4954200\n",
      "2017-11-16 15:00:00  16.91  17.29  16.90  17.28   8070300\n",
      "2017-11-17 15:00:00  17.04  17.11  16.42  16.86  20087700\n",
      "2017-11-20 15:00:00  16.79  17.04  16.70  16.88   6301800\n",
      "\n",
      "[215 rows x 5 columns]), ('601818.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   5.03  5.04  4.96  4.97  136691347\n",
      "2017-01-04 15:00:00   5.03  5.06  5.01  5.02   71909565\n",
      "2017-01-05 15:00:00   5.03  5.06  5.02  5.04   52666645\n",
      "2017-01-06 15:00:00   4.99  5.03  4.97  5.03   51623974\n",
      "2017-01-09 15:00:00   4.98  5.01  4.97  4.98   47068285\n",
      "2017-01-10 15:00:00   4.98  5.01  4.97  4.99   42862020\n",
      "2017-01-11 15:00:00   4.97  5.01  4.97  4.98   52285506\n",
      "2017-01-12 15:00:00   4.96  4.99  4.94  4.98   39174165\n",
      "2017-01-13 15:00:00   4.99  5.02  4.94  4.97   66908022\n",
      "2017-01-16 15:00:00   5.06  5.10  4.96  4.99  188959446\n",
      "2017-01-17 15:00:00   5.04  5.06  5.02  5.03   56533745\n",
      "2017-01-18 15:00:00   5.10  5.12  5.03  5.03   71378202\n",
      "2017-01-19 15:00:00   5.07  5.12  5.04  5.08   50928127\n",
      "2017-01-20 15:00:00   5.10  5.11  5.06  5.06   58844345\n",
      "2017-01-23 15:00:00   5.10  5.12  5.07  5.10   38958028\n",
      "2017-01-24 15:00:00   5.16  5.17  5.07  5.08   78614855\n",
      "2017-01-25 15:00:00   5.16  5.18  5.12  5.16   34555463\n",
      "2017-01-26 15:00:00   5.20  5.24  5.17  5.17   55510636\n",
      "2017-02-03 15:00:00   5.13  5.21  5.13  5.20   29409172\n",
      "2017-02-06 15:00:00   5.15  5.17  5.13  5.16   38105979\n",
      "2017-02-07 15:00:00   5.13  5.16  5.12  5.15   30946178\n",
      "2017-02-08 15:00:00   5.16  5.16  5.10  5.13   40204591\n",
      "2017-02-09 15:00:00   5.16  5.17  5.13  5.16   49000356\n",
      "2017-02-10 15:00:00   5.21  5.22  5.16  5.17   66969327\n",
      "2017-02-13 15:00:00   5.26  5.29  5.21  5.22   89213868\n",
      "2017-02-14 15:00:00   5.24  5.29  5.22  5.26   37804124\n",
      "2017-02-15 15:00:00   5.27  5.32  5.24  5.25  101908984\n",
      "2017-02-16 15:00:00   5.29  5.32  5.27  5.29   49857380\n",
      "2017-02-17 15:00:00   5.22  5.31  5.21  5.30   46236100\n",
      "2017-02-20 15:00:00   5.32  5.38  5.21  5.21  154011804\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   5.22  5.24  5.18  5.21   39202500\n",
      "2017-10-11 15:00:00   5.24  5.25  5.21  5.22   37392300\n",
      "2017-10-12 15:00:00   5.22  5.24  5.21  5.24   24485000\n",
      "2017-10-13 15:00:00   5.22  5.24  5.21  5.21   17083600\n",
      "2017-10-16 15:00:00   5.26  5.26  5.22  5.22   52578400\n",
      "2017-10-17 15:00:00   5.24  5.27  5.24  5.26   29531400\n",
      "2017-10-18 15:00:00   5.26  5.27  5.22  5.24   47494200\n",
      "2017-10-19 15:00:00   5.27  5.27  5.22  5.25   54194400\n",
      "2017-10-20 15:00:00   5.24  5.26  5.22  5.25   20489800\n",
      "2017-10-23 15:00:00   5.17  5.24  5.16  5.24   51080600\n",
      "2017-10-24 15:00:00   5.18  5.21  5.17  5.18   39758300\n",
      "2017-10-25 15:00:00   5.18  5.20  5.16  5.18   44398100\n",
      "2017-10-26 15:00:00   5.17  5.18  5.15  5.18   48286700\n",
      "2017-10-27 15:00:00   5.18  5.22  5.16  5.17   70554900\n",
      "2017-10-30 15:00:00   5.16  5.21  5.12  5.20   83141000\n",
      "2017-10-31 15:00:00   5.15  5.18  5.13  5.15   37187800\n",
      "2017-11-01 15:00:00   5.13  5.16  5.12  5.15   42417500\n",
      "2017-11-02 15:00:00   5.13  5.15  5.08  5.15   61480300\n",
      "2017-11-03 15:00:00   5.13  5.13  5.07  5.12   65252500\n",
      "2017-11-06 15:00:00   5.10  5.12  5.08  5.12   29281600\n",
      "2017-11-07 15:00:00   5.16  5.17  5.08  5.10   69891400\n",
      "2017-11-08 15:00:00   5.16  5.18  5.13  5.16   46192100\n",
      "2017-11-09 15:00:00   5.12  5.16  5.11  5.16   47351600\n",
      "2017-11-10 15:00:00   5.10  5.15  5.08  5.12   90107200\n",
      "2017-11-13 15:00:00   5.17  5.18  5.10  5.11  101067900\n",
      "2017-11-14 15:00:00   5.13  5.16  5.11  5.16   52978200\n",
      "2017-11-15 15:00:00   5.12  5.15  5.11  5.13   42558100\n",
      "2017-11-16 15:00:00   5.11  5.12  5.10  5.11   41147500\n",
      "2017-11-17 15:00:00   5.21  5.22  5.10  5.10  138334800\n",
      "2017-11-20 15:00:00   5.24  5.25  5.16  5.17   71833900\n",
      "\n",
      "[215 rows x 5 columns]), ('601857.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  10.10  10.13  10.01  10.06   44791760\n",
      "2017-01-04 15:00:00  10.12  10.17  10.02  10.07   39550853\n",
      "2017-01-05 15:00:00  10.34  10.40  10.08  10.11   78716533\n",
      "2017-01-06 15:00:00  10.58  10.65  10.31  10.34  116199523\n",
      "2017-01-09 15:00:00  10.59  10.83  10.50  10.50   78483928\n",
      "2017-01-10 15:00:00  10.63  10.68  10.40  10.56   47098486\n",
      "2017-01-11 15:00:00  10.54  10.74  10.50  10.56   51345438\n",
      "2017-01-12 15:00:00  10.53  10.65  10.49  10.51   38066738\n",
      "2017-01-13 15:00:00  10.62  10.65  10.46  10.53   34978613\n",
      "2017-01-16 15:00:00  10.77  10.82  10.46  10.58   91972530\n",
      "2017-01-17 15:00:00  10.81  11.01  10.69  10.72   64947709\n",
      "2017-01-18 15:00:00  10.84  10.89  10.74  10.79   21393905\n",
      "2017-01-19 15:00:00  10.77  10.82  10.58  10.81   46652802\n",
      "2017-01-20 15:00:00  10.68  10.73  10.63  10.70   25467508\n",
      "2017-01-23 15:00:00  10.77  10.81  10.64  10.69   31742518\n",
      "2017-01-24 15:00:00  11.07  11.17  10.74  10.78   58646360\n",
      "2017-01-25 15:00:00  11.05  11.17  10.98  11.06   31153655\n",
      "2017-01-26 15:00:00  10.94  11.08  10.87  11.00   50405831\n",
      "2017-02-03 15:00:00  10.87  10.96  10.83  10.94   20337392\n",
      "2017-02-06 15:00:00  10.82  10.88  10.74  10.86   55450794\n",
      "2017-02-07 15:00:00  10.77  10.82  10.72  10.81   32693792\n",
      "2017-02-08 15:00:00  10.65  10.75  10.55  10.74   72215818\n",
      "2017-02-09 15:00:00  10.67  10.69  10.54  10.64  102311570\n",
      "2017-02-10 15:00:00  10.69  10.70  10.60  10.63   81942060\n",
      "2017-02-13 15:00:00  10.64  10.70  10.59  10.69   76020256\n",
      "2017-02-14 15:00:00  10.62  10.63  10.56  10.63   38899534\n",
      "2017-02-15 15:00:00  10.65  10.68  10.59  10.62   56427751\n",
      "2017-02-16 15:00:00  10.53  10.64  10.45  10.63   82858296\n",
      "2017-02-17 15:00:00  10.46  10.60  10.44  10.50   54262314\n",
      "2017-02-20 15:00:00  10.55  10.58  10.45  10.48   52499717\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  10.17  10.17  10.12  10.15    9184400\n",
      "2017-10-11 15:00:00  10.17  10.19  10.15  10.19    8733300\n",
      "2017-10-12 15:00:00  10.14  10.17  10.11  10.17    8221300\n",
      "2017-10-13 15:00:00  10.15  10.15  10.11  10.12    7743500\n",
      "2017-10-16 15:00:00  10.24  10.25  10.14  10.15   19508100\n",
      "2017-10-17 15:00:00  10.24  10.29  10.20  10.23   12195100\n",
      "2017-10-18 15:00:00  10.49  10.52  10.21  10.23   51399100\n",
      "2017-10-19 15:00:00  10.52  10.52  10.39  10.43   29603900\n",
      "2017-10-20 15:00:00  10.37  10.45  10.34  10.44   16155800\n",
      "2017-10-23 15:00:00  10.37  10.39  10.29  10.37   14620900\n",
      "2017-10-24 15:00:00  10.39  10.45  10.34  10.34   21528400\n",
      "2017-10-25 15:00:00  10.34  10.38  10.30  10.37   12938600\n",
      "2017-10-26 15:00:00  10.39  10.39  10.29  10.33   14715400\n",
      "2017-10-27 15:00:00  10.34  10.42  10.30  10.39   17237000\n",
      "2017-10-30 15:00:00  10.56  10.61  10.31  10.37   51478600\n",
      "2017-10-31 15:00:00  10.52  10.56  10.45  10.52   23444100\n",
      "2017-11-01 15:00:00  10.67  10.72  10.51  10.53   43382500\n",
      "2017-11-02 15:00:00  10.67  10.72  10.59  10.62   23677600\n",
      "2017-11-03 15:00:00  10.58  10.80  10.52  10.67   33813700\n",
      "2017-11-06 15:00:00  10.66  10.76  10.58  10.66   29571500\n",
      "2017-11-07 15:00:00  10.93  11.01  10.75  10.75   55535600\n",
      "2017-11-08 15:00:00  10.81  10.90  10.75  10.85   38927500\n",
      "2017-11-09 15:00:00  10.84  10.84  10.73  10.79   19499600\n",
      "2017-11-10 15:00:00  10.67  10.85  10.61  10.81   27459100\n",
      "2017-11-13 15:00:00  10.68  10.75  10.57  10.70   25431100\n",
      "2017-11-14 15:00:00  10.63  10.70  10.59  10.65   16833900\n",
      "2017-11-15 15:00:00  10.37  10.54  10.35  10.54   29488000\n",
      "2017-11-16 15:00:00  10.28  10.39  10.25  10.34   21092300\n",
      "2017-11-17 15:00:00  10.33  10.34  10.23  10.30   30633900\n",
      "2017-11-20 15:00:00  10.40  10.45  10.30  10.31   30404900\n",
      "\n",
      "[215 rows x 5 columns]), ('601881.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-23 15:00:00   9.81   9.81   8.17   8.17     460605\n",
      "2017-01-24 15:00:00  10.79  10.79  10.79  10.79     543559\n",
      "2017-01-25 15:00:00  11.87  11.87  11.87  11.87    3411293\n",
      "2017-01-26 15:00:00  11.82  12.56  11.71  12.12  250239226\n",
      "2017-02-03 15:00:00  10.99  11.46  10.94  11.40  137290005\n",
      "2017-02-06 15:00:00  11.09  11.16  10.89  10.92   95518187\n",
      "2017-02-07 15:00:00  10.77  11.02  10.73  11.02  101578380\n",
      "2017-02-08 15:00:00  11.43  11.60  10.56  10.72  181606643\n",
      "2017-02-09 15:00:00  11.23  11.56  11.14  11.19  154092585\n",
      "2017-02-10 15:00:00  12.00  12.34  11.13  11.16  247215321\n",
      "2017-02-13 15:00:00  12.22  12.48  11.80  11.85  197302537\n",
      "2017-02-14 15:00:00  12.83  13.39  12.10  12.20  188114520\n",
      "2017-02-15 15:00:00  12.90  13.39  12.43  12.60  186280904\n",
      "2017-02-16 15:00:00  14.19  14.19  12.61  12.70  258121891\n",
      "2017-02-17 15:00:00  13.94  15.61  13.90  14.40  318902565\n",
      "2017-02-20 15:00:00  13.92  14.13  13.33  13.51  182239650\n",
      "2017-02-21 15:00:00  13.72  14.37  13.55  13.90  142103552\n",
      "2017-02-22 15:00:00  13.41  13.67  13.25  13.60  100329316\n",
      "2017-02-23 15:00:00  13.63  13.72  13.29  13.40   95036951\n",
      "2017-02-24 15:00:00  13.65  13.77  13.36  13.51   74172957\n",
      "2017-02-27 15:00:00  13.26  13.64  13.20  13.60   68410807\n",
      "2017-02-28 15:00:00  13.78  13.80  13.21  13.21  108147992\n",
      "2017-03-01 15:00:00  13.61  14.04  13.55  13.80   86116331\n",
      "2017-03-02 15:00:00  14.14  14.64  13.58  13.66  170168702\n",
      "2017-03-03 15:00:00  13.86  13.99  13.69  13.97   75131972\n",
      "2017-03-06 15:00:00  14.01  14.15  13.70  13.80   69905494\n",
      "2017-03-07 15:00:00  14.17  14.17  13.78  13.99   72270683\n",
      "2017-03-08 15:00:00  13.91  14.14  13.82  14.12   59973770\n",
      "2017-03-09 15:00:00  13.83  13.93  13.59  13.86   66498710\n",
      "2017-03-10 15:00:00  13.29  13.89  13.25  13.73   62706529\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-10-10 15:00:00  15.73  15.76  15.30  15.52   20342300\n",
      "2017-10-11 15:00:00  15.36  15.68  15.34  15.62   17141300\n",
      "2017-10-12 15:00:00  14.98  15.45  14.84  15.37   18503200\n",
      "2017-10-13 15:00:00  15.18  15.21  14.89  15.03   11628200\n",
      "2017-10-16 15:00:00  14.85  15.43  14.81  15.14   19712400\n",
      "2017-10-17 15:00:00  14.62  14.89  14.51  14.78   13711200\n",
      "2017-10-18 15:00:00  14.49  14.83  14.43  14.74   12295400\n",
      "2017-10-19 15:00:00  13.81  14.55  13.65  14.47   18505300\n",
      "2017-10-20 15:00:00  13.96  14.06  13.71  13.72    8975300\n",
      "2017-10-23 15:00:00  13.96  14.02  13.73  13.98    7589900\n",
      "2017-10-24 15:00:00  14.19  14.32  13.88  13.89   14374300\n",
      "2017-10-25 15:00:00  14.16  14.25  13.99  14.19   10690300\n",
      "2017-10-26 15:00:00  14.31  14.75  14.07  14.12   20550900\n",
      "2017-10-27 15:00:00  13.96  14.43  13.84  14.21   12720500\n",
      "2017-10-30 15:00:00  13.19  13.89  13.04  13.85   20899100\n",
      "2017-10-31 15:00:00  13.19  13.27  12.91  13.14   12627600\n",
      "2017-11-01 15:00:00  12.99  13.33  12.93  13.15   12716200\n",
      "2017-11-02 15:00:00  13.05  13.33  12.71  12.94   15987300\n",
      "2017-11-03 15:00:00  13.09  13.21  12.78  12.99   11385400\n",
      "2017-11-06 15:00:00  13.14  13.15  12.91  13.11    8655900\n",
      "2017-11-07 15:00:00  13.32  13.42  13.03  13.09   17939500\n",
      "2017-11-08 15:00:00  13.57  14.06  13.23  13.25   29247800\n",
      "2017-11-09 15:00:00  13.56  13.67  13.44  13.44   12182800\n",
      "2017-11-10 15:00:00  13.65  13.86  13.42  13.61   17258700\n",
      "2017-11-13 15:00:00  13.52  13.80  13.45  13.58   13166000\n",
      "2017-11-14 15:00:00  13.15  13.54  13.11  13.53   15596600\n",
      "2017-11-15 15:00:00  13.03  13.27  13.00  13.06    9138800\n",
      "2017-11-16 15:00:00  12.76  13.11  12.75  13.06   10662400\n",
      "2017-11-17 15:00:00  12.30  12.82  12.20  12.70   17538200\n",
      "2017-11-20 15:00:00  12.32  12.35  11.94  12.13    8568500\n",
      "\n",
      "[201 rows x 5 columns]), ('601901.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   7.96  7.99  7.81  7.83   45033729\n",
      "2017-01-04 15:00:00   8.00  8.02  7.91  7.95   32317783\n",
      "2017-01-05 15:00:00   7.94  8.03  7.92  7.99   28165906\n",
      "2017-01-06 15:00:00   7.87  7.96  7.84  7.95   31240535\n",
      "2017-01-09 15:00:00   7.89  7.92  7.84  7.84   26713739\n",
      "2017-01-10 15:00:00   7.90  7.91  7.85  7.89   36960626\n",
      "2017-01-11 15:00:00   7.74  7.89  7.72  7.84   43702007\n",
      "2017-01-12 15:00:00   7.70  7.79  7.69  7.72   28707594\n",
      "2017-01-13 15:00:00   7.73  7.77  7.62  7.71   39024932\n",
      "2017-01-16 15:00:00   7.81  7.85  7.48  7.68   95534309\n",
      "2017-01-17 15:00:00   7.79  7.80  7.67  7.72   25646861\n",
      "2017-01-18 15:00:00   7.91  7.95  7.75  7.77   60598024\n",
      "2017-01-19 15:00:00   7.93  7.96  7.85  7.86   33402412\n",
      "2017-01-20 15:00:00   8.10  8.11  7.89  7.90   61079651\n",
      "2017-01-23 15:00:00   8.06  8.17  8.03  8.08   36056852\n",
      "2017-01-24 15:00:00   7.98  8.08  7.96  8.07   19279476\n",
      "2017-01-25 15:00:00   7.99  8.02  7.93  7.95   20443173\n",
      "2017-01-26 15:00:00   8.01  8.06  7.98  8.02   30636271\n",
      "2017-02-03 15:00:00   8.04  8.07  7.99  8.00   27299880\n",
      "2017-02-06 15:00:00   8.03  8.07  7.95  8.02   37285825\n",
      "2017-02-07 15:00:00   8.01  8.06  7.94  8.02   26561564\n",
      "2017-02-08 15:00:00   8.35  8.39  7.98  8.00  106253268\n",
      "2017-02-09 15:00:00   8.49  8.65  8.26  8.30  176827906\n",
      "2017-02-10 15:00:00   8.53  8.60  8.39  8.46   79168031\n",
      "2017-02-13 15:00:00   8.52  8.68  8.44  8.48   77939153\n",
      "2017-02-14 15:00:00   8.58  8.64  8.46  8.50   42470464\n",
      "2017-02-15 15:00:00   8.56  8.67  8.50  8.56   53592763\n",
      "2017-02-16 15:00:00   8.75  8.76  8.50  8.53   73650474\n",
      "2017-03-03 15:00:00   8.25  8.48  8.15  8.34   91332909\n",
      "2017-03-06 15:00:00   8.71  8.77  8.21  8.26   68254162\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   8.99  8.99  8.89  8.91    7844900\n",
      "2017-10-11 15:00:00   8.96  8.99  8.93  8.97    4645900\n",
      "2017-10-12 15:00:00   8.91  8.98  8.90  8.96    3756600\n",
      "2017-10-13 15:00:00   8.96  9.03  8.93  8.93    6420800\n",
      "2017-10-16 15:00:00   8.89  9.05  8.89  9.01    6834400\n",
      "2017-10-17 15:00:00   8.81  8.92  8.78  8.91    8283400\n",
      "2017-10-18 15:00:00   8.65  8.86  8.63  8.84    8628600\n",
      "2017-10-19 15:00:00   8.39  8.66  8.37  8.65   10347200\n",
      "2017-10-20 15:00:00   8.46  8.46  8.37  8.38    3626100\n",
      "2017-10-23 15:00:00   8.48  8.51  8.44  8.46    4308400\n",
      "2017-10-24 15:00:00   8.49  8.51  8.45  8.48    4365300\n",
      "2017-10-25 15:00:00   8.46  8.53  8.46  8.51    4053200\n",
      "2017-10-26 15:00:00   8.48  8.54  8.41  8.48    7895700\n",
      "2017-10-27 15:00:00   8.41  8.50  8.41  8.48    4543300\n",
      "2017-10-30 15:00:00   8.11  8.42  8.10  8.41   10143500\n",
      "2017-10-31 15:00:00   8.10  8.13  8.03  8.11    5778500\n",
      "2017-11-01 15:00:00   8.13  8.22  8.10  8.10    5695900\n",
      "2017-11-02 15:00:00   8.56  8.87  8.13  8.17   23254900\n",
      "2017-11-03 15:00:00   8.52  8.55  8.37  8.48   10899300\n",
      "2017-11-06 15:00:00   8.46  8.50  8.39  8.49    6879100\n",
      "2017-11-07 15:00:00   8.53  8.63  8.43  8.46   11505900\n",
      "2017-11-08 15:00:00   8.63  8.84  8.42  8.48   20840500\n",
      "2017-11-09 15:00:00   8.58  8.64  8.51  8.57    8192300\n",
      "2017-11-10 15:00:00   8.61  8.71  8.49  8.57   10827000\n",
      "2017-11-13 15:00:00   8.65  8.85  8.61  8.71   14159300\n",
      "2017-11-14 15:00:00   8.63  8.67  8.51  8.61    9596000\n",
      "2017-11-15 15:00:00   8.49  8.66  8.47  8.55    7899100\n",
      "2017-11-16 15:00:00   8.28  8.55  8.27  8.48    9105700\n",
      "2017-11-17 15:00:00   8.11  8.35  8.09  8.28    9056100\n",
      "2017-11-20 15:00:00   8.22  8.22  7.96  8.08    8036600\n",
      "\n",
      "[205 rows x 5 columns]), ('601985.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   7.20  7.22  7.13  7.15   55033020\n",
      "2017-01-04 15:00:00   7.20  7.21  7.17  7.20   59782099\n",
      "2017-01-05 15:00:00   7.15  7.21  7.11  7.20  101212965\n",
      "2017-01-06 15:00:00   7.15  7.20  7.12  7.14   62948599\n",
      "2017-01-09 15:00:00   7.29  7.30  7.12  7.13  143938898\n",
      "2017-01-10 15:00:00   7.23  7.29  7.22  7.28   68514533\n",
      "2017-01-11 15:00:00   7.21  7.28  7.18  7.23   70601472\n",
      "2017-01-12 15:00:00   7.16  7.23  7.15  7.21   52573465\n",
      "2017-01-13 15:00:00   7.18  7.20  7.11  7.16   70808520\n",
      "2017-01-16 15:00:00   7.17  7.19  7.00  7.15  128028000\n",
      "2017-01-17 15:00:00   7.12  7.15  7.07  7.13   38145736\n",
      "2017-01-18 15:00:00   7.11  7.15  7.10  7.11   26343548\n",
      "2017-01-19 15:00:00   7.07  7.12  7.05  7.12   33854082\n",
      "2017-01-20 15:00:00   7.09  7.12  7.05  7.05   24695481\n",
      "2017-01-23 15:00:00   7.12  7.15  7.09  7.10   38519275\n",
      "2017-01-24 15:00:00   7.13  7.14  7.09  7.11   24557227\n",
      "2017-01-25 15:00:00   7.14  7.14  7.10  7.12   21456919\n",
      "2017-01-26 15:00:00   7.14  7.16  7.12  7.13   26442977\n",
      "2017-02-03 15:00:00   7.16  7.19  7.13  7.14   35318585\n",
      "2017-02-06 15:00:00   7.20  7.20  7.15  7.16   34785533\n",
      "2017-02-07 15:00:00   7.17  7.21  7.14  7.20   33506036\n",
      "2017-02-08 15:00:00   7.18  7.18  7.11  7.16   43324060\n",
      "2017-02-09 15:00:00   7.20  7.23  7.13  7.16   53154590\n",
      "2017-02-10 15:00:00   7.24  7.28  7.19  7.20   98610680\n",
      "2017-02-13 15:00:00   7.28  7.29  7.22  7.25   81510754\n",
      "2017-02-14 15:00:00   7.25  7.30  7.23  7.29   48993638\n",
      "2017-02-15 15:00:00   7.26  7.38  7.25  7.27  115449386\n",
      "2017-02-16 15:00:00   7.55  7.82  7.22  7.24  275324604\n",
      "2017-02-17 15:00:00   7.40  7.56  7.39  7.47  162723780\n",
      "2017-02-20 15:00:00   7.44  7.51  7.37  7.44  145637476\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   7.61  7.62  7.58  7.60    8653500\n",
      "2017-10-11 15:00:00   7.61  7.62  7.58  7.62    8534700\n",
      "2017-10-12 15:00:00   7.57  7.62  7.56  7.61    7649800\n",
      "2017-10-13 15:00:00   7.58  7.59  7.55  7.58    5557000\n",
      "2017-10-16 15:00:00   7.55  7.59  7.54  7.56   10280600\n",
      "2017-10-17 15:00:00   7.58  7.62  7.53  7.53   10612200\n",
      "2017-10-18 15:00:00   7.66  7.67  7.57  7.59   22472000\n",
      "2017-10-19 15:00:00   7.70  7.70  7.61  7.66   20954300\n",
      "2017-10-20 15:00:00   7.67  7.69  7.64  7.67    8099200\n",
      "2017-10-23 15:00:00   7.63  7.69  7.62  7.66    8751800\n",
      "2017-10-24 15:00:00   7.71  7.72  7.62  7.64   24782900\n",
      "2017-10-25 15:00:00   7.68  7.70  7.66  7.70   10530500\n",
      "2017-10-26 15:00:00   7.75  7.77  7.65  7.66   22633700\n",
      "2017-10-27 15:00:00   7.73  7.82  7.71  7.77   17418200\n",
      "2017-10-30 15:00:00   7.87  7.94  7.65  7.75   52475900\n",
      "2017-10-31 15:00:00   7.89  7.95  7.83  7.86   32426900\n",
      "2017-11-01 15:00:00   7.91  7.97  7.86  7.90   27653800\n",
      "2017-11-02 15:00:00   7.89  7.91  7.78  7.87   29084000\n",
      "2017-11-03 15:00:00   7.90  7.92  7.79  7.87   29183000\n",
      "2017-11-06 15:00:00   7.90  7.96  7.87  7.90   19620200\n",
      "2017-11-07 15:00:00   7.99  8.03  7.86  7.92   45131200\n",
      "2017-11-08 15:00:00   7.91  8.02  7.88  7.96   30576800\n",
      "2017-11-09 15:00:00   7.90  7.93  7.84  7.90   20542400\n",
      "2017-11-10 15:00:00   7.82  7.90  7.80  7.88   30803200\n",
      "2017-11-13 15:00:00   7.80  7.86  7.76  7.83   21968500\n",
      "2017-11-14 15:00:00   7.80  7.84  7.76  7.78   15766200\n",
      "2017-11-15 15:00:00   7.79  7.83  7.76  7.77   15918000\n",
      "2017-11-16 15:00:00   7.54  7.76  7.53  7.76   40822200\n",
      "2017-11-17 15:00:00   7.63  7.65  7.28  7.52   67654100\n",
      "2017-11-20 15:00:00   7.54  7.60  7.43  7.51   15793000\n",
      "\n",
      "[215 rows x 5 columns]), ('601988.XSHG',                      close  high   low  open     volume\n",
      "datetime                                               \n",
      "2017-01-03 15:00:00   5.42  5.45  5.38  5.39  113687763\n",
      "2017-01-04 15:00:00   5.44  5.45  5.41  5.42   94002132\n",
      "2017-01-05 15:00:00   5.44  5.45  5.41  5.45  121066329\n",
      "2017-01-06 15:00:00   5.38  5.42  5.36  5.42  165438251\n",
      "2017-01-09 15:00:00   5.39  5.39  5.36  5.38   85800724\n",
      "2017-01-10 15:00:00   5.38  5.39  5.36  5.39  116026700\n",
      "2017-01-11 15:00:00   5.39  5.41  5.36  5.38  109653385\n",
      "2017-01-12 15:00:00   5.39  5.39  5.36  5.38  111184326\n",
      "2017-01-13 15:00:00   5.42  5.42  5.36  5.36  154072229\n",
      "2017-01-16 15:00:00   5.49  5.53  5.38  5.41  376903624\n",
      "2017-01-17 15:00:00   5.49  5.50  5.45  5.47  102381158\n",
      "2017-01-18 15:00:00   5.50  5.52  5.47  5.49  108266531\n",
      "2017-01-19 15:00:00   5.50  5.56  5.49  5.50  143843540\n",
      "2017-01-20 15:00:00   5.50  5.52  5.49  5.50   76470073\n",
      "2017-01-23 15:00:00   5.50  5.52  5.49  5.52  100229539\n",
      "2017-01-24 15:00:00   5.55  5.55  5.49  5.50  183042560\n",
      "2017-01-25 15:00:00   5.53  5.55  5.52  5.53   82113320\n",
      "2017-01-26 15:00:00   5.61  5.63  5.53  5.55  154662324\n",
      "2017-02-03 15:00:00   5.56  5.61  5.55  5.61   70918131\n",
      "2017-02-06 15:00:00   5.56  5.60  5.55  5.56  111705899\n",
      "2017-02-07 15:00:00   5.53  5.58  5.52  5.56  109941968\n",
      "2017-02-08 15:00:00   5.56  5.56  5.50  5.53   78136121\n",
      "2017-02-09 15:00:00   5.60  5.61  5.55  5.55  103917629\n",
      "2017-02-10 15:00:00   5.63  5.64  5.60  5.60  138917324\n",
      "2017-02-13 15:00:00   5.69  5.71  5.63  5.64  164876663\n",
      "2017-02-14 15:00:00   5.66  5.69  5.64  5.69  112420180\n",
      "2017-02-15 15:00:00   5.74  5.77  5.66  5.67  263269929\n",
      "2017-02-16 15:00:00   5.77  5.80  5.74  5.77  169611620\n",
      "2017-02-17 15:00:00   5.69  5.78  5.69  5.78  140586052\n",
      "2017-02-20 15:00:00   5.78  5.83  5.69  5.71  326358412\n",
      "...                    ...   ...   ...   ...        ...\n",
      "2017-10-10 15:00:00   6.49  6.49  6.43  6.46   55460800\n",
      "2017-10-11 15:00:00   6.54  6.55  6.46  6.49   80042700\n",
      "2017-10-12 15:00:00   6.52  6.55  6.49  6.54   56556200\n",
      "2017-10-13 15:00:00   6.49  6.51  6.46  6.49   42813900\n",
      "2017-10-16 15:00:00   6.51  6.52  6.44  6.47   60867100\n",
      "2017-10-17 15:00:00   6.49  6.52  6.47  6.51   38189600\n",
      "2017-10-18 15:00:00   6.54  6.57  6.44  6.47  105715300\n",
      "2017-10-19 15:00:00   6.57  6.58  6.49  6.51   96781700\n",
      "2017-10-20 15:00:00   6.54  6.55  6.51  6.54   39508500\n",
      "2017-10-23 15:00:00   6.44  6.54  6.44  6.52   58449400\n",
      "2017-10-24 15:00:00   6.46  6.49  6.44  6.44   50315200\n",
      "2017-10-25 15:00:00   6.38  6.47  6.36  6.46   75617100\n",
      "2017-10-26 15:00:00   6.27  6.38  6.24  6.38  172862400\n",
      "2017-10-27 15:00:00   6.32  6.36  6.24  6.25  108202000\n",
      "2017-10-30 15:00:00   6.35  6.38  6.29  6.32   97535300\n",
      "2017-10-31 15:00:00   6.18  6.30  6.18  6.30  138886800\n",
      "2017-11-01 15:00:00   6.13  6.19  6.10  6.18  141272900\n",
      "2017-11-02 15:00:00   6.10  6.13  6.03  6.11  119252500\n",
      "2017-11-03 15:00:00   6.08  6.10  6.02  6.08  118633500\n",
      "2017-11-06 15:00:00   6.07  6.08  6.02  6.05   79572500\n",
      "2017-11-07 15:00:00   6.13  6.16  6.05  6.05   87160800\n",
      "2017-11-08 15:00:00   6.19  6.19  6.11  6.13   91860000\n",
      "2017-11-09 15:00:00   6.14  6.19  6.13  6.18   45805800\n",
      "2017-11-10 15:00:00   6.07  6.14  6.03  6.13  106695600\n",
      "2017-11-13 15:00:00   6.10  6.13  6.03  6.05  175495000\n",
      "2017-11-14 15:00:00   6.08  6.08  6.03  6.07   64675300\n",
      "2017-11-15 15:00:00   6.07  6.08  6.03  6.07   56563000\n",
      "2017-11-16 15:00:00   6.02  6.07  6.00  6.07   46680800\n",
      "2017-11-17 15:00:00   6.14  6.18  6.02  6.02  160313500\n",
      "2017-11-20 15:00:00   6.18  6.21  6.10  6.13  114923500\n",
      "\n",
      "[215 rows x 5 columns]), ('601989.XSHG',                      close   high    low   open     volume\n",
      "datetime                                                  \n",
      "2017-01-03 15:00:00  12.32  12.35  11.93  11.95  189598255\n",
      "2017-01-04 15:00:00  12.38  12.44  12.25  12.25  208742752\n",
      "2017-01-05 15:00:00  12.54  12.62  12.32  12.32  226152290\n",
      "2017-01-06 15:00:00  12.47  12.70  12.40  12.54  214847387\n",
      "2017-01-09 15:00:00  13.02  13.09  12.42  12.47  422152651\n",
      "2017-01-10 15:00:00  12.74  13.01  12.70  12.99  246989575\n",
      "2017-01-11 15:00:00  12.84  12.97  12.64  12.69  226412662\n",
      "2017-01-12 15:00:00  12.85  13.26  12.57  12.75  286158663\n",
      "2017-01-13 15:00:00  12.62  12.89  12.50  12.75  224137757\n",
      "2017-01-16 15:00:00  12.37  12.52  12.00  12.49  306688451\n",
      "2017-01-17 15:00:00  12.44  12.55  12.25  12.27  122827283\n",
      "2017-01-18 15:00:00  12.38  12.62  12.35  12.44  120855122\n",
      "2017-01-19 15:00:00  12.18  12.35  12.13  12.27   97407182\n",
      "2017-01-20 15:00:00  12.38  12.44  12.13  12.17  109446843\n",
      "2017-01-23 15:00:00  12.75  12.84  12.47  12.49  203744160\n",
      "2017-01-24 15:00:00  12.70  12.82  12.64  12.72  118312015\n",
      "2017-01-25 15:00:00  12.84  12.85  12.60  12.64  115580279\n",
      "2017-01-26 15:00:00  12.85  12.94  12.67  12.85  123390765\n",
      "2017-02-03 15:00:00  12.92  13.19  12.82  12.94  194861447\n",
      "2017-02-06 15:00:00  12.82  12.99  12.69  12.85  165910332\n",
      "2017-02-07 15:00:00  12.79  12.89  12.65  12.75  121665601\n",
      "2017-02-08 15:00:00  13.16  13.22  12.69  12.74  321427881\n",
      "2017-02-09 15:00:00  13.24  13.36  13.04  13.29  272540975\n",
      "2017-02-10 15:00:00  13.49  13.64  13.12  13.19  353557515\n",
      "2017-02-13 15:00:00  13.48  13.54  13.31  13.43  207541097\n",
      "2017-02-14 15:00:00  13.26  13.54  13.22  13.44  198923143\n",
      "2017-02-15 15:00:00  12.90  13.14  12.82  13.09  328152358\n",
      "2017-02-16 15:00:00  12.97  12.99  12.79  12.84  131700962\n",
      "2017-02-17 15:00:00  12.99  13.11  12.82  12.94  218071483\n",
      "2017-02-20 15:00:00  13.06  13.09  12.94  13.02  161369476\n",
      "...                    ...    ...    ...    ...        ...\n",
      "2017-05-02 15:00:00  11.71  11.83  11.68  11.83   66516894\n",
      "2017-05-03 15:00:00  11.51  11.70  11.51  11.68   86226463\n",
      "2017-05-04 15:00:00  11.38  11.50  11.28  11.50  105002084\n",
      "2017-05-05 15:00:00  11.14  11.43  11.01  11.31  139291098\n",
      "2017-05-08 15:00:00  10.76  11.06  10.66  11.06  144383861\n",
      "2017-05-09 15:00:00  10.89  10.98  10.66  10.72   77318745\n",
      "2017-05-10 15:00:00  10.57  10.91  10.57  10.89   40267500\n",
      "2017-05-11 15:00:00  10.64  10.67  10.25  10.45   52067900\n",
      "2017-05-12 15:00:00  10.56  10.64  10.51  10.59   41523700\n",
      "2017-05-15 15:00:00  10.44  10.66  10.44  10.59   36408300\n",
      "2017-05-16 15:00:00  10.56  10.59  10.19  10.45   59984100\n",
      "2017-05-17 15:00:00  10.61  10.72  10.52  10.54   53909900\n",
      "2017-05-18 15:00:00  10.47  10.61  10.44  10.51   31986100\n",
      "2017-05-19 15:00:00  10.56  10.59  10.49  10.52   51783854\n",
      "2017-05-22 15:00:00  10.45  10.67  10.44  10.52   34573900\n",
      "2017-05-23 15:00:00  10.10  10.49  10.09  10.45   58354600\n",
      "2017-05-24 15:00:00  10.14  10.15   9.87  10.02   38052400\n",
      "2017-05-25 15:00:00  10.32  10.35  10.04  10.19   48837500\n",
      "2017-05-26 15:00:00  10.42  10.44  10.27  10.29   37444300\n",
      "2017-11-06 15:00:00  10.91  11.46  10.77  11.18  173580500\n",
      "2017-11-07 15:00:00  11.38  11.46  10.77  10.84  117562500\n",
      "2017-11-08 15:00:00  11.16  11.33  11.09  11.33   81308900\n",
      "2017-11-09 15:00:00  11.14  11.23  11.08  11.13   56688300\n",
      "2017-11-10 15:00:00  10.92  11.19  10.86  11.13   64234100\n",
      "2017-11-13 15:00:00  10.69  10.92  10.66  10.89   66121300\n",
      "2017-11-14 15:00:00  10.64  10.79  10.49  10.66   54575400\n",
      "2017-11-15 15:00:00  10.51  10.64  10.49  10.54   34343600\n",
      "2017-11-16 15:00:00  10.49  10.59  10.40  10.49   42821800\n",
      "2017-11-17 15:00:00  10.14  10.52  10.10  10.49   55797100\n",
      "2017-11-20 15:00:00  10.25  10.30   9.93  10.09   43195600\n",
      "\n",
      "[107 rows x 5 columns])])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " df =pd.read_excel('sz50.xlsx', None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['600000.XSHG', '600016.XSHG', '600028.XSHG', '600029.XSHG', '600030.XSHG', '600036.XSHG', '600048.XSHG', '600050.XSHG', '600100.XSHG', '600104.XSHG', '600111.XSHG', '600340.XSHG', '600485.XSHG', '600518.XSHG', '600519.XSHG', '600547.XSHG', '600606.XSHG', '600837.XSHG', '600887.XSHG', '600919.XSHG', '600958.XSHG', '600999.XSHG', '601006.XSHG', '601088.XSHG', '601166.XSHG', '601169.XSHG', '601186.XSHG', '601198.XSHG', '601211.XSHG', '601229.XSHG', '601288.XSHG', '601318.XSHG', '601328.XSHG', '601336.XSHG', '601390.XSHG', '601398.XSHG', '601601.XSHG', '601628.XSHG', '601668.XSHG', '601688.XSHG', '601766.XSHG', '601788.XSHG', '601800.XSHG', '601818.XSHG', '601857.XSHG', '601881.XSHG', '601901.XSHG', '601985.XSHG', '601988.XSHG', '601989.XSHG'])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_excel('sz50.xlsx',sheetname='600036.XSHG',index_col='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      close    high     low    open    volume\n",
      "datetime                                                     \n",
      "2017-01-03 15:00:00   69.31   69.39   67.80   67.92  30449820\n",
      "2017-01-04 15:00:00   69.42   69.89   68.88   69.08  25665746\n",
      "2017-01-05 15:00:00   69.85   70.27   69.58   69.66  24562635\n",
      "2017-01-06 15:00:00   69.35   70.08   69.31   69.85  17487854\n",
      "2017-01-09 15:00:00   69.23   69.96   69.12   69.66  17341504\n",
      "2017-01-10 15:00:00   69.23   69.81   69.12   69.27  10668237\n",
      "2017-01-11 15:00:00   69.27   69.73   69.19   69.58  13428968\n",
      "2017-01-12 15:00:00   69.46   69.96   69.23   69.27  14095858\n",
      "2017-01-13 15:00:00   70.27   70.93   69.39   69.46  25113771\n",
      "2017-01-16 15:00:00   71.62   71.74   70.08   70.16  75103166\n",
      "2017-01-17 15:00:00   71.20   71.74   71.12   71.39  23566010\n",
      "2017-01-18 15:00:00   71.74   71.82   71.28   71.35  17879565\n",
      "2017-01-19 15:00:00   71.47   72.32   71.43   71.59  13110922\n",
      "2017-01-20 15:00:00   71.66   71.97   71.28   71.55  21739051\n",
      "2017-01-23 15:00:00   71.39   72.40   71.04   72.09  19875392\n",
      "2017-01-24 15:00:00   72.78   72.86   71.39   71.74  25543630\n",
      "2017-01-25 15:00:00   72.86   73.13   72.09   72.59  15272178\n",
      "2017-01-26 15:00:00   73.32   74.29   72.63   72.94  27318666\n",
      "2017-02-03 15:00:00   72.20   73.63   72.01   73.63  23302810\n",
      "2017-02-06 15:00:00   71.78   72.94   71.55   72.86  23996219\n",
      "2017-02-07 15:00:00   71.70   72.09   71.59   71.89  22940249\n",
      "2017-02-08 15:00:00   71.78   71.78   71.31   71.59  19599726\n",
      "2017-02-09 15:00:00   72.36   73.05   71.74   71.74  22249868\n",
      "2017-02-10 15:00:00   72.94   73.21   72.28   72.78  39642313\n",
      "2017-02-13 15:00:00   73.24   73.67   72.90   72.94  25320767\n",
      "2017-02-14 15:00:00   72.78   73.44   72.59   73.32  23787741\n",
      "2017-02-15 15:00:00   73.82   74.21   72.94   73.21  59678978\n",
      "2017-02-16 15:00:00   73.82   74.63   73.48   74.05  35223424\n",
      "2017-02-17 15:00:00   73.40   74.21   73.24   74.05  17980208\n",
      "2017-02-20 15:00:00   74.94   75.25   73.24   73.44  44607085\n",
      "...                     ...     ...     ...     ...       ...\n",
      "2017-10-10 15:00:00  104.23  105.82  101.47  103.95  51590600\n",
      "2017-10-11 15:00:00  103.91  104.75  103.39  103.95  23650400\n",
      "2017-10-12 15:00:00  105.23  105.90  103.95  104.35  23267400\n",
      "2017-10-13 15:00:00  104.55  105.74  104.39  105.34  16395500\n",
      "2017-10-16 15:00:00  107.22  107.54  104.55  105.07  34795900\n",
      "2017-10-17 15:00:00  107.86  109.06  106.54  106.54  27227800\n",
      "2017-10-18 15:00:00  108.18  108.90  107.38  108.06  19014200\n",
      "2017-10-19 15:00:00  108.14  108.94  107.42  108.18  20272600\n",
      "2017-10-20 15:00:00  106.82  107.90  106.58  107.58  14128700\n",
      "2017-10-23 15:00:00  105.74  107.26  105.70  106.66  18036600\n",
      "2017-10-24 15:00:00  106.22  107.06  105.42  105.58  18542300\n",
      "2017-10-25 15:00:00  106.94  107.30  105.38  106.02  17211500\n",
      "2017-10-26 15:00:00  105.94  108.50  105.46  106.38  35886900\n",
      "2017-10-27 15:00:00  112.13  112.29  106.54  106.66  56214600\n",
      "2017-10-30 15:00:00  110.89  111.93  109.81  111.05  50826500\n",
      "2017-10-31 15:00:00  108.14  109.85  107.42  109.61  29707800\n",
      "2017-11-01 15:00:00  107.34  108.46  106.38  108.34  32890100\n",
      "2017-11-02 15:00:00  107.78  107.82  106.66  106.90  18322000\n",
      "2017-11-03 15:00:00  107.98  108.34  106.22  107.34  34042900\n",
      "2017-11-06 15:00:00  106.18  107.50  104.87  107.34  34867200\n",
      "2017-11-07 15:00:00  107.86  108.78  105.86  106.10  36048200\n",
      "2017-11-08 15:00:00  108.10  109.41  106.94  107.66  34603200\n",
      "2017-11-09 15:00:00  108.02  109.49  107.10  107.70  18438200\n",
      "2017-11-10 15:00:00  108.02  108.58  106.10  107.38  35885400\n",
      "2017-11-13 15:00:00  110.41  113.13  108.46  108.46  64037400\n",
      "2017-11-14 15:00:00  111.81  112.81  110.57  110.93  42886800\n",
      "2017-11-15 15:00:00  111.25  112.73  110.21  111.65  34028800\n",
      "2017-11-16 15:00:00  112.13  112.13  109.73  110.77  33138100\n",
      "2017-11-17 15:00:00  117.24  117.67  112.93  112.93  74014200\n",
      "2017-11-20 15:00:00  121.82  122.50  116.20  116.92  64388900\n",
      "\n",
      "[215 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data =  pd.read_excel('sz50.xlsx','600036.XSHG', index_col='datetime')['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2017-01-03 15:00:00     69.31\n",
      "2017-01-04 15:00:00     69.42\n",
      "2017-01-05 15:00:00     69.85\n",
      "2017-01-06 15:00:00     69.35\n",
      "2017-01-09 15:00:00     69.23\n",
      "2017-01-10 15:00:00     69.23\n",
      "2017-01-11 15:00:00     69.27\n",
      "2017-01-12 15:00:00     69.46\n",
      "2017-01-13 15:00:00     70.27\n",
      "2017-01-16 15:00:00     71.62\n",
      "2017-01-17 15:00:00     71.20\n",
      "2017-01-18 15:00:00     71.74\n",
      "2017-01-19 15:00:00     71.47\n",
      "2017-01-20 15:00:00     71.66\n",
      "2017-01-23 15:00:00     71.39\n",
      "2017-01-24 15:00:00     72.78\n",
      "2017-01-25 15:00:00     72.86\n",
      "2017-01-26 15:00:00     73.32\n",
      "2017-02-03 15:00:00     72.20\n",
      "2017-02-06 15:00:00     71.78\n",
      "2017-02-07 15:00:00     71.70\n",
      "2017-02-08 15:00:00     71.78\n",
      "2017-02-09 15:00:00     72.36\n",
      "2017-02-10 15:00:00     72.94\n",
      "2017-02-13 15:00:00     73.24\n",
      "2017-02-14 15:00:00     72.78\n",
      "2017-02-15 15:00:00     73.82\n",
      "2017-02-16 15:00:00     73.82\n",
      "2017-02-17 15:00:00     73.40\n",
      "2017-02-20 15:00:00     74.94\n",
      "                        ...  \n",
      "2017-10-10 15:00:00    104.23\n",
      "2017-10-11 15:00:00    103.91\n",
      "2017-10-12 15:00:00    105.23\n",
      "2017-10-13 15:00:00    104.55\n",
      "2017-10-16 15:00:00    107.22\n",
      "2017-10-17 15:00:00    107.86\n",
      "2017-10-18 15:00:00    108.18\n",
      "2017-10-19 15:00:00    108.14\n",
      "2017-10-20 15:00:00    106.82\n",
      "2017-10-23 15:00:00    105.74\n",
      "2017-10-24 15:00:00    106.22\n",
      "2017-10-25 15:00:00    106.94\n",
      "2017-10-26 15:00:00    105.94\n",
      "2017-10-27 15:00:00    112.13\n",
      "2017-10-30 15:00:00    110.89\n",
      "2017-10-31 15:00:00    108.14\n",
      "2017-11-01 15:00:00    107.34\n",
      "2017-11-02 15:00:00    107.78\n",
      "2017-11-03 15:00:00    107.98\n",
      "2017-11-06 15:00:00    106.18\n",
      "2017-11-07 15:00:00    107.86\n",
      "2017-11-08 15:00:00    108.10\n",
      "2017-11-09 15:00:00    108.02\n",
      "2017-11-10 15:00:00    108.02\n",
      "2017-11-13 15:00:00    110.41\n",
      "2017-11-14 15:00:00    111.81\n",
      "2017-11-15 15:00:00    111.25\n",
      "2017-11-16 15:00:00    112.13\n",
      "2017-11-17 15:00:00    117.24\n",
      "2017-11-20 15:00:00    121.82\n",
      "Name: close, Length: 215, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import talib as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "close =pd.read_excel('sz50.xlsx', '600036.XSHG',index_col='datetime')['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[108.34999999999995,\n",
       " 108.74099999999994,\n",
       " 109.17599999999993,\n",
       " 110.10199999999993,\n",
       " 111.66599999999991]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ta.MA(close,timeperiod=10).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import talib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "file = pd.ExcelFile('sz50.xlsx')\n",
    "data = pd.read_excel(file, sheetname = '600036.XSHG', index_col = 'datetime')\n",
    "res = ta.MA(data.close.values, 10)\n",
    "close = pd.Series(res, index = data.close.index)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(close, color = 'orange')\n",
    "plt.plot(data.close, color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= pd.read_excel('sz50.xlsx',sheetname= None, index_col='datetime')\n",
    "plt.figure(figsize=(15, 7))\n",
    "new_dict = {}\n",
    "for key,value in data.items():\n",
    "    try:\n",
    "        index = value.index\n",
    "        new_dict[key] = pd.Series(ta.ROCR100(value.close.values, timeperiod = 5), index = index)\n",
    "    except AttributeError:\n",
    "        pass \n",
    "\n",
    "df = pd.DataFrame(new_dict)\n",
    "list = df.columns.values.tolist()\n",
    "for i in range(5):\n",
    "    plt.plot(df[list[i]],label=list[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      macd  macdsignal   macdhist\n",
      "datetime            minor                                        \n",
      "2017-02-24 15:00:00 600000.XSHG   0.871114    1.197907  -0.326792\n",
      "                    600016.XSHG  -0.007077    0.265328  -0.272405\n",
      "                    600028.XSHG   0.028081    0.052015  -0.023934\n",
      "                    600029.XSHG   0.221787    0.132200   0.089587\n",
      "                    600030.XSHG   0.602873    0.620235  -0.017362\n",
      "                    600036.XSHG   1.291055    1.245643   0.045412\n",
      "                    600048.XSHG   2.316978    1.771997   0.544982\n",
      "                    600050.XSHG  -0.105248   -0.189278   0.084029\n",
      "                    600100.XSHG   0.453028    0.079491   0.373537\n",
      "                    600104.XSHG   2.271146    2.012658   0.258488\n",
      "                    600111.XSHG   2.429090    1.926561   0.502529\n",
      "                    600340.XSHG   8.025312    5.194384   2.830927\n",
      "                    600518.XSHG   1.014290    2.387216  -1.372926\n",
      "                    600519.XSHG  20.810882    7.146779  13.664103\n",
      "                    600547.XSHG  -0.041687    0.918715  -0.960402\n",
      "                    600606.XSHG   0.298737    0.267833   0.030904\n",
      "                    600837.XSHG  -1.406916   -0.673088  -0.733828\n",
      "                    600887.XSHG   7.150619    7.826700  -0.676082\n",
      "                    600919.XSHG   0.203864    0.155884   0.047980\n",
      "                    600999.XSHG   0.206569    0.203989   0.002579\n",
      "                    601006.XSHG  -0.135435   -0.173164   0.037729\n",
      "                    601088.XSHG   0.183388    0.266840  -0.083452\n",
      "                    601166.XSHG   0.539498    0.661410  -0.121912\n",
      "                    601169.XSHG   0.164487    0.169715  -0.005229\n",
      "                    601186.XSHG   0.356202    0.373367  -0.017165\n",
      "                    601198.XSHG   0.035657   -0.035817   0.071473\n",
      "                    601211.XSHG   0.170293    0.168216   0.002077\n",
      "                    601229.XSHG   0.420298    0.354342   0.065955\n",
      "                    601288.XSHG   0.052733    0.051096   0.001637\n",
      "                    601318.XSHG   0.588912    0.565824   0.023089\n",
      "...                                    ...         ...        ...\n",
      "2017-11-20 15:00:00 600958.XSHG  -0.017209   -0.030368   0.013159\n",
      "                    600999.XSHG  -0.316469   -0.361278   0.044810\n",
      "                    601006.XSHG  -0.031503   -0.035473   0.003970\n",
      "                    601088.XSHG   1.028069    0.616766   0.411303\n",
      "                    601166.XSHG  -0.397310   -0.514731   0.117421\n",
      "                    601169.XSHG  -0.061091   -0.101625   0.040533\n",
      "                    601186.XSHG  -0.102098   -0.051427  -0.050671\n",
      "                    601198.XSHG  -0.240666   -0.276337   0.035671\n",
      "                    601211.XSHG  -0.228540   -0.260129   0.031589\n",
      "                    601229.XSHG  -0.569227   -0.348796  -0.220430\n",
      "                    601288.XSHG  -0.050925   -0.046703  -0.004222\n",
      "                    601318.XSHG   9.177855    7.405553   1.772302\n",
      "                    601328.XSHG  -0.078237   -0.087515   0.009278\n",
      "                    601336.XSHG   3.017400    2.223956   0.793444\n",
      "                    601390.XSHG  -0.051329    0.003959  -0.055288\n",
      "                    601398.XSHG  -0.042961   -0.034460  -0.008502\n",
      "                    601601.XSHG   2.358322    1.947435   0.410887\n",
      "                    601628.XSHG   1.516911    1.445633   0.071278\n",
      "                    601668.XSHG  -0.064400   -0.036614  -0.027786\n",
      "                    601688.XSHG  -0.487274   -0.473025  -0.014250\n",
      "                    601766.XSHG   0.110179    0.231906  -0.121726\n",
      "                    601788.XSHG  -0.133310   -0.125970  -0.007340\n",
      "                    601800.XSHG  -0.328193   -0.232894  -0.095299\n",
      "                    601818.XSHG  -0.010007   -0.022297   0.012290\n",
      "                    601857.XSHG   0.020054    0.073234  -0.053180\n",
      "                    601881.XSHG  -0.471919   -0.403344  -0.068574\n",
      "                    601901.XSHG  -0.106860   -0.094530  -0.012330\n",
      "                    601985.XSHG  -0.017573    0.024240  -0.041813\n",
      "                    601988.XSHG  -0.082474   -0.091479   0.009005\n",
      "                    601989.XSHG  -0.249136   -0.252932   0.003796\n",
      "\n",
      "[8468 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as tb\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "data = pd.read_excel ('sz50.xlsx', sheetname = None, index_col = 'datetime')\n",
    "new_dict = {}\n",
    "for key,value in data.items():\n",
    "    try:\n",
    "        new_dict[key] = tb.abstract.MACD(value,None)\n",
    "    except:\n",
    "        pass \n",
    "p = pd.Panel(new_dict)\n",
    "q = p.transpose(2,1,0)\n",
    "qq = q.to_frame()\n",
    "print(qq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrame in module pandas.core.frame object:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame)\n",
      " |  DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  Two-dimensional size-mutable, potentially heterogeneous tabular data\n",
      " |  structure with labeled axes (rows and columns). Arithmetic operations\n",
      " |  align on both row and column labels. Can be thought of as a dict-like\n",
      " |  container for Series objects. The primary pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : numpy ndarray (structured or homogeneous), dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, or list-like objects\n",
      " |  \n",
      " |      .. versionchanged :: 0.23.0\n",
      " |         If data is a dict, argument order is maintained for Python 3.6\n",
      " |         and later.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if no column labels are provided\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer\n",
      " |  copy : boolean, default False\n",
      " |      Copy data from inputs. Only affects DataFrame / 2d ndarray input\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),\n",
      " |  ...                    columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |  >>> df2\n",
      " |      a   b   c   d   e\n",
      " |  0   2   8   8   3   4\n",
      " |  1   4   2   9   0   9\n",
      " |  2   1   0   7   8   0\n",
      " |  3   5   1   7   1   3\n",
      " |  4   6   0   2   4   2\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DataFrame.from_records : constructor from tuples, also record arrays\n",
      " |  DataFrame.from_dict : from dicts of Series, arrays, or dicts\n",
      " |  DataFrame.from_items : from sequence of (key, value) pairs\n",
      " |  pandas.read_csv, pandas.read_table, pandas.read_clipboard\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Wrapper for comparison method __eq__\n",
      " |  \n",
      " |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Wrapper for comparison method __ge__\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Wrapper for comparison method __gt__\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __iand__ = f(self, other)\n",
      " |  \n",
      " |  __ifloordiv__ = f(self, other)\n",
      " |  \n",
      " |  __imod__ = f(self, other)\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, columns=None, dtype=None, copy=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __ior__ = f(self, other)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __ixor__ = f(self, other)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Wrapper for comparison method __le__\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns length of info axis, but here we use the index\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Wrapper for comparison method __lt__\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Wrapper for comparison method __ne__\n",
      " |  \n",
      " |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |  \n",
      " |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5\n",
      " |  \n",
      " |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  1.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[np.nan, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  NaN\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  2.0  NaN\n",
      " |      b  1.0  2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.radd\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, string, dictionary, or list of string/functions\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. For\n",
      " |          a DataFrame, can pass a dict, if the keys are DataFrame column names.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - string function name.\n",
      " |          - function.\n",
      " |          - list of functions.\n",
      " |          - dict of column names -> functions (or list of functions).\n",
      " |      \n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          - 0 or 'index': apply function to each column.\n",
      " |          - 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      aggregated : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to ``numpy.mean(arr_2d,\n",
      " |      axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      max   NaN  8.0\n",
      " |      min   1.0  2.0\n",
      " |      sum  12.0  NaN\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      pandas.core.groupby.GroupBy : Perform operations over groups.\n",
      " |      pandas.core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      pandas.core.window.Rolling : Perform operations over rolling window.\n",
      " |      pandas.core.window.Expanding : Perform operations over expanding window.\n",
      " |      pandas.core.window.EWM : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (DataFrame, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True if all elements within a series or along a Dataframe\n",
      " |      axis are non-zero, not-empty or not-False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.all : Return True if all elements are True\n",
      " |      pandas.DataFrame.any : Return True if one (or more) elements are True\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      \n",
      " |      DataFrames\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis.\n",
      " |      \n",
      " |      Unlike :meth:`DataFrame.all`, this performs an *or* operation. If any of the\n",
      " |      values along the specified axis is True, this will return True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.all : Return whether all elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index=False, verify_integrity=False, sort=None)\n",
      " |      Append rows of `other` to the end of this frame, returning a new\n",
      " |      object. Columns not in this frame are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : boolean, default None\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |          The default sorting is deprecated and will change to not-sorting\n",
      " |          in a future version of pandas. Explicitly pass ``sort=True`` to\n",
      " |          silence the warning and sort. Explicitly pass ``sort=False`` to\n",
      " |          silence the warning and not sort.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      0  5  6\n",
      " |      1  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      broadcast : bool, optional\n",
      " |          Only relevant for aggregation functions:\n",
      " |      \n",
      " |          * ``False`` or ``None`` : returns a Series whose length is the\n",
      " |            length of the index or the number of columns (based on the\n",
      " |            `axis` parameter)\n",
      " |          * ``True`` : results will be broadcast to the original shape\n",
      " |            of the frame, the original index and columns will be retained.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0\n",
      " |             This argument will be removed in a future version, replaced\n",
      " |             by result_type='broadcast'.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      reduce : bool or None, default None\n",
      " |          Try to apply reduction procedures. If the DataFrame is empty,\n",
      " |          `apply` will use `reduce` to determine whether the result\n",
      " |          should be a Series or a DataFrame. If ``reduce=None`` (the\n",
      " |          default), `apply`'s return value will be guessed by calling\n",
      " |          `func` on an empty Series\n",
      " |          (note: while guessing, exceptions raised by `func` will be\n",
      " |          ignored).\n",
      " |          If ``reduce=True`` a Series will always be returned, and if\n",
      " |          ``reduce=False`` a DataFrame will always be returned.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0\n",
      " |             This argument will be removed in a future version, replaced\n",
      " |             by ``result_type='reduce'``.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwds\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the current implementation apply calls `func` twice on the\n",
      " |      first column/row to decide whether it can take a fast or slow\n",
      " |      code path. This can lead to unexpected behavior if `func` has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      column/row.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations\n",
      " |      DataFrame.aggregate: only perform aggregating type operations\n",
      " |      DataFrame.transform: only perform transformating type operations\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[4, 9],] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Retuning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing result_type='expand' will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |  \n",
      " |  applymap(self, func)\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  assign(self, **kwargs)\n",
      " |      Assign new columns to a DataFrame, returning a new object\n",
      " |      (a copy) with the new columns added to the original ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs : keyword, value pairs\n",
      " |          keywords are the column names. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      For Python 3.6 and above, later items in '\\*\\*kwargs' may refer to\n",
      " |      newly created or modified columns in 'df'; items are computed and\n",
      " |      assigned into 'df' in order.  For Python 3.5 and below, the order of\n",
      " |      keyword arguments is not specified, you cannot refer to newly created\n",
      " |      or modified columns. All items are computed first, and then assigned\n",
      " |      in alphabetical order.\n",
      " |      \n",
      " |      .. versionchanged :: 0.23.0\n",
      " |      \n",
      " |          Keyword argument order is maintained for Python 3.6 and later.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(ln_A = lambda x: np.log(x.A))\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |      \n",
      " |      Where the value already exists and is inserted:\n",
      " |      \n",
      " |      >>> newcol = np.log(df['A'])\n",
      " |      >>> df.assign(ln_A=newcol)\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |      \n",
      " |      Where the keyword arguments depend on each other\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3]})\n",
      " |      \n",
      " |      >>> df.assign(B=df.A, C=lambda x:x['A']+ x['B'])\n",
      " |          A  B  C\n",
      " |       0  1  1  2\n",
      " |       1  2  2  4\n",
      " |       2  3  3  6\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwds)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. The position of the whiskers\n",
      " |      is set by default to `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box.\n",
      " |      Outlier points are those past the end of the whiskers.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate sytem.\n",
      " |      grid : boolean, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result :\n",
      " |      \n",
      " |          The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |          * 'axes' : object of class matplotlib.axes.Axes\n",
      " |          * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |          * 'both' : a nametuple with strucure (ax, lines)\n",
      " |      \n",
      " |          For data grouped with ``by``:\n",
      " |      \n",
      " |          * :class:`~pandas.Series`\n",
      " |          * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10,4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10,3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1','Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot =  df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                       return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=None, overwrite=True)\n",
      " |      Add two DataFrame objects and do not propagate NaN values, so if for a\n",
      " |      (column, time) one frame is missing a value, it will default to the\n",
      " |      other frame's value (which might be NaN as well)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar\n",
      " |      fill_value : scalar value\n",
      " |      overwrite : boolean, default True\n",
      " |          If True then overwrite values for common keys in the calling frame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, lambda s1, s2: s1 if s1.sum() < s2.sum() else s2)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine two DataFrame objects and default to non-null values in frame\n",
      " |      calling the method. Result index columns will be the union of the\n",
      " |      respective indexes and columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      df1's values prioritized, use values from df2 to fill holes:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([[1, np.nan]])\n",
      " |      >>> df2 = pd.DataFrame([[3, 4]])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |         0    1\n",
      " |      0  1  4.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  corr(self, method='pearson', min_periods=1)\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  corrwith(self, other, axis=0, drop=False)\n",
      " |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      " |      objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' to compute column-wise, 1 or 'columns' for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result, default returns union of all\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |  \n",
      " |  count(self, axis=0, level=None, numeric_only=False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each **row**.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : boolean, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: number of non-NA elements in a Series\n",
      " |      DataFrame.shape: number of DataFrame rows and columns (including NA\n",
      " |          elements)\n",
      " |      DataFrame.isna: boolean same-sized DataFrame showing places of NA\n",
      " |          elements\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", None, \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2    None  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    4\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for one level of a `MultiIndex`:\n",
      " |      \n",
      " |      >>> df.set_index([\"Person\", \"Single\"]).count(level=\"Person\")\n",
      " |              Age\n",
      " |      Person\n",
      " |      John      2\n",
      " |      Myla      1\n",
      " |  \n",
      " |  cov(self, min_periods=None)\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.cov : compute covariance with another Series\n",
      " |      pandas.core.window.EWM.cov: expoential weighted sample covariance\n",
      " |      pandas.core.window.Expanding.cov : expanding sample covariance\n",
      " |      pandas.core.window.Rolling.cov : rolling sample covariance\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <http://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummax : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cummin : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumprod : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cumsum : Series or DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |  \n",
      " |  diff(self, periods=1, axis=0)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a DataFrame element compared with another\n",
      " |      element in the DataFrame (default is the element in the same column\n",
      " |      of the previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |          .. versionadded:: 0.16.1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff: First discrete difference for a Series.\n",
      " |      DataFrame.pct_change: Percent change over given number of periods.\n",
      " |      DataFrame.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a    b     c\n",
      " |      0 NaN  0.0   0.0\n",
      " |      1 NaN -1.0   3.0\n",
      " |      2 NaN -1.0   7.0\n",
      " |      3 NaN -1.0  13.0\n",
      " |      4 NaN  0.0  20.0\n",
      " |      5 NaN  2.0  28.0\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or Series objects.  Can also be\n",
      " |      called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : DataFrame or Series\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index, columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the selected axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3,0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset=None, keep='first', inplace=False)\n",
      " |      Return DataFrame with duplicate rows removed, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to drop duplicates in place or to return a copy\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : DataFrame\n",
      " |  \n",
      " |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. deprecated:: 0.23.0: Pass tuple or list to drop on multiple\n",
      " |          axes.\n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values.\n",
      " |      subset : array-like, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'born'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset=None, keep='first')\n",
      " |      Return boolean Series denoting duplicate rows, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the\n",
      " |            first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the\n",
      " |            last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods eq\n",
      " |  \n",
      " |  eval(self, expr, inplace=False, **kwargs)\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0.\n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`~pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, or pandas object\n",
      " |          The result of the evaluation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      pandas.eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~pandas.eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provides exponential weighted functions\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{ for } halflife > 0`\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : boolean, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average)\n",
      " |      ignore_na : boolean, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      expanding : Provides expanding transformations.\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provides expanding transformations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame). (values not\n",
      " |          in the dict/Series/DataFrame will not be filled). This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                    columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rfloordiv\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ge\n",
      " |  \n",
      " |  get_value(self, index, col, takeable=False)\n",
      " |      Quickly retrieve single value at passed column and index\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use .at[] or .iat[] accessors instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods gt\n",
      " |  \n",
      " |  hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, **kwds)\n",
      " |      Make a histogram of the DataFrame's.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : boolean, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : integer or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      **kwds\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          This example draws a histogram based on the length and width of\n",
      " |          some animals, displayed in three bins\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index= ['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |  \n",
      " |  info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and column dtypes, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources.\n",
      " |      null_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the frame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |         int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |      int_col      5 non-null int64\n",
      " |      text_col     5 non-null object\n",
      " |      float_col    5 non-null float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 200.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 200.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\", encoding=\"utf-8\") as f:\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |      column_1    1000000 non-null object\n",
      " |      column_2    1000000 non-null object\n",
      " |      column_3    1000000 non-null object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |      column_1    1000000 non-null object\n",
      " |      column_2    1000000 non-null object\n",
      " |      column_3    1000000 non-null object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 188.8 MB\n",
      " |  \n",
      " |  insert(self, loc, column, value, allow_duplicates=False)\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns)\n",
      " |      column : string, number, or hashable object\n",
      " |          label of the inserted column\n",
      " |      value : int, Series, or array-like\n",
      " |      allow_duplicates : bool, optional\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return boolean DataFrame showing whether each element in the\n",
      " |      DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dictionary\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dictionary, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      DataFrame of booleans\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      When ``values`` is a list:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> df.isin([1, 3, 12, 'a'])\n",
      " |             A      B\n",
      " |      0   True   True\n",
      " |      1  False  False\n",
      " |      2   True  False\n",
      " |      \n",
      " |      When ``values`` is a dict:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
      " |      >>> df.isin({'A': [1, 3], 'B': [4, 7, 12]})\n",
      " |             A      B\n",
      " |      0   True  False  # Note that B didn't match the 1 here.\n",
      " |      1  False   True\n",
      " |      2   True   True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> other = DataFrame({'A': [1, 3, 3, 2], 'B': ['e', 'f', 'f', 'e']})\n",
      " |      >>> df.isin(other)\n",
      " |             A      B\n",
      " |      0   True  False\n",
      " |      1  False  False  # Column A in `other` has a 3, but not at index 1.\n",
      " |      2   True   True\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : alias of isna\n",
      " |      DataFrame.notna : boolean inverse of isna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : alias of isna\n",
      " |      DataFrame.notna : boolean inverse of isna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      isna : top-level isna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items = iteritems(self)\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Iterator over (column name, Series) pairs.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |  \n",
      " |  iterrows(self)\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      it : generator\n",
      " |          A generator that iterates over the rows of the frame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      iteritems : Iterate over (column name, Series) pairs.\n",
      " |  \n",
      " |  itertuples(self, index=True, name='Pandas')\n",
      " |      Iterate over DataFrame rows as namedtuples, with index value as first\n",
      " |      element of the tuple.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : boolean, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : string, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      With a large number of columns (>255), regular tuples are returned.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      iteritems : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [0.1, 0.2]},\n",
      " |                            index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      a     1   0.1\n",
      " |      b     2   0.2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='a', col1=1, col2=0.10000000000000001)\n",
      " |      Pandas(Index='b', col1=2, col2=0.20000000000000001)\n",
      " |  \n",
      " |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
      " |      Join columns with other DataFrame either on index or on a key\n",
      " |      column. Efficiently Join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series with name field set, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame\n",
      " |      on : name, tuple/list of names, or array-like\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default: 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use other frame's index\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with other frame's index, and sort it\n",
      " |            lexicographically\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with other frame's index, preserving the order\n",
      " |            of the calling's one\n",
      " |      lsuffix : string\n",
      " |          Suffix to use from left frame's overlapping columns\n",
      " |      rsuffix : string\n",
      " |          Suffix to use from right frame's overlapping columns\n",
      " |      sort : boolean, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      on, lsuffix, and rsuffix options are not supported when passing a list\n",
      " |      of DataFrame objects\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                        'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> caller\n",
      " |          A key\n",
      " |      0  A0  K0\n",
      " |      1  A1  K1\n",
      " |      2  A2  K2\n",
      " |      3  A3  K3\n",
      " |      4  A4  K4\n",
      " |      5  A5  K5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |          B key\n",
      " |      0  B0  K0\n",
      " |      1  B1  K1\n",
      " |      2  B2  K2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> caller.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |      \n",
      " |      >>>     A key_caller    B key_other\n",
      " |          0  A0         K0   B0        K0\n",
      " |          1  A1         K1   B1        K1\n",
      " |          2  A2         K2   B2        K2\n",
      " |          3  A3         K3  NaN       NaN\n",
      " |          4  A4         K4  NaN       NaN\n",
      " |          5  A5         K5  NaN       NaN\n",
      " |      \n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both caller and other. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> caller.set_index('key').join(other.set_index('key'))\n",
      " |      \n",
      " |      >>>      A    B\n",
      " |          key\n",
      " |          K0   A0   B0\n",
      " |          K1   A1   B1\n",
      " |          K2   A2   B2\n",
      " |          K3   A3  NaN\n",
      " |          K4   A4  NaN\n",
      " |          K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the on\n",
      " |      parameter. DataFrame.join always uses other's index but we can use any\n",
      " |      column in the caller. This method preserves the original caller's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> caller.join(other.set_index('key'), on='key')\n",
      " |      \n",
      " |      >>>     A key    B\n",
      " |          0  A0  K0   B0\n",
      " |          1  A1  K1   B1\n",
      " |          2  A2  K2   B2\n",
      " |          3  A3  K3  NaN\n",
      " |          4  A4  K4  NaN\n",
      " |          5  A5  K5  NaN\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      joined : DataFrame\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods le\n",
      " |  \n",
      " |  lookup(self, row_labels, col_labels)\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Akin to::\n",
      " |      \n",
      " |          result = []\n",
      " |          for row, col in zip(row_labels, col_labels):\n",
      " |              result.append(df.get_value(row, col))\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      values : ndarray\n",
      " |          The found values\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods lt\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object.\n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\n",
      " |      \"Unpivots\" a DataFrame from wide format to long format, optionally\n",
      " |      leaving identifier variables set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frame : DataFrame\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or string, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      melt\n",
      " |      pivot_table\n",
      " |      DataFrame.pivot\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True`` the memory usage of the\n",
      " |          index the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sizes : Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      pandas.Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64  complex128 object  bool\n",
      " |      0      1      1.0      (1+0j)      1  True\n",
      " |      1      1      1.0      (1+0j)      1  True\n",
      " |      2      1      1.0      (1+0j)      1  True\n",
      " |      3      1      1.0      (1+0j)      1  True\n",
      " |      4      1      1.0      (1+0j)      1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index            80\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index             80\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        160000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5168\n",
      " |  \n",
      " |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
      " |      Merge DataFrame objects by performing a database-style join operation by\n",
      " |      columns or indexes.\n",
      " |      \n",
      " |      If joining columns on columns, the DataFrame indexes *will be\n",
      " |      ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      " |      columns, the index will be passed on.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys\n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : boolean, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels\n",
      " |      right_index : boolean, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index\n",
      " |      sort : boolean, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword)\n",
      " |      suffixes : 2-length sequence (tuple, list, ...)\n",
      " |          Suffix to apply to overlapping column names in the left and right\n",
      " |          side, respectively\n",
      " |      copy : boolean, default True\n",
      " |          If False, do not copy data unnecessarily\n",
      " |      indicator : boolean or string, default False\n",
      " |          If True, adds a column to output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row.\n",
      " |          If string, column with information on source of each row will be added to\n",
      " |          output DataFrame, and column will be named value of string.\n",
      " |          Information column is Categorical-type and takes on a value of \"left_only\"\n",
      " |          for observations whose merge key only appears in 'left' DataFrame,\n",
      " |          \"right_only\" for observations whose merge key only appears in 'right'\n",
      " |          DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      " |      \n",
      " |      validate : string, default None\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> A              >>> B\n",
      " |          lkey value         rkey value\n",
      " |      0   foo  1         0   foo  5\n",
      " |      1   bar  2         1   bar  6\n",
      " |      2   baz  3         2   qux  7\n",
      " |      3   foo  4         3   bar  8\n",
      " |      \n",
      " |      >>> A.merge(B, left_on='lkey', right_on='rkey', how='outer')\n",
      " |         lkey  value_x  rkey  value_y\n",
      " |      0  foo   1        foo   5\n",
      " |      1  foo   4        foo   5\n",
      " |      2  bar   2        bar   6\n",
      " |      3  bar   2        bar   8\n",
      " |      4  baz   3        NaN   NaN\n",
      " |      5  NaN   NaN      qux   7\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      merged : DataFrame\n",
      " |          The output type will the be same as 'left', if it is a subclass\n",
      " |          of DataFrame.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      merge_ordered\n",
      " |      merge_asof\n",
      " |      DataFrame.join\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object.\n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rmod\n",
      " |  \n",
      " |  mode(self, axis=0, numeric_only=False)\n",
      " |      Gets the mode(s) of each element along the axis selected. Adds a row\n",
      " |      for each mode per label, fills in gaps with nan.\n",
      " |      \n",
      " |      Note that there could be multiple values returned for the selected\n",
      " |      axis (when more than one item share the maximum frequency), which is\n",
      " |      the reason why a dataframe is returned. If you want to impute missing\n",
      " |      values with the mode in a dataframe ``df``, you can just do this:\n",
      " |      ``df.fillna(df.mode().iloc[0])``\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row\n",
      " |      numeric_only : boolean, default False\n",
      " |          if True, only apply to numeric columns\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : DataFrame (sorted)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 1, 2, 1, 2, 3]})\n",
      " |      >>> df.mode()\n",
      " |         A\n",
      " |      0  1\n",
      " |      1  2\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rmul\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ne\n",
      " |  \n",
      " |  nlargest(self, n, columns, keep='first')\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - `first` : prioritize the first occurrence(s)\n",
      " |          - `last` : prioritize the last occurrence(s)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 10, 8, 10, -1],\n",
      " |      ...                    'b': list('abdce'),\n",
      " |      ...                    'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      " |      >>> df\n",
      " |          a  b    c\n",
      " |      0   1  a  1.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      3  10  c  3.0\n",
      " |      4  -1  e  4.0\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"a\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'a')\n",
      " |          a  b    c\n",
      " |      1  10  b  2.0\n",
      " |      3  10  c  3.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'a', keep='last')\n",
      " |          a  b    c\n",
      " |      3  10  c  3.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      To order by the largest values in column \"a\" and then \"c\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['a', 'c'])\n",
      " |          a  b    c\n",
      " |      3  10  c  3.0\n",
      " |      1  10  b  2.0\n",
      " |      2   8  d  NaN\n",
      " |      \n",
      " |      Attempting to use ``nlargest`` on non-numeric dtypes will raise a\n",
      " |      ``TypeError``:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'b')\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Column 'b' has dtype object, cannot use method 'nlargest'\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : alias of notna\n",
      " |      DataFrame.isna : boolean inverse of notna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : alias of notna\n",
      " |      DataFrame.isna : boolean inverse of notna\n",
      " |      DataFrame.dropna : omit axes labels with missing values\n",
      " |      notna : top-level notna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n, columns, keep='first')\n",
      " |      Get the rows of a DataFrame sorted by the `n` smallest\n",
      " |      values of `columns`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by\n",
      " |      keep : {'first', 'last'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 10, 8, 11, -1],\n",
      " |      ...                    'b': list('abdce'),\n",
      " |      ...                    'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
      " |      >>> df.nsmallest(3, 'a')\n",
      " |         a  b   c\n",
      " |      4 -1  e   4\n",
      " |      0  1  a   1\n",
      " |      2  8  d NaN\n",
      " |  \n",
      " |  nunique(self, axis=0, dropna=True)\n",
      " |      Return Series with number of distinct observations over requested\n",
      " |      axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      dropna : boolean, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      nunique : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [1, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    1\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None)\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : string or object, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      columns : string or object\n",
      " |          Column to use to make new frame's columns.\n",
      " |      values : string, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |          .. versionchanged :: 0.23.0\n",
      " |             Also accept list of column names.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame. The levels in\n",
      " |      the pivot table will be stored in MultiIndex objects (hierarchical\n",
      " |      indexes) on the index and columns of the result DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with\n",
      " |      margins : boolean, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals)\n",
      " |      dropna : boolean, default True\n",
      " |          Do not include columns whose entries are all NaN\n",
      " |      margins_name : string, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7]})\n",
      " |      >>> df\n",
      " |           A    B      C  D\n",
      " |      0  foo  one  small  1\n",
      " |      1  foo  one  large  2\n",
      " |      2  foo  one  large  2\n",
      " |      3  foo  two  small  3\n",
      " |      4  foo  two  small  3\n",
      " |      5  bar  one  large  4\n",
      " |      6  bar  one  small  5\n",
      " |      7  bar  two  small  6\n",
      " |      8  bar  two  large  7\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                        D   E\n",
      " |                     mean max median min\n",
      " |      A   C\n",
      " |      bar large  5.500000  16   14.5  13\n",
      " |          small  5.500000  15   14.5  14\n",
      " |      foo large  2.000000  10    9.5   9\n",
      " |          small  2.333333  12   11.0   8\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      table : DataFrame\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pivot : pivot without aggregation that can handle\n",
      " |          non-numeric data\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rpow\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis=0, numeric_only=True, interpolation='linear')\n",
      " |      Return values at the given quantile over requested axis, a la\n",
      " |      numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          0 or 'index' for row-wise, 1 or 'columns' for column-wise\n",
      " |      numeric_only : boolean, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |      \n",
      " |          - If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          - If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |                            columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |                             'B': [pd.Timestamp('2010'),\n",
      " |                                   pd.Timestamp('2011')],\n",
      " |                             'C': [pd.Timedelta('1 days'),\n",
      " |                                   pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.core.window.Rolling.quantile\n",
      " |  \n",
      " |  query(self, expr, inplace=False, **kwargs)\n",
      " |      Query the columns of a frame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : string\n",
      " |          The query string to evaluate.  You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      inplace : bool\n",
      " |          Whether the query should modify the data in place or return\n",
      " |          a modified copy\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      q : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`pandas.eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.eval\n",
      " |      DataFrame.eval\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy.random import randn\n",
      " |      >>> from pandas import DataFrame\n",
      " |      >>> df = pd.DataFrame(randn(10, 2), columns=list('ab'))\n",
      " |      >>> df.query('a > b')\n",
      " |      >>> df[df.a > df.b]  # same result as the previous expression\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  1.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[np.nan, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  NaN\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  2.0  NaN\n",
      " |      b  1.0  2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.add\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform DataFrame to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like, optional\n",
      " |          New labels / index to conform the axis specified by 'axis' to.\n",
      " |      index, columns : array-like, optional (should be specified using keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      " |          or number (0, 1).\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...      'http_status': [200,200,404,404,301],\n",
      " |      ...      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...       index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...             'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to backpropagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29     100\n",
      " |      2009-12-30     100\n",
      " |      2009-12-31     100\n",
      " |      2010-01-01     100\n",
      " |      2010-01-02     101\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04     100\n",
      " |      2010-01-05      89\n",
      " |      2010-01-06      88\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)\n",
      " |      Conform input object to new index with optional\n",
      " |      filling logic, placing NA/NaN in locations having no value in the\n",
      " |      previous index. A new object is produced unless the new index is\n",
      " |      equivalent to the current one and copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          Method to use for filling holes in reindexed DataFrame:\n",
      " |      \n",
      " |          * default: don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.reindex_axis(['A', 'B', 'C'], axis=1)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, reindex_like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None)\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper, index, columns : dict-like or function, optional\n",
      " |          dict-like or functions transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename(index=str, columns={\"A\": \"a\", \"C\": \"c\"})\n",
      " |         a  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Using axis-style parameters\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order, axis=0)\n",
      " |      Rearrange index levels using input order.\n",
      " |      May not drop or duplicate levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : int\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values\n",
      " |      DataFrame.where : Replace values based on boolean condition\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$':'new', 'foo':'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the pecularities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
      " |      For DataFrame with multi-level index, return new DataFrame with\n",
      " |      labeling information in the columns under the index names, defaulting\n",
      " |      to 'level_0', 'level_1', etc. if any are None. For a standard index,\n",
      " |      the index name will be used (if set), otherwise a default 'index' or\n",
      " |      'level_0' (if 'index' is already taken) will be used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      resetted : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird',    389.0),\n",
      " |      ...                    ('bird',     24.0),\n",
      " |      ...                    ('mammal',   80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.floordiv\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.mod\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.mul\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provides rolling window calculations.\n",
      " |      \n",
      " |      .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, or offset\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes. This is\n",
      " |          new in 0.19.0\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          this will default to 1.\n",
      " |      center : boolean, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : string, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column on which to calculate\n",
      " |          the rolling window, rather than the index\n",
      " |      closed : string, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      axis : int or string, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  2.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width).\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.random([3, 3]),\n",
      " |      ...     columns=['A', 'B', 'C'], index=['first', 'second', 'third'])\n",
      " |      >>> df\n",
      " |                     A         B         C\n",
      " |      first   0.028208  0.992815  0.173891\n",
      " |      second  0.038683  0.645646  0.577595\n",
      " |      third   0.877076  0.149370  0.491027\n",
      " |      >>> df.round(2)\n",
      " |                 A     B     C\n",
      " |      first   0.03  0.99  0.17\n",
      " |      second  0.04  0.65  0.58\n",
      " |      third   0.88  0.15  0.49\n",
      " |      >>> df.round({'A': 1, 'C': 2})\n",
      " |                A         B     C\n",
      " |      first   0.0  0.992815  0.17\n",
      " |      second  0.0  0.645646  0.58\n",
      " |      third   0.9  0.149370  0.49\n",
      " |      >>> decimals = pd.Series([1, 0, 2], index=['A', 'B', 'C'])\n",
      " |      >>> df.round(decimals)\n",
      " |                A  B     C\n",
      " |      first   0.0  1  0.17\n",
      " |      second  0.0  1  0.58\n",
      " |      third   0.9  0  0.49\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around\n",
      " |      Series.round\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pow\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([2, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  2.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[3, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  3.0\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.sub(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  1.0  -3.0\n",
      " |      b  1.0  -2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  -1.0  NaN\n",
      " |      e  NaN  -2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.sub\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.truediv\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None)\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns. By default yields a new object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : column label or list of column labels / arrays\n",
      " |      drop : boolean, default True\n",
      " |          Delete columns to be used as the new index\n",
      " |      append : boolean, default False\n",
      " |          Whether to append columns to existing index\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      verify_integrity : boolean, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale':[55, 40, 84, 31]})\n",
      " |         month  sale  year\n",
      " |      0  1      55    2012\n",
      " |      1  4      40    2014\n",
      " |      2  7      84    2013\n",
      " |      3  10     31    2014\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             sale  year\n",
      " |      month\n",
      " |      1      55    2012\n",
      " |      4      40    2014\n",
      " |      7      84    2013\n",
      " |      10     31    2014\n",
      " |      \n",
      " |      Create a multi-index using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a multi-index using a set of values and a column:\n",
      " |      \n",
      " |      >>> df.set_index([[1, 2, 3, 4], 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dataframe : DataFrame\n",
      " |  \n",
      " |  set_value(self, index, col, value, takeable=False)\n",
      " |      Put single value at passed column and index\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use .at[] or .iat[] accessors instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      value : scalar value\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |          If label pair is contained, will be reference to calling DataFrame,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : DataFrame\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, by=None)\n",
      " |      Sort object by labels (along an axis)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : index, columns to direct sorting\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          if not None, sort on values in specified index level(s)\n",
      " |      ascending : boolean, default True\n",
      " |          Sort ascending vs. descending\n",
      " |      inplace : bool, default False\n",
      " |          if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end.\n",
      " |           Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          if true and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : DataFrame\n",
      " |  \n",
      " |  sort_values(self, by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort by the values along either axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : str or list of str\n",
      " |          Name or list of names to sort by.\n",
      " |      \n",
      " |          - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |            levels and/or column labels\n",
      " |          - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |            levels and/or index labels\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |             Allow specifying index or column level names.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           if True, perform operation in-place\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also ndarray.np.sort for more\n",
      " |           information.  `mergesort` is the only stable algorithm. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           `first` puts NaNs at the beginning, `last` puts NaNs at the end\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_obj : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2' : [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          col1 col2 col3\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      2   B    9    9\n",
      " |      3   NaN  8    4\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |          col1 col2 col3\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      2   B    9    9\n",
      " |      5   C    4    3\n",
      " |      4   D    7    2\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |          col1 col2 col3\n",
      " |      1   A    1    1\n",
      " |      0   A    2    0\n",
      " |      2   B    9    9\n",
      " |      5   C    4    3\n",
      " |      4   D    7    2\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |          col1 col2 col3\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      2   B    9    9\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |      3   NaN  8    4\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |          col1 col2 col3\n",
      " |      3   NaN  8    4\n",
      " |      4   D    7    2\n",
      " |      5   C    4    3\n",
      " |      2   B    9    9\n",
      " |      0   A    2    0\n",
      " |      1   A    1    1\n",
      " |  \n",
      " |  sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)\n",
      " |      Sort multilevel index by chosen axis and primary level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Use :meth:`DataFrame.sort_index`\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      ascending : boolean, default True\n",
      " |      inplace : boolean, default False\n",
      " |          Sort the DataFrame without creating a new instance\n",
      " |      sort_remaining : boolean, default True\n",
      " |          Sort by the other levels too.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index(level=...)\n",
      " |  \n",
      " |  stack(self, level=-1, dropna=True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      The new index levels are sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being re-organised from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> a = pd.DataFrame([2, 1, 1, np.nan], index=['a', 'b', 'c', 'd'],\n",
      " |      ...                  columns=['one'])\n",
      " |      >>> a\n",
      " |         one\n",
      " |      a  2.0\n",
      " |      b  1.0\n",
      " |      c  1.0\n",
      " |      d  NaN\n",
      " |      >>> b = pd.DataFrame(dict(one=[1, np.nan, 1, np.nan],\n",
      " |      ...                       two=[3, 2, np.nan, 2]),\n",
      " |      ...                  index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |         one  two\n",
      " |      a  1.0  3.0\n",
      " |      b  NaN  2.0\n",
      " |      d  1.0  NaN\n",
      " |      e  NaN  2.0\n",
      " |      >>> a.sub(b, fill_value=0)\n",
      " |         one  two\n",
      " |      a  1.0  -3.0\n",
      " |      b  1.0  -2.0\n",
      " |      c  1.0  NaN\n",
      " |      d  -1.0  NaN\n",
      " |      e  NaN  -2.0\n",
      " |      \n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rsub\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded :: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, axis=0)\n",
      " |      Swap levels i and j in a MultiIndex on a particular axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : type of caller (new object)\n",
      " |      \n",
      " |      .. versionchanged:: 0.18.1\n",
      " |      \n",
      " |         The indexes ``i`` and ``j`` are now optional, and default to\n",
      " |         the two innermost levels of the index.\n",
      " |  \n",
      " |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=None, date_format=None, doublequote=True, escapechar=None, decimal='.')\n",
      " |      Write DataFrame to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      sep : character, default ','\n",
      " |          Field delimiter for the output file.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.  If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'\n",
      " |      encoding : string, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      compression : string, optional\n",
      " |          A string representing the compression to use in the output file.\n",
      " |          Allowed values are 'gzip', 'bz2', 'zip', 'xz'. This input is only\n",
      " |          used when the first argument is a filename.\n",
      " |      line_terminator : string, default ``'\\n'``\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file\n",
      " |      quoting : optional constant from csv module\n",
      " |          defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric\n",
      " |      quotechar : string (length 1), default '\\\"'\n",
      " |          character used to quote fields\n",
      " |      doublequote : boolean, default True\n",
      " |          Control quoting of `quotechar` inside a field\n",
      " |      escapechar : string (length 1), default None\n",
      " |          character used to escape `sep` and `quotechar` when appropriate\n",
      " |      chunksize : int or None\n",
      " |          rows to write at a time\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          .. deprecated:: 0.21.0\n",
      " |             This argument will be removed and will always write each row\n",
      " |             of the multi-index as a separate row in the CSV file.\n",
      " |      \n",
      " |          Write MultiIndex columns as a list of tuples (if True) or in\n",
      " |          the new, expanded format, where each MultiIndex column is a row\n",
      " |          in the CSV (if False).\n",
      " |      date_format : string, default None\n",
      " |          Format string for datetime objects\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data\n",
      " |  \n",
      " |  to_dict(self, orient='dict', into=<class 'dict'>)\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : collections.Mapping like {column -> {index -> value}}\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: create a DataFrame from a dictionary\n",
      " |      DataFrame.to_json: convert a DataFrame to JSON format\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      a     1   0.50\n",
      " |      b     2   0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'a': 1, 'b': 2}, 'col2': {'a': 0.5, 'b': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': a    1\n",
      " |               b    2\n",
      " |               Name: col1, dtype: int64,\n",
      " |       'col2': a    0.50\n",
      " |               b    0.75\n",
      " |               Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['a', 'b'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1.0, 0.5], [2.0, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1.0, 'col2': 0.5}, {'col1': 2.0, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'a': {'col1': 1.0, 'col2': 0.5}, 'b': {'col1': 2.0, 'col2': 0.75}}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('a', 1), ('b', 2)])),\n",
      " |                   ('col2', OrderedDict([('a', 0.5), ('b', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1.0, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2.0, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)\n",
      " |      Write DataFrame to an excel sheet\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      freeze_panes : tuple of integer (length 2), default None\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = pd.ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |      \n",
      " |      For compatibility with to_csv, to_excel serializes lists and dicts to\n",
      " |      strings before writing.\n",
      " |  \n",
      " |  to_feather(self, fname)\n",
      " |      write out the binary feather-format for DataFrames\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          string file path\n",
      " |  \n",
      " |  to_gbq(self, destination_table, project_id, chunksize=None, verbose=None, reauth=False, if_exists='fail', private_key=None, auth_local_webserver=False, table_schema=None)\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      Authentication to the Google BigQuery service is via OAuth 2.0.\n",
      " |      \n",
      " |      - If ``private_key`` is provided, the library loads the JSON service\n",
      " |        account credentials and uses those to authenticate.\n",
      " |      \n",
      " |      - If no ``private_key`` is provided, the library tries `application\n",
      " |        default credentials`_.\n",
      " |      \n",
      " |        .. _application default credentials:\n",
      " |            https://cloud.google.com/docs/authentication/production#providing_credentials_to_your_application\n",
      " |      \n",
      " |      - If application default credentials are not found or cannot be used\n",
      " |        with BigQuery, the library authenticates with user account\n",
      " |        credentials. In this case, you will be asked to grant permissions\n",
      " |        for product name 'pandas GBQ'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form 'dataset.tablename'.\n",
      " |      project_id : str\n",
      " |          Google BigQuery Account project ID.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to reauthenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists, do nothing.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      private_key : str, optional\n",
      " |          Service account private key in JSON format. Can be file path\n",
      " |          or string contents. This is useful for remote server\n",
      " |          authentication (eg. Jupyter/IPython notebook on remote host).\n",
      " |      auth_local_webserver : bool, default False\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              http://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      verbose : boolean, deprecated\n",
      " |          *Deprecated in Pandas-GBQ 0.4.0.* Use the `logging module\n",
      " |          to adjust verbosity instead\n",
      " |          <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      pandas.read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False, notebook=False, decimal='.', border=None, table_id=None)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      `to_html`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default True\n",
      " |          Make the row labels bold in the output\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table\n",
      " |      escape : boolean, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to show before truncating. If None, show\n",
      " |          all.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.html.border``.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          whether to print column labels, default True\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters, default no wrap\n",
      " |      table_id : str, optional\n",
      " |          id for the <table> element create by to_html\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_panel(self)\n",
      " |      Transform long (stacked) format (DataFrame) into wide (3D, Panel)\n",
      " |      format.\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |      \n",
      " |      Currently the index of the DataFrame must be a 2-level MultiIndex. This\n",
      " |      may be generalized later\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      panel : Panel\n",
      " |  \n",
      " |  to_parquet(self, fname, engine='auto', compression='snappy', **kwargs)\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          String file path.\n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip', compression='gzip')\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |  \n",
      " |  to_period(self, freq=None, axis=0, copy=True)\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If False then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : TimeSeries with PeriodIndex\n",
      " |  \n",
      " |  to_records(self, index=True, convert_datetime64=None)\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be put in the 'index' field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : boolean, default True\n",
      " |          Include index in resulting record array, stored in 'index' field.\n",
      " |      convert_datetime64 : boolean, default None\n",
      " |          .. deprecated:: 0.23.0\n",
      " |      \n",
      " |          Whether to convert the index to datetime.datetime if it is a\n",
      " |          DatetimeIndex.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : numpy.recarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      By default, timestamps are converted to `datetime.datetime`:\n",
      " |      \n",
      " |      >>> df.index = pd.date_range('2018-01-01 09:00', periods=2, freq='min')\n",
      " |      >>> df\n",
      " |                           A     B\n",
      " |      2018-01-01 09:00:00  1  0.50\n",
      " |      2018-01-01 09:01:00  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([(datetime.datetime(2018, 1, 1, 9, 0), 1, 0.5 ),\n",
      " |                 (datetime.datetime(2018, 1, 1, 9, 1), 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The timestamp conversion can be disabled so NumPy's datetime64\n",
      " |      data type is used instead:\n",
      " |      \n",
      " |      >>> df.to_records(convert_datetime64=False)\n",
      " |      rec.array([('2018-01-01T09:00:00.000000000', 1, 0.5 ),\n",
      " |                 ('2018-01-01T09:01:00.000000000', 2, 0.75)],\n",
      " |                dtype=[('index', '<M8[ns]'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_sparse(self, fill_value=None, kind='block')\n",
      " |      Convert to SparseDataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fill_value : float, default NaN\n",
      " |      kind : {'block', 'integer'}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : SparseDataFrame\n",
      " |  \n",
      " |  to_stata(self, fname, convert_dates=None, write_index=True, encoding='latin-1', byteorder=None, time_stamp=None, data_label=None, variable_labels=None, version=114, convert_strl=None)\n",
      " |      Export Stata binary dta files.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : path (string), buffer or path object\n",
      " |          string, path object (pathlib.Path or py._path.local.LocalPath) or\n",
      " |          object implementing a binary write() functions. If using a buffer\n",
      " |          then the buffer will not be automatically closed after the file\n",
      " |          data has been written.\n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      encoding : str\n",
      " |          Default is latin-1. Unicode is not supported.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      version : {114, 117}\n",
      " |          Version to use in the output dta file.  Version 114 can be used\n",
      " |          read by Stata 10 and later.  Version 117 can be read by Stata 13\n",
      " |          or later. Version 114 limits string variables to 244 characters or\n",
      " |          fewer while 117 allows strings with lengths up to 2,000,000\n",
      " |          characters.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_stata : Import Stata data files\n",
      " |      pandas.io.stata.StataWriter : low-level writer for Stata data files\n",
      " |      pandas.io.stata.StataWriter117 : low-level writer for version 117 files\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data.to_stata('./data_file.dta')\n",
      " |      \n",
      " |      Or with dates\n",
      " |      \n",
      " |      >>> data.to_stata('./date_data_file.dta', {2 : 'tw'})\n",
      " |      \n",
      " |      Alternatively you can create an instance of the StataWriter class\n",
      " |      \n",
      " |      >>> writer = StataWriter('./data_file.dta', data)\n",
      " |      >>> writer.write_file()\n",
      " |      \n",
      " |      With dates:\n",
      " |      \n",
      " |      >>> writer = StataWriter('./date_data_file.dta', data, {2 : 'tw'})\n",
      " |      >>> writer.write_file()\n",
      " |  \n",
      " |  to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None, show_dimensions=False)\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters, default no wrap\n",
      " |      table_id : str, optional\n",
      " |          id for the <table> element create by to_html\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', axis=0, copy=True)\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If false then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, *args, **kwargs)\n",
      " |      Call function producing a like-indexed NDFrame\n",
      " |      and return a NDFrame with the transformed values\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable, string, dictionary, or list of string/callables\n",
      " |          To apply to column\n",
      " |      \n",
      " |          Accepted Combinations are:\n",
      " |      \n",
      " |          - string function name\n",
      " |          - function\n",
      " |          - list of functions\n",
      " |          - dict of column names -> functions (or list of functions)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      transformed : NDFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],\n",
      " |      ...                   index=pd.date_range('1/1/2000', periods=10))\n",
      " |      df.iloc[3:7] = np.nan\n",
      " |      \n",
      " |      >>> df.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                         A         B         C\n",
      " |      2000-01-01  0.579457  1.236184  0.123424\n",
      " |      2000-01-02  0.370357 -0.605875 -1.231325\n",
      " |      2000-01-03  1.455756 -0.277446  0.288967\n",
      " |      2000-01-04       NaN       NaN       NaN\n",
      " |      2000-01-05       NaN       NaN       NaN\n",
      " |      2000-01-06       NaN       NaN       NaN\n",
      " |      2000-01-07       NaN       NaN       NaN\n",
      " |      2000-01-08 -0.498658  1.274522  1.642524\n",
      " |      2000-01-09 -0.540524 -1.012676 -0.828968\n",
      " |      2000-01-10 -1.366388 -0.614710  0.005378\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.NDFrame.aggregate\n",
      " |      pandas.NDFrame.apply\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          If True, the underlying data is copied. Otherwise (default), no\n",
      " |          copy is made if possible.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5     8\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      None\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.rtruediv\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels, returning\n",
      " |      a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels. If the index is not a MultiIndex,\n",
      " |      the output will be a Series (the analogue of stack when the columns are\n",
      " |      not a MultiIndex).\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name\n",
      " |      fill_value : replace NaN with this value if the unstack produces\n",
      " |          missing values\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame or Series\n",
      " |  \n",
      " |  update(self, other, join='left', overwrite=True, filter_func=None, raise_conflict=False)\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> boolean 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      raise_conflict : bool, default False\n",
      " |          If True, will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When `raise_conflict` is True and there's overlapping non-NA data.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-columns(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, it's name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_csv(path, header=0, sep=',', index_col=0, parse_dates=True, encoding=None, tupleize_cols=None, infer_datetime_format=False) from builtins.type\n",
      " |      Read CSV file.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use :func:`pandas.read_csv` instead.\n",
      " |      \n",
      " |      It is preferable to use the more powerful :func:`pandas.read_csv`\n",
      " |      for most general purposes, but ``from_csv`` makes for an easy\n",
      " |      roundtrip to and from a file (the exact counterpart of\n",
      " |      ``to_csv``), especially with a DataFrame of time series data.\n",
      " |      \n",
      " |      This method only differs from the preferred :func:`pandas.read_csv`\n",
      " |      in some defaults:\n",
      " |      \n",
      " |      - `index_col` is ``0`` instead of ``None`` (take first column as index\n",
      " |        by default)\n",
      " |      - `parse_dates` is ``True`` instead of ``False`` (try parsing the index\n",
      " |        as datetime by default)\n",
      " |      \n",
      " |      So a ``pd.DataFrame.from_csv(path)`` can be replaced by\n",
      " |      ``pd.read_csv(path, index_col=0, parse_dates=True)``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      header : int, default 0\n",
      " |          Row to use as header (skip prior rows)\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          write multi_index columns as a list of tuples (if True)\n",
      " |          or new (expanded format) if False)\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.read_csv\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  from_dict(data, orient='columns', dtype=None, columns=None) from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'``.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from ndarray (structured\n",
      " |          dtype), list of tuples, dict, or DataFrame\n",
      " |      DataFrame : DataFrame object creation using constructor\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |  \n",
      " |  from_items(items, columns=None, orient='columns') from builtins.type\n",
      " |      Construct a dataframe from a list of tuples\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |        `from_items` is deprecated and will be removed in a future version.\n",
      " |        Use :meth:`DataFrame.from_dict(dict(items)) <DataFrame.from_dict>`\n",
      " |        instead.\n",
      " |        :meth:`DataFrame.from_dict(OrderedDict(items)) <DataFrame.from_dict>`\n",
      " |        may be used to preserve the key order.\n",
      " |      \n",
      " |      Convert (key, value) pairs to DataFrame. The keys will be the axis\n",
      " |      index (usually the columns, but depends on the specified\n",
      " |      orientation). The values should be arrays or Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : sequence of (key, value) pairs\n",
      " |          Values should be arrays or Series.\n",
      " |      columns : sequence of column labels, optional\n",
      " |          Must be passed if orient='index'.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the\n",
      " |          input correspond to column labels, pass 'columns'\n",
      " |          (default). Otherwise if the keys correspond to the index,\n",
      " |          pass 'index'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n",
      " |      index : string, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns)\n",
      " |      coerce_float : boolean, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  T\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default False\n",
      " |          If True, the underlying data is copied. Otherwise (default), no\n",
      " |          copy is made if possible.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5     8\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['coll', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Property returning a Styler object containing methods for\n",
      " |      building a styled HTML representation fo the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.io.formats.style.Styler\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.FramePlotMethods'>\n",
      " |      DataFrame plotting accessor and method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.plot.line()\n",
      " |      >>> df.plot.scatter('x', 'y')\n",
      " |      >>> df.plot.hexbin()\n",
      " |      \n",
      " |      These plotting methods can also be accessed by calling the accessor as a\n",
      " |      method with the ``kind`` argument:\n",
      " |      ``df.plot(kind='line')`` is equivalent to ``df.plot.line()``\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self, deep=True)\n",
      " |  \n",
      " |  __deepcopy__(self, memo=None)\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over infor axis\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self, decimals=0)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : calculate the absolute value element-wise.\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4],  'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  as_blocks(self, copy=True)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |          Use :meth:`DataFrame.values` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32. By numpy.find_common_type convention, mixing int64 and uint64\n",
      " |      will result in a flot64 dtype.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None)\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      fill_value: scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      The last row without any NaN is taken (or the last row without\n",
      " |      NaN considering only the subset of columns in the case of a DataFrame)\n",
      " |      \n",
      " |      .. versionadded:: 0.19.0 For DataFrame\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array of dates\n",
      " |      subset : string or list of strings, default None\n",
      " |         if not None use these columns for NaN propagation\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted\n",
      " |      Raises if this is not the case\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      where is scalar\n",
      " |      \n",
      " |        - value or NaN if input is Series\n",
      " |        - Series if input is DataFrame\n",
      " |      \n",
      " |      where is Index: same shape object as input\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, errors='raise', **kwargs)\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True.\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'.\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      raise_on_error : raise on invalid input\n",
      " |          .. deprecated:: 0.20.0\n",
      " |             Use ``errors`` instead\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> ser.astype('category', ordered=True, categories=[2, 1])\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1,2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='bfill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, axis=None, inplace=False, *args, **kwargs)\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip_lower : Clip values below specified threshold(s).\n",
      " |      clip_upper : Clip values above specified threshold(s).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  clip_lower(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of the input with values below a threshold truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : numeric or array-like\n",
      " |          Minimum value allowed. All values below threshold will be set to\n",
      " |          this value.\n",
      " |      \n",
      " |          * float : every value is compared to `threshold`.\n",
      " |          * array-like : The shape of `threshold` should match the object\n",
      " |            it's compared to. When `self` is a Series, `threshold` should be\n",
      " |            the length. When `self` is a DataFrame, `threshold` should 2-D\n",
      " |            and the same shape as `self` for ``axis=None``, or 1-D and the\n",
      " |            same length as the axis being compared.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Align `self` with `threshold` along the given axis.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Return copy of input with values below and above\n",
      " |          thresholds truncated.\n",
      " |      Series.clip_upper : Return copy of input with values above\n",
      " |          threshold truncated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Series single threshold clipping:\n",
      " |      \n",
      " |      >>> s = pd.Series([5, 6, 7, 8, 9])\n",
      " |      >>> s.clip_lower(8)\n",
      " |      0    8\n",
      " |      1    8\n",
      " |      2    8\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Series clipping element-wise using an array of thresholds. `threshold`\n",
      " |      should be the same length as the Series.\n",
      " |      \n",
      " |      >>> elemwise_thresholds = [4, 8, 7, 2, 5]\n",
      " |      >>> s.clip_lower(elemwise_thresholds)\n",
      " |      0    5\n",
      " |      1    8\n",
      " |      2    7\n",
      " |      3    8\n",
      " |      4    9\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      DataFrames can be compared to a scalar.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 3, 5], \"B\": [2, 4, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(3)\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      Or to an array of values. By default, `threshold` should be the same\n",
      " |      shape as the DataFrame.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([[3, 4], [2, 2], [6, 2]]))\n",
      " |         A  B\n",
      " |      0  3  4\n",
      " |      1  3  4\n",
      " |      2  6  6\n",
      " |      \n",
      " |      Control how `threshold` is broadcast with `axis`. In this case\n",
      " |      `threshold` should be the same length as the axis specified by\n",
      " |      `axis`.\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([3, 3, 5]), axis='index')\n",
      " |         A  B\n",
      " |      0  3  3\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      \n",
      " |      >>> df.clip_lower(np.array([4, 5]), axis='columns')\n",
      " |         A  B\n",
      " |      0  4  5\n",
      " |      1  4  5\n",
      " |      2  5  6\n",
      " |  \n",
      " |  clip_upper(self, threshold, axis=None, inplace=False)\n",
      " |      Return copy of input with values above given value(s) truncated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      threshold : float or array_like\n",
      " |      axis : int or string axis name, optional\n",
      " |          Align object with threshold along the given axis.\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray).\n",
      " |      \n",
      " |      .. deprecated:: 0.20.0\n",
      " |          Consolidate will be an internal implementation only.\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns.\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : boolean, default True\n",
      " |          If True, convert to date where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      convert_numeric : boolean, default False\n",
      " |          If True, attempt to coerce to numbers (including strings), with\n",
      " |          unconvertible values becoming NaN.\n",
      " |      convert_timedeltas : boolean, default True\n",
      " |          If True, convert to timedelta where possible. If 'coerce', force\n",
      " |          conversion, with unconvertible values becoming NaT.\n",
      " |      copy : boolean, default True\n",
      " |          If True, return a copy even if no copy is necessary (e.g. no\n",
      " |          conversion was done). Note: This is meant for internal use, and\n",
      " |          should not be confused with inplace.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Return a fixed frequency timedelta index,\n",
      " |          with day as the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series, DataFrame or Panel\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self, percentiles=None, include=None, exclude=None)\n",
      " |      Generates descriptive statistics that summarize the central tendency,\n",
      " |      dispersion and shape of a dataset's distribution, excluding\n",
      " |      ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary:  Series/DataFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({ 'object': ['a', 'b', 'c'],\n",
      " |      ...                     'numeric': [1, 2, 3],\n",
      " |      ...                     'categorical': pd.Categorical(['d','e','f'])\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |              categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count\n",
      " |      DataFrame.max\n",
      " |      DataFrame.min\n",
      " |      DataFrame.mean\n",
      " |      DataFrame.std\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Subset rows or columns of dataframe according to labels in\n",
      " |      the specified index.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or string axis name\n",
      " |          The axis to filter on.  By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |      one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |      one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |      one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return counts of unique dtypes in this object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dtypes : Return the dtypes in this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_dtype_counts()\n",
      " |      float64    1\n",
      " |      int64      1\n",
      " |      object     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return counts of unique ftypes in this object.\n",
      " |      \n",
      " |      .. deprecated:: 0.23.0\n",
      " |      \n",
      " |      This is useful for SparseDataFrame or for DataFrames containing\n",
      " |      sparse arrays.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dtype : Series\n",
      " |          Series with the count of columns with each type and\n",
      " |          sparsity (dense/sparse)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ftypes : Return ftypes (indication of sparse/dense and dtype) in\n",
      " |          this object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = [['a', 1, 1.0], ['b', 2, 2.0], ['c', 3, 3.0]]\n",
      " |      >>> df = pd.DataFrame(a, columns=['str', 'int', 'float'])\n",
      " |      >>> df\n",
      " |        str  int  float\n",
      " |      0   a    1    1.0\n",
      " |      1   b    2    2.0\n",
      " |      2   c    3    3.0\n",
      " |      \n",
      " |      >>> df.get_ftype_counts()\n",
      " |      float64:dense    1\n",
      " |      int64:dense      1\n",
      " |      object:dense     1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      Return an ndarray after converting sparse values to dense.\n",
      " |      \n",
      " |      This is the same as ``.values`` for non-sparse data. For sparse\n",
      " |      data contained in a `pandas.SparseArray`, the data are first\n",
      " |      converted to a dense representation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Numpy representation of DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      values : Numpy representation of DataFrame.\n",
      " |      pandas.SparseArray : Container for sparse data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2], 'b': [True, False],\n",
      " |      ...                    'c': [1.0, 2.0]})\n",
      " |      >>> df\n",
      " |         a      b    c\n",
      " |      0  1   True  1.0\n",
      " |      1  2  False  2.0\n",
      " |      \n",
      " |      >>> df.get_values()\n",
      " |      array([[1, True, 1.0], [2, False, 2.0]], dtype=object)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": pd.SparseArray([1, None, None]),\n",
      " |      ...                    \"c\": [1.0, 2.0, 3.0]})\n",
      " |      >>> df\n",
      " |           a    c\n",
      " |      0  1.0  1.0\n",
      " |      1  NaN  2.0\n",
      " |      2  NaN  3.0\n",
      " |      \n",
      " |      >>> df.get_values()\n",
      " |      array([[ 1.,  1.],\n",
      " |             [nan,  2.],\n",
      " |             [nan,  3.]])\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False, **kwargs)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted a (single) key.\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group.  groupby preserves the order of rows within each group.\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      observed : boolean, default False\n",
      " |          This only applies if any of the groupers are Categoricals\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      DataFrame results\n",
      " |      \n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      DataFrame with hierarchical index\n",
      " |      \n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      obj_head : type of caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |  \n",
      " |  infer_objects(self)\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.to_datetime : Convert argument to datetime.\n",
      " |      pandas.to_timedelta : Convert argument to timedelta.\n",
      " |      pandas.to_numeric : Convert argument to numeric typeR\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrames/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline', 'piecewise_polynomial',\n",
      " |                'from_derivatives', 'pchip', 'akima'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |            default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            ``scipy.interpolate.interp1d``. Both 'polynomial' and 'spline'\n",
      " |            require that you also specify an `order` (int),\n",
      " |            e.g. df.interpolate(method='polynomial', order=4).\n",
      " |            These use the actual numerical values of the index.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |            are all wrappers around the scipy interpolation methods of\n",
      " |            similar names. These use the actual numerical values of the\n",
      " |            index. For more information on their behavior, see the\n",
      " |            `scipy documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |            and `tutorial documentation\n",
      " |            <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__\n",
      " |          * 'from_derivatives' refers to BPoly.from_derivatives which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |      \n",
      " |             Added support for the 'akima' method\n",
      " |             Added interpolate method 'from_derivatives' which replaces\n",
      " |             'piecewise_polynomial' in scipy 0.18; backwards-compatible with\n",
      " |             scipy < 0.18\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |      limit_area : {'inside', 'outside'}, default None\n",
      " |          * None: (default) no fill restriction\n",
      " |          * 'inside' Only fill NaNs surrounded by valid values (interpolate).\n",
      " |          * 'outside' Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      kwargs : keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Filling in NaNs\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more)\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame and major_axis for\n",
      " |      Panel.\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset\n",
      " |      at_time : Select values at a particular time of the day\n",
      " |      between_time : Select values between particular times of the day\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Notes\n",
      " |      --------\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty NDFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      scalar : type of index\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is False and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where`\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          function to apply to the NDFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the NDFrame.\n",
      " |      args : iterable, optional\n",
      " |          positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          a dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.apply\n",
      " |      pandas.DataFrame.applymap\n",
      " |      pandas.Series.map\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Column label to be popped\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      popped : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self, axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          index to direct ranking\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. Valid only for DataFrame or\n",
      " |          Panel objects\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : same type as caller\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None, tolerance=None)\n",
      " |      Return an object with matching indices to myself.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between labels of the other object and this\n",
      " |          object for inexact matches. Can be list-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter the name of the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set as the axis name attribute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis.\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : boolean, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Prior to version 0.21.0, ``rename_axis`` could also be used to change\n",
      " |      the axis *labels* by passing a mapping or scalar. This behavior is\n",
      " |      deprecated and will be removed in a future version. Use ``rename``\n",
      " |      instead.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.Series.rename : Alter Series index labels or name\n",
      " |      pandas.DataFrame.rename : Alter DataFrame index labels or name\n",
      " |      pandas.Index.rename : Set new names on index\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.rename_axis(\"foo\")\n",
      " |      foo\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename_axis(\"foo\")\n",
      " |           A  B\n",
      " |      foo\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |      \n",
      " |      >>> df.rename_axis(\"bar\", axis=\"columns\")\n",
      " |      bar  A  B\n",
      " |      0    1  4\n",
      " |      1    2  5\n",
      " |      2    3  6\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)\n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series.  Object must have a datetime-like index (DatetimeIndex,\n",
      " |      PeriodIndex, or TimedeltaIndex), or pass datetime-like values\n",
      " |      to the on or level keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      axis : int, optional, default 0\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |          For PeriodIndex only, controls whether to use the start or end of\n",
      " |          `rule`\n",
      " |      kind: {'timestamp', 'period'}, optional\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          ``DateTimeIndex`` or 'period' to convert it to a ``PeriodIndex``.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |      on : string, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      level : string or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling.  Level must be datetime-like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5] #select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like)+5\n",
      " |      \n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |                                                      freq='A',\n",
      " |                                                      periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      \n",
      " |      Resample by month using 'start' `convention`. Values are assigned to\n",
      " |      the first month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='start').asfreq().head()\n",
      " |      2012-01    1.0\n",
      " |      2012-02    NaN\n",
      " |      2012-03    NaN\n",
      " |      2012-04    NaN\n",
      " |      2012-05    NaN\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      Resample by month using 'end' `convention`. Values are assigned to\n",
      " |      the last month of the period.\n",
      " |      \n",
      " |      >>> s.resample('M', convention='end').asfreq()\n",
      " |      2012-12    1.0\n",
      " |      2013-01    NaN\n",
      " |      2013-02    NaN\n",
      " |      2013-03    NaN\n",
      " |      2013-04    NaN\n",
      " |      2013-05    NaN\n",
      " |      2013-06    NaN\n",
      " |      2013-07    NaN\n",
      " |      2013-08    NaN\n",
      " |      2013-09    NaN\n",
      " |      2013-10    NaN\n",
      " |      2013-11    NaN\n",
      " |      2013-12    2.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword ``on`` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data=9*[range(4)], columns=['a', 'b', 'c', 'd'])\n",
      " |      >>> df['time'] = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> df.resample('3T', on='time').sum()\n",
      " |                           a  b  c  d\n",
      " |      time\n",
      " |      2000-01-01 00:00:00  0  3  6  9\n",
      " |      2000-01-01 00:03:00  0  3  6  9\n",
      " |      2000-01-01 00:06:00  0  3  6  9\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword ``level`` can be used to\n",
      " |      specify on level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> time = pd.date_range('1/1/2000', periods=5, freq='T')\n",
      " |      >>> df2 = pd.DataFrame(data=10*[range(4)],\n",
      " |                             columns=['a', 'b', 'c', 'd'],\n",
      " |                             index=pd.MultiIndex.from_product([time, [1, 2]])\n",
      " |                             )\n",
      " |      >>> df2.resample('3T', level=0).sum()\n",
      " |                           a  b   c   d\n",
      " |      2000-01-01 00:00:00  0  6  12  18\n",
      " |      2000-01-01 00:03:00  0  4   8  12\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |  \n",
      " |  sample(self, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : boolean, optional\n",
      " |          Sample with or without replacement. Default = False.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          inf and -inf values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : int or string, optional\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames, 1 for Panels).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A new object of same type as caller.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an example ``Series`` and ``DataFrame``:\n",
      " |      \n",
      " |      >>> s = pd.Series(np.random.randn(50))\n",
      " |      >>> s.head()\n",
      " |      0   -0.038497\n",
      " |      1    1.820773\n",
      " |      2   -0.972766\n",
      " |      3   -1.598270\n",
      " |      4   -1.095526\n",
      " |      dtype: float64\n",
      " |      >>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n",
      " |      >>> df.head()\n",
      " |                A         B         C         D\n",
      " |      0  0.016443 -2.318952 -0.566372 -1.028078\n",
      " |      1 -1.051921  0.438836  0.658280 -0.175797\n",
      " |      2 -1.243569 -0.364626 -0.215065  0.057736\n",
      " |      3  1.768216  0.404512 -0.385604 -1.457834\n",
      " |      4  1.072446 -1.137172  0.314194 -0.046661\n",
      " |      \n",
      " |      Next extract a random sample from both of these objects...\n",
      " |      \n",
      " |      3 random elements from the ``Series``:\n",
      " |      \n",
      " |      >>> s.sample(n=3)\n",
      " |      27   -0.994689\n",
      " |      55   -1.049016\n",
      " |      67   -0.224565\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      And a random 10% of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.1, replace=True)\n",
      " |                 A         B         C         D\n",
      " |      35  1.981780  0.142106  1.817165 -0.290805\n",
      " |      49 -1.336199 -0.448634 -0.789640  0.217116\n",
      " |      40  0.823173 -0.078816  1.009536  1.015108\n",
      " |      15  1.421154 -0.055301 -1.922594 -0.019696\n",
      " |      6  -0.148339  0.832938  1.787600 -1.383767\n",
      " |      \n",
      " |      You can use `random state` for reproducibility:\n",
      " |      \n",
      " |      >>> df.sample(random_state=1)\n",
      " |      A         B         C         D\n",
      " |      37 -2.027662  0.103611  0.237496 -0.165867\n",
      " |      43 -0.259323 -0.583426  1.516140 -0.479118\n",
      " |      12 -1.686325 -0.579510  0.985195 -0.460286\n",
      " |      8   1.167946  0.429082  1.215742 -1.636041\n",
      " |      9   1.197475 -0.864188  1.554031 -1.505264\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |          Use df.loc[df.index.map(crit)] to select via labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=None)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : boolean, default None\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             ``inplace=None`` currently falls back to to True, but in a\n",
      " |             future version, will default to False. Use inplace=True\n",
      " |             explicitly rather than relying on the default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0, inplace=False)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The original object is not modified.\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index', inplace=False)\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns', inplace=False)\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze length 1 dimensions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : None, integer or string axis name, optional\n",
      " |          The axis to squeeze if 1-sized.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar if 1-sized, else original object\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal':['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=None, is_copy=True, **kwargs)\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      convert : bool, default True\n",
      " |          Whether to convert negative indices into positive ones.\n",
      " |          For example, ``-1`` would map to the ``len(axis) - 1``.\n",
      " |          The conversions are similar to the behavior of indexing a\n",
      " |          regular Python list.\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |             In the future, negative indices will always be converted.\n",
      " |      \n",
      " |      is_copy : bool, default True\n",
      " |          Whether to return a copy of the original object or not.\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird',    389.0),\n",
      " |      ...                    ('parrot', 'bird',     24.0),\n",
      " |      ...                    ('lion',   'mammal',   80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                    columns=['name', 'class', 'max_speed'],\n",
      " |      ...                    index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          - True, use the provided separator, writing in a csv format for\n",
      " |            allowing easy pasting into excel.\n",
      " |          - False, write a string representation of the object to the\n",
      " |            clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `gtk` or `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      format : {'fixed', 'table'}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      data_columns :  list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum.\n",
      " |      dropna : bool, default False\n",
      " |          If true, ALL nan rows will not be written to store.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression=None, index=True)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : string\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - 'split' : dict like {'index' -> [index],\n",
      " |              'columns' -> [columns], 'data' -> [values]}\n",
      " |            - 'records' : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - 'index' : dict like {index -> {column -> value}}\n",
      " |            - 'columns' : dict like {column -> {index -> value}}\n",
      " |            - 'values' : just the values array\n",
      " |            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |              describing the data, and the data component is\n",
      " |              like ``orient='records'``.\n",
      " |      \n",
      " |              .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : boolean, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : boolean, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |          .. versionadded:: 0.19.0\n",
      " |      \n",
      " |      compression : {None, 'gzip', 'bz2', 'zip', 'xz'}\n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_json\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None)\n",
      " |      Render an object to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\\\usepackage{booktabs}.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default False\n",
      " |          Make the row labels bold in the output\n",
      " |      column_format : str, default None\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g 'rcl' for 3\n",
      " |          columns\n",
      " |      longtable : boolean, default will be read from the pandas config module\n",
      " |          Default: False.\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\\\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default will be read from the pandas config module\n",
      " |          Default: True.\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, default None\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      decimal : string, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |          .. versionadded:: 0.18.0\n",
      " |      \n",
      " |      multicolumn : boolean, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      multirow : boolean, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows.\n",
      " |          Requires adding a \\\\usepackage{multirow} to your LaTeX preamble.\n",
      " |          Will print centered labels (instead of top-aligned)\n",
      " |          across the contained rows, separating groups via clines.\n",
      " |          The default will be read from the pandas config module.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, encoding='utf-8', **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path, compression='infer', protocol=4)\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      \n",
      " |          .. versionadded:: 0.20.0\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values for this parameter depend on the version of Python. For\n",
      " |          Python 2.x, possible values are 0, 1, 2. For Python>=3.0, 3 is a\n",
      " |          valid value. For Python >= 3.4, 4 is a valid value. A negative\n",
      " |          value for the protocol parameter is equivalent to setting its value\n",
      " |          to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html\n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects.\n",
      " |      schema : string, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Rows will be written in batches of this size at a time. By default,\n",
      " |          all rows will be written at once.\n",
      " |      dtype : dict, optional\n",
      " |          Specifying the datatype for columns. The keys should be the column\n",
      " |          names and the values should be the SQLAlchemy types or strings for\n",
      " |          the sqlite3 legacy mode.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.read_sql : read a DataFrame from a table\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a DataArray for a Series\n",
      " |      a Dataset for a DataFrame\n",
      " |      a DataArray for higher dims\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)})\n",
      " |      >>> df\n",
      " |         A    B    C\n",
      " |      0  1  foo  4.0\n",
      " |      1  1  bar  5.0\n",
      " |      2  2  foo  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (index: 3)\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2\n",
      " |      Data variables:\n",
      " |          A        (index) int64 1 1 2\n",
      " |          B        (index) object 'foo' 'bar' 'foo'\n",
      " |          C        (index) float64 4.0 5.0 6.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [1, 1, 2],\n",
      " |                             'B' : ['foo', 'bar', 'foo'],\n",
      " |                             'C' : np.arange(4.,7)}\n",
      " |                           ).set_index(['B','A'])\n",
      " |      >>> df\n",
      " |               C\n",
      " |      B   A\n",
      " |      foo 1  4.0\n",
      " |      bar 1  5.0\n",
      " |      foo 2  6.0\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (A: 2, B: 2)\n",
      " |      Coordinates:\n",
      " |        * B        (B) object 'bar' 'foo'\n",
      " |        * A        (A) int64 1 2\n",
      " |      Data variables:\n",
      " |          C        (B, A) float64 5.0 nan 4.0 6.0\n",
      " |      \n",
      " |      >>> p = pd.Panel(np.arange(24).reshape(4,3,2),\n",
      " |                       items=list('ABCD'),\n",
      " |                       major_axis=pd.date_range('20130101', periods=3),\n",
      " |                       minor_axis=['first', 'second'])\n",
      " |      >>> p\n",
      " |      <class 'pandas.core.panel.Panel'>\n",
      " |      Dimensions: 4 (items) x 3 (major_axis) x 2 (minor_axis)\n",
      " |      Items axis: A to D\n",
      " |      Major_axis axis: 2013-01-01 00:00:00 to 2013-01-03 00:00:00\n",
      " |      Minor_axis axis: first to second\n",
      " |      \n",
      " |      >>> p.to_xarray()\n",
      " |      <xarray.DataArray (items: 4, major_axis: 3, minor_axis: 2)>\n",
      " |      array([[[ 0,  1],\n",
      " |              [ 2,  3],\n",
      " |              [ 4,  5]],\n",
      " |             [[ 6,  7],\n",
      " |              [ 8,  9],\n",
      " |              [10, 11]],\n",
      " |             [[12, 13],\n",
      " |              [14, 15],\n",
      " |              [16, 17]],\n",
      " |             [[18, 19],\n",
      " |              [20, 21],\n",
      " |              [22, 23]]])\n",
      " |      Coordinates:\n",
      " |        * items       (items) object 'A' 'B' 'C' 'D'\n",
      " |        * major_axis  (major_axis) datetime64[ns] 2013-01-01 2013-01-02 2013-01-03  # noqa\n",
      " |        * minor_axis  (minor_axis) object 'first' 'second'\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, string, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, string, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : boolean, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                    index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0)\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from the tseries module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=True, ambiguous='raise')\n",
      " |      Localize tz-naive TimeSeries to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False, raise_on_error=None)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where `cond` is True and otherwise are from\n",
      " |      `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the NDFrame and\n",
      " |          should return boolean NDFrame or array. The callable must\n",
      " |          not change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as cond.\n",
      " |      \n",
      " |      other : scalar, NDFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the NDFrame and\n",
      " |          should return scalar or NDFrame. The callable must not\n",
      " |          change input NDFrame (though pandas doesn't check it).\n",
      " |      \n",
      " |          .. versionadded:: 0.18.1\n",
      " |              A callable can be used as other.\n",
      " |      \n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object\n",
      " |      \n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |          .. deprecated:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10.0\n",
      " |      1    10.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask`\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the\n",
      " |      Series/DataFrame. Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or\n",
      " |      levels.  It is a superset of xs functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      Series.at : Access a single value using a label\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          When label does not exist in DataFrame\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |      \n",
      " |      .. deprecated:: 0.21.0\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.ftypes : dtype and sparsity information.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether DataFrame is empty.\n",
      " |      \n",
      " |      True if DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.Series.dropna\n",
      " |      pandas.DataFrame.dropna\n",
      " |  \n",
      " |  ftypes\n",
      " |      Return the ftypes (indication of sparse/dense and dtype) in DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype.  See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type and indication of sparse/dense of each column.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.dtypes: Series with just dtype information.\n",
      " |      pandas.SparseDataFrame : Container for sparse tabular data.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Sparse data should have the same dtypes as its dense representation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> arr = np.random.RandomState(0).randn(100, 4)\n",
      " |      >>> arr[arr < .8] = np.nan\n",
      " |      >>> pd.DataFrame(arr).ftypes\n",
      " |      0    float64:dense\n",
      " |      1    float64:dense\n",
      " |      2    float64:dense\n",
      " |      3    float64:dense\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> pd.SparseDataFrame(arr).ftypes\n",
      " |      0    float64:sparse\n",
      " |      1    float64:sparse\n",
      " |      2    float64:sparse\n",
      " |      3    float64:sparse\n",
      " |      dtype: object\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s)\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  is_copy\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      Warning: Starting in 0.20.0, the .ix indexer is deprecated, in\n",
      " |      favor of the more strict .iloc and .loc indexers.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierarchical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |        or Panel) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s)\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError:\n",
      " |          when any items are not found\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]], dtype=int64)\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.index : Retrievie the index labels\n",
      " |      pandas.DataFrame.columns : Retrieving the column names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(q.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
